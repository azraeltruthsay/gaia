
"""
Thought Seed System (GAIA pillar-compliant).
- Saves, stores, reviews, and processes thought seeds.
- Seeds are now generated by the main LLM via the THOUGHT_SEED: directive
- and parsed by the output_router.
"""

# /home/azrael/Project/gaia-assistant/app/cognition/thought_seed.py

import os
import json
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, Any
from gaia_core.config import Config
import logging
from gaia_common.protocols.cognition_packet import CognitionPacket
from gaia_common.utils.thoughtstream import write as ts_write

logger = logging.getLogger("GAIA.ThoughtSeed")

SEEDS_DIR = Path("/knowledge/seeds")
SEEDS_ARCHIVE_DIR = SEEDS_DIR / "archive"
SEEDS_PENDING_DIR = SEEDS_DIR / "pending"
# Do not create the seeds directory at import time (bind mounts may be
# owned by root and cause a PermissionError during import). Create lazily
# when saving or listing seeds and handle failures gracefully.


def save_thought_seed(seed_text: str, packet: CognitionPacket, config: Config) -> Dict[str, Any] | None:
    """
    Saves a thought seed text to a file, linked to the current packet.
    This is called when a THOUGHT_SEED: directive is parsed from LLM output.
    """
    try:
        # Ensure directory exists (best-effort). If this fails we log and
        # return None rather than raising at import time.
        try:
            SEEDS_DIR.mkdir(parents=True, exist_ok=True)
        except Exception:
            logger.warning(f"Could not create seeds dir {SEEDS_DIR}; saving seed skipped")
            return None

        fname = f"seed_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S%f')}.json"
        seed_obj = {
            "created": datetime.now(timezone.utc).isoformat(),
            "context": {
                "prompt": getattr(packet.intent, 'primary_goal', '') if hasattr(packet, 'intent') else '',
                "packet_id": packet.header.packet_id if hasattr(packet, 'header') else 'unknown',
                "persona": str(packet.header.persona.role) if hasattr(packet, 'header') and hasattr(packet.header, 'persona') else '',
            },
            "seed": seed_text.strip(),
            "reviewed": False,
            "action_taken": False,
            "result": None
        }
        with open(SEEDS_DIR / fname, "w", encoding="utf-8") as f:
            json.dump(seed_obj, f, indent=2)
        logger.info(f"üå± Thought seed saved: {fname}")
        ts_write({"type": "thought_seed_saved", "seed": seed_text.strip()}, packet.header.packet_id if hasattr(packet, 'header') else 'unknown')
        seed_obj["_saved_path"] = str(SEEDS_DIR / fname)
        return seed_obj
    except Exception as e:
        logger.error(f"‚ùå Error saving thought seed: {e}", exc_info=True)
        return None


def list_unreviewed_seeds():
    seeds = []
    if not SEEDS_DIR.exists():
        return []
    for f in SEEDS_DIR.glob("seed_*.json"):
        try:  # Add try-except for file reading
            with open(f, "r", encoding="utf-8") as fp:
                data = json.load(fp)
                if not data.get("reviewed"):
                    seeds.append((f, data))
        except Exception as e:
            logger.error(f"‚ùå Error reading thought seed file {f}: {e}", exc_info=True)
    return seeds


def get_seed_by_id(seed_id: str) -> Dict[str, Any] | None:
    """Retrieves a thought seed by its filename."""
    # The seed_id is just the filename, e.g., "seed_20250720_053808.json"
    seed_file = SEEDS_DIR / seed_id
    if not seed_file.is_file():
        logger.warning(f"Seed file not found: {seed_id}")
        return None
    try:
        with open(seed_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"‚ùå Error reading thought seed file {seed_file}: {e}", exc_info=True)
        return None


def update_seed(seed_id: str, seed_data: Dict[str, Any]) -> bool:
    """Overwrites a thought seed file with new data."""
    seed_file = SEEDS_DIR / seed_id
    try:
        with open(seed_file, "w", encoding="utf-8") as f:
            json.dump(seed_data, f, indent=2)
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating thought seed file {seed_file}: {e}", exc_info=True)
        return False


def review_and_process_seeds(config=None, llm=None, auto_act=False):  # <--- llm parameter added
    """
    Load unreviewed seeds, use model to decide whether to act, then process as appropriate.
    """
    # Local import to break circular dependency

    if config is None:
        config = Config()

    # Ensure LLM is available. If not passed, try to get from config's model_pool.
    if llm is None:
        if hasattr(config, 'model_pool') and config.model_pool is not None:
            llm = config.model_pool.get_model_for_role("prime")
        else:
            logger.error("‚ùå No LLM provided and model_pool not available in config for seed review.")
            return False  # Indicate failure

    seeds = list_unreviewed_seeds()
    for f, data in seeds:
        review_prompt = (
            f"Here is a thought seed generated earlier:\nSeed: {data['seed']}\n"
            f"Context: {data['context']}\nShould GAIA act on this seed now? Answer yes or no, and explain."
        )
        try:
            messages = [
                {"role": "system", "content": "You are a decision-making assistant. Answer with 'yes' or 'no' and a brief explanation."},
                {"role": "user", "content": review_prompt},
            ]
            result = llm.create_chat_completion(
                messages=messages,
                temperature=0.3,
                top_p=0.7,
                max_tokens=256,
                stream=False
            )
            decision = result["choices"][0]["message"]["content"].strip()
            should_act = "yes" in decision.lower()
            data["reviewed"] = True
            data["reviewed_at"] = datetime.now(timezone.utc).isoformat()
            data["review_decision"] = decision
            if should_act and auto_act:
                action_result = "Not implemented yet"
                data["action_taken"] = True
                data["action_result"] = action_result
            if update_seed(f.name, data):
                logger.info(f"Thought seed reviewed: {f.name} ‚Äî Decision: {decision}")
        except Exception as e:
            logger.error(f"‚ùå Error reviewing thought seed {f.name}: {e}", exc_info=True)
    return True


def refine_seed(seed_id, refinement_prompt, config=None, llm=None):
    """Refines an existing thought seed."""
    seed_data = get_seed_by_id(seed_id)
    if not seed_data:
        return None

    if config is None:
        config = Config()

    if llm is None:
        if hasattr(config, 'model_pool') and config.model_pool is not None:
            llm = config.model_pool.get_model_for_role("prime")
        else:
            logger.error("‚ùå No LLM provided and model_pool not available in config for thought seed refinement.")
            return None

    prompt = f"""Original Seed: {seed_data['seed']}

Refinement: {refinement_prompt}

New Seed:"""
    
    try:
        result = llm.create_chat_completion(messages=[{"role": "user", "content": prompt}], max_tokens=128, temperature=0.2, stop=["\n"])
        refined_seed = result["choices"][0]["message"]["content"].strip()
        seed_data["seed"] = refined_seed
        seed_data["refined_at"] = datetime.now(timezone.utc).isoformat()
        if update_seed(seed_id, seed_data):
            logger.info(f"Refined thought seed: {seed_id}")
            return seed_data
        return None
    except Exception as e:
        logger.error(f"‚ùå Error refining thought seed {seed_id}: {e}", exc_info=True)
        return None


def link_seeds(source_seed_id, target_seed_id, relationship):
    """Links two thought seeds together."""
    source_seed = get_seed_by_id(source_seed_id)
    target_seed = get_seed_by_id(target_seed_id)

    if not source_seed or not target_seed:
        return False

    if "links" not in source_seed:
        source_seed["links"] = []

    source_seed["links"].append({"target": target_seed_id, "relationship": relationship})
    return update_seed(source_seed_id, source_seed)


def maybe_review_seeds(config, llm=None):  # <--- llm parameter added
    """
    Decides (based on config/heuristics) whether to review/process seeds now.
    """
    # Add conditions as needed‚Äîby default, always review for demonstration.
    review_and_process_seeds(config=config, llm=llm, auto_act=False)  # <--- Pass llm here
    # Set auto_act=True if you want seeds to trigger actions directly.


# ‚îÄ‚îÄ Heartbeat directory operations ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def archive_seed(seed_filename: str) -> bool:
    """Move a seed to the archive directory (permanently dismissed).

    Reads the seed, stamps it with archived metadata, writes to
    SEEDS_ARCHIVE_DIR, and deletes the original.
    """
    src = SEEDS_DIR / seed_filename
    if not src.is_file():
        logger.warning("archive_seed: source not found: %s", seed_filename)
        return False

    try:
        SEEDS_ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
        with open(src, "r", encoding="utf-8") as f:
            data = json.load(f)
        data["archived"] = True
        data["archived_at"] = datetime.now(timezone.utc).isoformat()
        with open(SEEDS_ARCHIVE_DIR / seed_filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)
        src.unlink()
        logger.info("Seed archived: %s", seed_filename)
        return True
    except Exception:
        logger.error("Failed to archive seed %s", seed_filename, exc_info=True)
        return False


def defer_seed(seed_filename: str, revisit_after: str | None = None) -> bool:
    """Move a seed to the pending directory (deferred for later).

    Args:
        seed_filename: Name of the seed file in SEEDS_DIR.
        revisit_after: Optional ISO-8601 datetime string for when to re-triage.
    """
    src = SEEDS_DIR / seed_filename
    if not src.is_file():
        logger.warning("defer_seed: source not found: %s", seed_filename)
        return False

    try:
        SEEDS_PENDING_DIR.mkdir(parents=True, exist_ok=True)
        with open(src, "r", encoding="utf-8") as f:
            data = json.load(f)
        data["pending"] = True
        data["deferred_at"] = datetime.now(timezone.utc).isoformat()
        if revisit_after:
            data["revisit_after"] = revisit_after
        with open(SEEDS_PENDING_DIR / seed_filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)
        src.unlink()
        logger.info("Seed deferred: %s (revisit_after=%s)", seed_filename, revisit_after)
        return True
    except Exception:
        logger.error("Failed to defer seed %s", seed_filename, exc_info=True)
        return False


def list_pending_seeds_due() -> list[tuple[Path, dict]]:
    """Promote overdue pending seeds back to the triage queue.

    A seed is "due" if:
    - It has a ``revisit_after`` datetime that has passed, or
    - It has no ``revisit_after`` and was deferred more than 7 days ago.

    Promoted seeds are moved from SEEDS_PENDING_DIR back to SEEDS_DIR.
    Returns a list of (new_path, seed_data) for each promoted seed.
    """
    promoted: list[tuple[Path, dict]] = []
    if not SEEDS_PENDING_DIR.exists():
        return promoted

    now = datetime.now(timezone.utc)

    for fp in SEEDS_PENDING_DIR.glob("seed_*.json"):
        try:
            with open(fp, "r", encoding="utf-8") as f:
                data = json.load(f)

            due = False
            revisit = data.get("revisit_after")
            if revisit:
                try:
                    due = datetime.fromisoformat(revisit) <= now
                except (ValueError, TypeError):
                    due = False
            else:
                deferred_at = data.get("deferred_at")
                if deferred_at:
                    try:
                        deferred_dt = datetime.fromisoformat(deferred_at)
                        due = (now - deferred_dt).days >= 7
                    except (ValueError, TypeError):
                        pass

            if due:
                # Move back to SEEDS_DIR
                SEEDS_DIR.mkdir(parents=True, exist_ok=True)
                dest = SEEDS_DIR / fp.name
                data.pop("pending", None)
                data.pop("deferred_at", None)
                data.pop("revisit_after", None)
                data["reviewed"] = False  # Reset so heartbeat re-triages
                with open(dest, "w", encoding="utf-8") as f:
                    json.dump(data, f, indent=2)
                fp.unlink()
                promoted.append((dest, data))
                logger.info("Pending seed promoted back to triage: %s", fp.name)
        except Exception:
            logger.error("Error checking pending seed %s", fp.name, exc_info=True)

    return promoted
