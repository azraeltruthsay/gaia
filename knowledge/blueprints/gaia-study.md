# GAIA Service Blueprint: `gaia-study` (The Subconscious (Background Learning))

> **Status:** ğŸŸ¢ LIVE Â· âš ï¸ genesis â€” awaiting validation  
> **Service version:** 0.5  
> **Blueprint version:** 0.2  
> **Generated by:** `manual_seed`  
> **Last reflected:** never  

## Purpose

Background processing service for GAIA's self-study during sleep cycles. Handles vector index building, document embedding, LoRA adapter training via QLoRA, and adapter lifecycle management. Sole writer to the vector store and LoRA adapter directories â€” all other services read only.


**Cognitive role:** The Subconscious

### Design Decisions

- Sole writer principle â€” only gaia-study writes to /vector_store and LoRA adapter directories
- GPU isolation â€” exclusive GPU access during training via orchestrator-managed handoff
- Async background processing â€” long-running ops don't block HTTP responses; client polls /study/status
- Tiered adapter architecture: tier 1 (global, protected), tier 2 (user), tier 3 (session, ephemeral)
- QLoRA 4-bit quantization reduces VRAM from ~50GB to ~16GB for large models
- Gradient checkpointing + paged AdamW (8-bit) further reduce memory footprint
- Content governance: forbidden pattern detection, size limits, sample count limits
- JSON-based vector store for human readability and debugging; suitable for ~100K documents
- Fallback to simulated training when real training dependencies unavailable

### âš ï¸ Open Questions

- Should vector store migrate to FAISS or ChromaDB for better performance at scale?
- Should CUDA_VISIBLE_DEVICES be dynamic based on orchestrator GPU allocation?
- Optimal gradient accumulation steps for RTX 5080 16GB VRAM?

## Runtime

| Property | Value |
|----------|-------|
| Port | `8766` |
| Base image | `nvidia/cuda:12.4.0-devel-ubuntu22.04` |
| GPU | Yes |
| Health check | `curl -f http://localhost:8766/health` |
| Startup | `uvicorn gaia_study.main:app --host 0.0.0.0 --port 8766` |
| GPU count | `all` |
| User | `${UID}:${GID}` |
| Dockerfile | `gaia-study/Dockerfile` |
| Compose service | `gaia-study` |

## Interfaces

### Inbound

- **`health`** âœ… `http_rest` `/health`  
  Container health check endpoint.
- **`status`** âœ… `http_rest` `/status`  
  Service status with loaded indexes and statistics.
- **`index_build`** âœ… `http_rest` `/index/build`  
  Build or rebuild vector index from documents (async background task).
- **`index_add`** âœ… `http_rest` `/index/add`  
  Add single document to existing vector index.
- **`index_query`** âœ… `http_rest` `/index/query`  
  Query index for semantically similar documents.
- **`index_status`** âœ… `http_rest` `/index/{knowledge_base_name}/status`  
  Get status of a specific knowledge base index.
- **`index_refresh`** âœ… `http_rest` `/index/{knowledge_base_name}/refresh`  
  Reload index from disk.
- **`gpu_ready`** âœ… `http_rest` `/study/gpu-ready`  
  Signal from orchestrator that GPU is available for training.
- **`gpu_release`** âœ… `http_rest` `/study/gpu-release`  
  Signal from orchestrator to release GPU; cancels training, cleans CUDA resources.
- **`study_start`** âœ… `http_rest` `/study/start`  
  Start LoRA adapter training from documents (async background task). Supports 3 tiers: global, user, session.
- **`study_status`** âœ… `http_rest` `/study/status`  
  Get current training status (IDLE, PREPARING, TRAINING, COMPLETE, FAILED).
- **`study_cancel`** âœ… `http_rest` `/study/cancel`  
  Cancel in-progress training.
- **`adapter_list`** âœ… `http_rest` `/adapters`  
  List all LoRA adapters, optionally filtered by tier.
- **`adapter_load`** âœ… `http_rest` `/adapters/load`  
  Load adapter for generation (stub â€” requires model pool integration).
- **`adapter_unload`** âœ… `http_rest` `/adapters/unload`  
  Unload adapter (stub â€” requires model pool integration).
- **`adapter_info`** âœ… `http_rest` `/adapters/{adapter_name}`  
  Get detailed adapter metadata.
- **`adapter_delete`** âœ… `http_rest` `/adapters/{adapter_name}`  
  Delete adapter (tier 1 protected from deletion).

## Volume Dependencies

- **gaia-common** `ro` â†’ `/gaia-common` â€” Shared library (vector client, utils)
- **knowledge** `rw` â†’ `/knowledge` â€” Knowledge base documents for indexing (sole writer to vector indices)
- **vector_store** `rw` â†’ `/vector_store` â€” Vector store â€” sole writer for FAISS indices
- **gaia-models** `rw` â†’ `/models` â€” Embedding models, LoRA adapters, base model for training
- **gaia-shared** `rw` â†’ `/shared` â€” Shared state volume
- **logs** `rw` â†’ `/logs` â€” Consolidated service logs

## Failure Modes

- ğŸŸ¡ **Document directory not found**
  â†’ FileNotFoundError raised; index build fails gracefully
- ğŸŸ¡ **No valid training samples**
  â†’ TrainingResult with success=False; adapter not created
- ğŸŸ  **GPU OOM during training**
  â†’ Training marked failed; CUDA cache cleared
- ğŸŸ¡ **Adapter tier limit exceeded**
  â†’ HTTPException 409 Conflict
- ğŸŸ¡ **Content validation failure (forbidden patterns)**
  â†’ Offending samples skipped with logged warning; training continues with remaining
- ğŸŸ¡ **Model load failure (missing base model)**
  â†’ Falls back to simulated training mode for UI/workflow testing
- ğŸŸ¡ **Vector index corruption**
  â†’ Returns empty index; rebuild via /index/build

## Source Files

- `candidates/gaia-study/gaia_study/main.py` _entrypoint_ [python]
- `candidates/gaia-study/gaia_study/server.py` _api_factory_ [python]
- `candidates/gaia-study/gaia_study/indexer.py` _vector_indexer_ [python]
- `candidates/gaia-study/gaia_study/study_mode_manager.py` _training_orchestration_ [python]
- `candidates/gaia-study/gaia_study/qlora_trainer.py` _qlora_training_ [python]
- `candidates/gaia-study/gaia_study/training_utils.py` _training_utilities_ [python]
- `candidates/gaia-study/Dockerfile` _build_config_ [dockerfile]

## Blueprint Confidence

| Section | Confidence |
|---------|------------|
| Runtime | ğŸŸ¢ ConfidenceLevel.HIGH |
| Contract | ğŸŸ¢ ConfidenceLevel.HIGH |
| Dependencies | ğŸŸ¢ ConfidenceLevel.HIGH |
| Failure Modes | ğŸŸ¡ ConfidenceLevel.MEDIUM |
| Intent | ğŸŸ¡ ConfidenceLevel.MEDIUM |

---
_Generated automatically from `gaia-study.yaml`. Do not edit this file directly._