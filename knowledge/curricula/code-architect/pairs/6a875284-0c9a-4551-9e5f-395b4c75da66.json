{
  "pair_id": "6a875284-0c9a-4551-9e5f-395b4c75da66",
  "pair_type": "retroactive",
  "granularity": "service",
  "service_id": "gaia-core",
  "file_scope": null,
  "created_at": "2026-02-21T15:55:35.839145Z",
  "blueprint_yaml": "architecture:\n  components:\n  - consumes_interfaces: []\n    description: 'FastAPI entrypoint and endpoint routers. Receives HTTP requests,\n      deserializes CognitionPackets, and routes to the cognition engine. Includes\n      GPU lifecycle endpoints (release/reclaim) and sleep/wake control endpoints used\n      by gaia-orchestrator and gaia-web respectively.\n\n      '\n    exposes_interfaces:\n    - process_packet\n    - health\n    - root\n    - status\n    - gpu_status\n    - gpu_release\n    - gpu_reclaim\n    - sleep_wake\n    - sleep_status\n    - sleep_study_handoff\n    - sleep_distracted_check\n    - sleep_shutdown\n    id: api_layer\n    key_classes:\n    - AIManagerShim\n    - GPUReleaseRequest\n    - GPUReclaimRequest\n    key_functions:\n    - initialize_cognitive_system()\n    - process_packet(packet_data)\n    - gpu_status()\n    - gpu_release(request)\n    - gpu_reclaim(request)\n    - receive_wake_signal(request)\n    - get_sleep_status()\n    - study_handoff(request)\n    label: API Layer\n    source_files:\n    - candidates/gaia-core/gaia_core/main.py\n    - candidates/gaia-core/gaia_core/api/gpu_endpoints.py\n    - candidates/gaia-core/gaia_core/api/sleep_endpoints.py\n  - consumes_interfaces: []\n    description: 'Core reasoning loop. AgentCore runs multi-turn reasoning with self-improvement.\n      CognitiveDispatcher processes execution results. GoalDetector identifies user\n      intent via fast-path heuristics or LLM classification. ToolSelector decides\n      if/which MCP tools are needed. ExternalVoice generates LLM responses. SelfReflection\n      reviews output quality before delivery.\n\n      '\n    exposes_interfaces: []\n    id: cognition_engine\n    key_classes:\n    - AgentCore\n    - GoalDetector\n    - ExternalVoice\n    key_functions:\n    - AgentCore.run_turn()\n    - AgentCore.run_self_improvement()\n    - process_execution_results()\n    - GoalDetector.detect()\n    - needs_tool_routing()\n    - select_tool()\n    - ExternalVoice.stream_response()\n    - reflect_and_refine()\n    - enhance_packet()\n    label: Cognition Engine\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/agent_core.py\n    - candidates/gaia-core/gaia_core/cognition/cognitive_dispatcher.py\n    - candidates/gaia-core/gaia_core/cognition/goal_detector.py\n    - candidates/gaia-core/gaia_core/cognition/tool_selector.py\n    - candidates/gaia-core/gaia_core/cognition/external_voice.py\n    - candidates/gaia-core/gaia_core/cognition/self_reflection.py\n    - candidates/gaia-core/gaia_core/cognition/knowledge_enhancer.py\n    - candidates/gaia-core/gaia_core/cognition/knowledge_ingestion.py\n  - consumes_interfaces: []\n    description: \"Manages ACTIVE \\u2192 DROWSY \\u2192 ASLEEP \\u2192 WAKING lifecycle.\\\n      \\ SleepCycleLoop is the main event loop driving state transitions. SleepWakeManager\\\n      \\ is the state machine (GaiaState enum). PrimeCheckpointManager writes LLM-generated\\\n      \\ introspective checkpoints (prime.md) on sleep and marks them consumed on wake.\\\n      \\ SleepTaskScheduler runs background tasks (conversation curation, thought seed\\\n      \\ review, blueprint validation) during sleep windows.\\n\"\n    exposes_interfaces: []\n    id: sleep_system\n    key_classes:\n    - SleepCycleLoop\n    - GaiaState\n    - SleepWakeManager\n    - PrimeCheckpointManager\n    - SleepTaskScheduler\n    - SleepTask\n    key_functions:\n    - SleepCycleLoop.start()\n    - SleepWakeManager.initiate_drowsy()\n    - SleepWakeManager.receive_wake_signal()\n    - SleepWakeManager.complete_wake()\n    - PrimeCheckpointManager.create_checkpoint()\n    - PrimeCheckpointManager.mark_consumed()\n    - SleepTaskScheduler.execute_task()\n    label: Sleep/Wake System\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/sleep_cycle_loop.py\n    - candidates/gaia-core/gaia_core/cognition/sleep_wake_manager.py\n    - candidates/gaia-core/gaia_core/cognition/prime_checkpoint.py\n    - candidates/gaia-core/gaia_core/cognition/sleep_task_scheduler.py\n  - consumes_interfaces: []\n    description: 'Four-tier memory architecture. SessionManager handles per-conversation\n      history with summarize-and-archive. SemanticCodex provides mid-term cross-session\n      recall via symbol-indexed entries. SessionHistoryIndexer builds per-session\n      vector indices for semantic retrieval within a conversation. MemoryManager is\n      the top-level singleton coordinating short/long-term access. CodexWriter generates\n      structured codex entries from conversations using LLM refinement.\n\n      '\n    exposes_interfaces: []\n    id: memory_system\n    key_classes:\n    - SessionManager\n    - Session\n    - SemanticCodex\n    - CodexEntry\n    - MemoryManager\n    - SessionHistoryIndexer\n    - CodexWriter\n    key_functions:\n    - SessionManager.get_or_create_session()\n    - SessionManager.add_message()\n    - SessionManager.summarize_and_archive()\n    - SemanticCodex.write_entry()\n    - SemanticCodex.search()\n    - MemoryManager.query_long()\n    label: Memory System\n    source_files:\n    - candidates/gaia-core/gaia_core/memory/session_manager.py\n    - candidates/gaia-core/gaia_core/memory/semantic_codex.py\n    - candidates/gaia-core/gaia_core/memory/memory_manager.py\n    - candidates/gaia-core/gaia_core/memory/session_history_indexer.py\n    - candidates/gaia-core/gaia_core/memory/codex_writer.py\n  - consumes_interfaces:\n    - prime_inference\n    - prime_health\n    description: 'Unified inference abstraction over multiple LLM backends. ModelPool\n      provides role-based model selection (primary, fallback, lite, oracle). VLLMRemoteModel\n      calls gaia-prime''s OpenAI-compatible API. GroqAPIModel provides free-tier cloud\n      fallback. GPTAPIModel and GeminiAPIModel are oracle backends for high-quality\n      reasoning. All backends implement create_chat_completion() for uniform access.\n      Supports LoRA adapter hot-loading and health-checked failover.\n\n      '\n    exposes_interfaces: []\n    id: model_pool\n    key_classes:\n    - ModelPool\n    - ModelManager\n    - VLLMRemoteModel\n    - GroqAPIModel\n    - GPTAPIModel\n    - GeminiAPIModel\n    key_functions:\n    - ModelPool.get_model_for_role()\n    - ModelPool.forward_to_model()\n    - ModelPool.load_prime_only()\n    - VLLMRemoteModel.create_chat_completion()\n    - VLLMRemoteModel.health_check()\n    label: Model Pool\n    source_files:\n    - candidates/gaia-core/gaia_core/models/_model_pool_impl.py\n    - candidates/gaia-core/gaia_core/models/model_manager.py\n    - candidates/gaia-core/gaia_core/models/vllm_remote_model.py\n    - candidates/gaia-core/gaia_core/models/groq_model.py\n    - candidates/gaia-core/gaia_core/models/oracle_model.py\n    - candidates/gaia-core/gaia_core/models/gemini_model.py\n  - consumes_interfaces:\n    - mcp_dispatch\n    - mcp_approval\n    description: 'JSON-RPC client for communicating with gaia-mcp. Provides typed\n      wrappers for all MCP tool methods: file I/O, shell execution, vector queries,\n      knowledge management, and fragment assembly. Includes approval workflow integration\n      for sensitive operations.\n\n      '\n    exposes_interfaces: []\n    id: tool_dispatch\n    key_classes: []\n    key_functions:\n    - call_jsonrpc()\n    - dispatch_sidecar_actions()\n    - ai_read()\n    - ai_write()\n    - ai_execute()\n    - embedding_query()\n    - request_approval_via_mcp()\n    - discover()\n    label: Tool Dispatch (MCP Client)\n    source_files:\n    - candidates/gaia-core/gaia_core/utils/mcp_client.py\n  - consumes_interfaces: []\n    description: \"Builds the final LLM prompt from conversation history, knowledge\\\n      \\ context, persona config, sleep checkpoint injection, and system instructions.\\\n      \\ OutputRouter post-processes LLM output \\u2014 strips think tags, CJK artifacts,\\\n      \\ and GCP metadata, then parses structured fields back into the CognitionPacket.\\n\"\n    exposes_interfaces: []\n    id: prompt_assembly\n    key_classes: []\n    key_functions:\n    - build_from_packet()\n    - build_prompt()\n    - route_output()\n    - _parse_llm_output_into_packet()\n    label: Prompt Assembly & Output Routing\n    source_files:\n    - candidates/gaia-core/gaia_core/utils/prompt_builder.py\n    - candidates/gaia-core/gaia_core/utils/output_router.py\n  - consumes_interfaces: []\n    description: \"Detects and recovers from cognitive loops \\u2014 repeated tool calls,\\\n      \\ similar outputs, state oscillation, error cycles, and token pattern repetition.\\\n      \\ LoopDetector aggregates 5 specialized detectors. LoopRecoveryManager captures\\\n      \\ state and injects recovery context. StreamObserver monitors output quality\\\n      \\ in real-time. ResourceMonitor tracks system resource pressure for distracted-state\\\n      \\ detection.\\n\"\n    exposes_interfaces: []\n    id: resilience\n    key_classes:\n    - LoopDetector\n    - LoopDetectionAggregator\n    - LoopRecoveryManager\n    - StreamObserver\n    - ResourceMonitor\n    key_functions:\n    - LoopDetector.check()\n    - LoopDetector.trigger_reset()\n    - LoopRecoveryManager.check_and_handle()\n    - StreamObserver.observe()\n    - ResourceMonitor.is_distracted()\n    label: Resilience & Loop Detection\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/loop_detector.py\n    - candidates/gaia-core/gaia_core/cognition/loop_recovery.py\n    - candidates/gaia-core/gaia_core/cognition/loop_patterns.py\n    - candidates/gaia-core/gaia_core/utils/stream_observer.py\n    - candidates/gaia-core/gaia_core/utils/resource_monitor.py\n  edges:\n  - data_flow: CognitionPacket\n    from_component: api_layer\n    label: dispatches CognitionPackets to\n    to_component: cognition_engine\n    transport: function_call\n  - data_flow: wake signal, sleep commands\n    from_component: api_layer\n    label: routes sleep/wake/GPU endpoints to\n    to_component: sleep_system\n    transport: function_call\n  - data_flow: \"messages[] \\u2192 completion text\"\n    from_component: cognition_engine\n    label: requests LLM completions via\n    to_component: model_pool\n    transport: function_call\n  - data_flow: JSON-RPC method + params\n    from_component: cognition_engine\n    label: sends tool execution requests to\n    to_component: tool_dispatch\n    transport: function_call\n  - data_flow: session_id, messages, codex entries\n    from_component: cognition_engine\n    label: reads/writes session state and knowledge\n    to_component: memory_system\n    transport: function_call\n  - data_flow: \"context \\u2192 prompt, output \\u2192 parsed packet\"\n    from_component: cognition_engine\n    label: builds prompts and routes output via\n    to_component: prompt_assembly\n    transport: function_call\n  - data_flow: tool calls, outputs, state transitions\n    from_component: cognition_engine\n    label: monitors for loops and quality issues\n    to_component: resilience\n    transport: function_call\n  - data_flow: \"metacognitive prompt \\u2192 checkpoint text\"\n    from_component: sleep_system\n    label: generates LLM checkpoint via lite model\n    to_component: model_pool\n    transport: function_call\n  - data_flow: session summary text\n    from_component: sleep_system\n    label: reads evolving summary for checkpoint context\n    to_component: memory_system\n    transport: function_call\n  - data_flow: \"SleepTask \\u2192 task results\"\n    from_component: sleep_system\n    label: runs sleep tasks (curation, thought seeds)\n    to_component: cognition_engine\n    transport: function_call\n  - data_flow: session history, codex results\n    from_component: prompt_assembly\n    label: retrieves history and knowledge context\n    to_component: memory_system\n    transport: function_call\ndependencies:\n  external_apis:\n  - name: groq\n    purpose: inference_fallback_when_prime_unavailable\n    required: false\n  - name: openai\n    purpose: oracle_tier_inference\n    required: false\n  - name: gemini\n    purpose: oracle_tier_inference\n    required: false\n  services:\n  - fallback: groq-api\n    id: gaia-prime\n    required: false\n    role: inference\n  - fallback: null\n    id: gaia-mcp\n    required: false\n    role: tool_execution\n  - fallback: null\n    id: gaia-web\n    required: true\n    role: output_routing\n  - fallback: null\n    id: gaia-orchestrator\n    required: false\n    role: gpu_lifecycle\n  volumes:\n  - access: rw\n    mount_path: /shared\n    name: gaia-shared\n    purpose: Session state, cognitive checkpoints, prime.md sleep notes\n  - access: ro\n    mount_path: /knowledge\n    name: knowledge\n    purpose: Blueprints, semantic codex, recitable docs\n  - access: rw\n    mount_path: /vector_store\n    name: vector_store\n    purpose: FAISS vector indices for long-term memory\n  - access: ro\n    mount_path: /models\n    name: models\n    purpose: LoRA adapters (json-architect, persona weights)\n  - access: rw\n    mount_path: /logs\n    name: logs\n    purpose: Structured cognition logs, heartbeat telemetry\nfailure_modes:\n- auto_recovers: true\n  condition: gaia-prime unavailable\n  response: Falls back to Groq API; if Groq unavailable, falls back to local GGUF\n    model\n  severity: degraded\n- auto_recovers: true\n  condition: gaia-mcp unavailable\n  response: Tool calls skipped; responds with capability_unavailable in packet\n  severity: degraded\n- auto_recovers: false\n  condition: All inference backends unavailable\n  response: Returns error packet to gaia-web; session preserved for retry\n  severity: partial\n- auto_recovers: true\n  condition: Session state corruption\n  response: Clears session, starts fresh, logs incident to heartbeat\n  severity: degraded\n- auto_recovers: true\n  condition: gaia-orchestrator unreachable\n  response: Sleep/wake GPU handoff skipped; gaia-core retains GPU, study cycle deferred\n  severity: degraded\n- auto_recovers: true\n  condition: Checkpoint write failure\n  response: Sleep proceeds without checkpoint; next wake has no prime.md restoration\n    context\n  severity: degraded\nid: gaia-core\nintent:\n  cognitive_role: The Brain\n  design_decisions:\n  - CPU-only runtime enables GPU handoffs between prime and study without blocking\n    the cognition loop\n  - \"Falls back through groq \\u2192 gguf rather than hard-failing \\u2014 uptime over\\\n    \\ raw capability\"\n  - gaia-web owns output routing so core remains interface-agnostic\n  - 'Four-tier memory: session (short-term), semantic codex (mid-term), vector store\n    (long-term), prime.md checkpoint (sleep continuity)'\n  - Guided decoding via json-architect LoRA adapter for reliable structured output\n    from smaller models\n  - \"Sleep/wake cognitive continuity \\u2014 LLM-generated checkpoint captures introspective\\\n    \\ state, consumed-sentinel prevents stale injection\"\n  - \"Parallel wake strategy \\u2014 GPU reclaim and checkpoint load happen concurrently\\\n    \\ for faster wake\"\n  - Human-in-the-loop approval flow for destructive tool calls via gaia-mcp /request_approval\n  open_questions:\n  - Should reflection loop depth be dynamic based on query complexity or fixed per\n    persona?\n  - \"Semantic codex hot-reload interval is hardcoded \\u2014 should it be configurable\\\n    \\ via gaia_constants.json?\"\n  purpose: 'The cognitive engine of GAIA. Runs the full reasoning loop: intent detection,\n    tool routing, multi-step reflection, and response generation. Deliberately CPU-only\n    to allow gaia-prime and gaia-study to share the GPU without interrupting cognition.\n    All inference is delegated to gaia-prime, with graceful fallback chains preserving\n    uptime across backend failures.\n\n    '\ninterfaces:\n- description: Primary cognition entry point. Receives CognitionPackets from gaia-web,\n    runs the full reasoning loop, returns completed packet.\n  direction: inbound\n  id: process_packet\n  status: active\n  transport:\n    input_schema: CognitionPacket\n    method: POST\n    output_schema: CognitionPacket\n    path: /process_packet\n    type: http_rest\n- description: Container health check endpoint.\n  direction: inbound\n  id: health\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /health\n    type: http_rest\n- description: \"Root endpoint \\u2014 returns list of available endpoints for service\\\n    \\ discovery.\"\n  direction: inbound\n  id: root\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /\n    type: http_rest\n- description: \"Cognitive status \\u2014 current state, uptime, active sessions.\"\n  direction: inbound\n  id: status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /status\n    type: http_rest\n- description: \"GPU allocation state \\u2014 owned, released, or unavailable.\"\n  direction: inbound\n  id: gpu_status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /gpu/status\n    type: http_rest\n- description: Release GPU to orchestrator pool. Called by gaia-orchestrator.\n  direction: inbound\n  id: gpu_release\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/release\n    type: http_rest\n- description: Reclaim GPU from orchestrator pool. Called by gaia-orchestrator.\n  direction: inbound\n  id: gpu_reclaim\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/reclaim\n    type: http_rest\n- description: \"Wake signal from gaia-web \\u2014 triggers transition from ASLEEP to\\\n    \\ WAKING.\"\n  direction: inbound\n  id: sleep_wake\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/wake\n    type: http_rest\n- description: Query current sleep state (ACTIVE, DROWSY, ASLEEP, WAKING).\n  direction: inbound\n  id: sleep_status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /sleep/status\n    type: http_rest\n- description: \"Study handoff endpoint \\u2014 orchestrator signals study cycle complete,\\\n    \\ GPU available.\"\n  direction: inbound\n  id: sleep_study_handoff\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/study-handoff\n    type: http_rest\n- description: Check if GAIA is asleep and should return a canned/distracted response.\n  direction: inbound\n  id: sleep_distracted_check\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /sleep/distracted-check\n    type: http_rest\n- description: \"Graceful shutdown \\u2014 completes current cycle, writes checkpoint,\\\n    \\ enters sleep.\"\n  direction: inbound\n  id: sleep_shutdown\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/shutdown\n    type: http_rest\n- description: LLM inference requests to gaia-prime via OpenAI-compatible API.\n  direction: outbound\n  id: prime_inference\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /v1/chat/completions\n    type: http_rest\n- description: \"Health probe to gaia-prime on boot \\u2014 sets prime_available flag.\"\n  direction: outbound\n  id: prime_health\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /health\n    type: http_rest\n- description: Tool execution requests dispatched to gaia-mcp via JSON-RPC.\n  direction: outbound\n  id: mcp_dispatch\n  status: active\n  transport:\n    methods:\n    - run_shell\n    - write_file\n    - read_file\n    - vector_query\n    - memory_rebuild_index\n    - request_approval\n    target_service: gaia-mcp\n    type: mcp\n- description: Tool approval requests sent to gaia-mcp for human-in-the-loop confirmation.\n  direction: outbound\n  id: mcp_approval\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /request_approval\n    type: http_rest\n- description: \"Notify orchestrator that gaia-core is entering sleep \\u2014 GPU available\\\n    \\ for study.\"\n  direction: outbound\n  id: orchestrator_gpu_sleep\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/sleep\n    type: http_rest\n- description: \"Notify orchestrator that gaia-core is waking \\u2014 request GPU reclamation.\"\n  direction: outbound\n  id: orchestrator_gpu_wake\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/wake\n    type: http_rest\n- description: \"Presence updates to gaia-web \\u2014 online/typing/sleeping status\\\n    \\ for Discord.\"\n  direction: outbound\n  id: web_presence\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /presence\n    type: http_rest\nmeta:\n  blueprint_version: '0.2'\n  confidence:\n    contract: high\n    dependencies: high\n    failure_modes: medium\n    intent: medium\n    runtime: high\n  created_at: '2026-02-21T15:55:35.767496Z'\n  divergence_score: null\n  generated_by: manual_seed\n  genesis: true\n  last_reflected: null\n  promoted_at: null\n  reflection_notes: null\n  schema_version: '1.0'\n  status: candidate\nrole: The Brain (Cognition)\nruntime:\n  base_image: python:3.11-slim\n  compose_service: gaia-core\n  dockerfile: gaia-core/Dockerfile\n  gpu: false\n  gpu_count: null\n  health_check: curl -f http://localhost:6415/health\n  port: 6415\n  security: null\n  startup_cmd: uvicorn gaia_core.main:app --host 0.0.0.0 --port 6415\n  user: ${UID}:${GID}\nservice_status: live\nsource_files:\n- file_type: python\n  path: candidates/gaia-core/gaia_core/main.py\n  role: entrypoint\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/cognitive_dispatcher.py\n  role: core_logic\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/tool_selector.py\n  role: tool_routing\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/goal_detector.py\n  role: intent_detection\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/sleep_cycle_loop.py\n  role: sleep_lifecycle\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/sleep_wake_manager.py\n  role: sleep_state_machine\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/prime_checkpoint.py\n  role: cognitive_checkpoint\n- file_type: python\n  path: candidates/gaia-core/gaia_core/api/gpu_endpoints.py\n  role: gpu_api\n- file_type: python\n  path: candidates/gaia-core/gaia_core/api/sleep_endpoints.py\n  role: sleep_api\n- file_type: python\n  path: candidates/gaia-core/gaia_core/memory/session_manager.py\n  role: session_management\n- file_type: python\n  path: candidates/gaia-core/gaia_core/memory/semantic_codex.py\n  role: mid_term_memory\n- file_type: python\n  path: candidates/gaia-core/gaia_core/models/vllm_remote_model.py\n  role: inference_client\n- file_type: python\n  path: candidates/gaia-core/gaia_core/utils/mcp_client.py\n  role: tool_dispatch\n- file_type: python\n  path: candidates/gaia-core/gaia_core/utils/prompt_builder.py\n  role: prompt_assembly\n- file_type: json\n  path: gaia-common/gaia_common/constants/gaia_constants.json\n  role: config\nversion: '0.5'\n",
  "blueprint_scoped": "architecture:\n  components:\n  - consumes_interfaces: []\n    description: 'FastAPI entrypoint and endpoint routers. Receives HTTP requests,\n      deserializes CognitionPackets, and routes to the cognition engine. Includes\n      GPU lifecycle endpoints (release/reclaim) and sleep/wake control endpoints used\n      by gaia-orchestrator and gaia-web respectively.\n\n      '\n    exposes_interfaces:\n    - process_packet\n    - health\n    - root\n    - status\n    - gpu_status\n    - gpu_release\n    - gpu_reclaim\n    - sleep_wake\n    - sleep_status\n    - sleep_study_handoff\n    - sleep_distracted_check\n    - sleep_shutdown\n    id: api_layer\n    key_classes:\n    - AIManagerShim\n    - GPUReleaseRequest\n    - GPUReclaimRequest\n    key_functions:\n    - initialize_cognitive_system()\n    - process_packet(packet_data)\n    - gpu_status()\n    - gpu_release(request)\n    - gpu_reclaim(request)\n    - receive_wake_signal(request)\n    - get_sleep_status()\n    - study_handoff(request)\n    label: API Layer\n    source_files:\n    - candidates/gaia-core/gaia_core/main.py\n    - candidates/gaia-core/gaia_core/api/gpu_endpoints.py\n    - candidates/gaia-core/gaia_core/api/sleep_endpoints.py\n  - consumes_interfaces: []\n    description: 'Core reasoning loop. AgentCore runs multi-turn reasoning with self-improvement.\n      CognitiveDispatcher processes execution results. GoalDetector identifies user\n      intent via fast-path heuristics or LLM classification. ToolSelector decides\n      if/which MCP tools are needed. ExternalVoice generates LLM responses. SelfReflection\n      reviews output quality before delivery.\n\n      '\n    exposes_interfaces: []\n    id: cognition_engine\n    key_classes:\n    - AgentCore\n    - GoalDetector\n    - ExternalVoice\n    key_functions:\n    - AgentCore.run_turn()\n    - AgentCore.run_self_improvement()\n    - process_execution_results()\n    - GoalDetector.detect()\n    - needs_tool_routing()\n    - select_tool()\n    - ExternalVoice.stream_response()\n    - reflect_and_refine()\n    - enhance_packet()\n    label: Cognition Engine\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/agent_core.py\n    - candidates/gaia-core/gaia_core/cognition/cognitive_dispatcher.py\n    - candidates/gaia-core/gaia_core/cognition/goal_detector.py\n    - candidates/gaia-core/gaia_core/cognition/tool_selector.py\n    - candidates/gaia-core/gaia_core/cognition/external_voice.py\n    - candidates/gaia-core/gaia_core/cognition/self_reflection.py\n    - candidates/gaia-core/gaia_core/cognition/knowledge_enhancer.py\n    - candidates/gaia-core/gaia_core/cognition/knowledge_ingestion.py\n  - consumes_interfaces: []\n    description: \"Manages ACTIVE \\u2192 DROWSY \\u2192 ASLEEP \\u2192 WAKING lifecycle.\\\n      \\ SleepCycleLoop is the main event loop driving state transitions. SleepWakeManager\\\n      \\ is the state machine (GaiaState enum). PrimeCheckpointManager writes LLM-generated\\\n      \\ introspective checkpoints (prime.md) on sleep and marks them consumed on wake.\\\n      \\ SleepTaskScheduler runs background tasks (conversation curation, thought seed\\\n      \\ review, blueprint validation) during sleep windows.\\n\"\n    exposes_interfaces: []\n    id: sleep_system\n    key_classes:\n    - SleepCycleLoop\n    - GaiaState\n    - SleepWakeManager\n    - PrimeCheckpointManager\n    - SleepTaskScheduler\n    - SleepTask\n    key_functions:\n    - SleepCycleLoop.start()\n    - SleepWakeManager.initiate_drowsy()\n    - SleepWakeManager.receive_wake_signal()\n    - SleepWakeManager.complete_wake()\n    - PrimeCheckpointManager.create_checkpoint()\n    - PrimeCheckpointManager.mark_consumed()\n    - SleepTaskScheduler.execute_task()\n    label: Sleep/Wake System\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/sleep_cycle_loop.py\n    - candidates/gaia-core/gaia_core/cognition/sleep_wake_manager.py\n    - candidates/gaia-core/gaia_core/cognition/prime_checkpoint.py\n    - candidates/gaia-core/gaia_core/cognition/sleep_task_scheduler.py\n  - consumes_interfaces: []\n    description: 'Four-tier memory architecture. SessionManager handles per-conversation\n      history with summarize-and-archive. SemanticCodex provides mid-term cross-session\n      recall via symbol-indexed entries. SessionHistoryIndexer builds per-session\n      vector indices for semantic retrieval within a conversation. MemoryManager is\n      the top-level singleton coordinating short/long-term access. CodexWriter generates\n      structured codex entries from conversations using LLM refinement.\n\n      '\n    exposes_interfaces: []\n    id: memory_system\n    key_classes:\n    - SessionManager\n    - Session\n    - SemanticCodex\n    - CodexEntry\n    - MemoryManager\n    - SessionHistoryIndexer\n    - CodexWriter\n    key_functions:\n    - SessionManager.get_or_create_session()\n    - SessionManager.add_message()\n    - SessionManager.summarize_and_archive()\n    - SemanticCodex.write_entry()\n    - SemanticCodex.search()\n    - MemoryManager.query_long()\n    label: Memory System\n    source_files:\n    - candidates/gaia-core/gaia_core/memory/session_manager.py\n    - candidates/gaia-core/gaia_core/memory/semantic_codex.py\n    - candidates/gaia-core/gaia_core/memory/memory_manager.py\n    - candidates/gaia-core/gaia_core/memory/session_history_indexer.py\n    - candidates/gaia-core/gaia_core/memory/codex_writer.py\n  - consumes_interfaces:\n    - prime_inference\n    - prime_health\n    description: 'Unified inference abstraction over multiple LLM backends. ModelPool\n      provides role-based model selection (primary, fallback, lite, oracle). VLLMRemoteModel\n      calls gaia-prime''s OpenAI-compatible API. GroqAPIModel provides free-tier cloud\n      fallback. GPTAPIModel and GeminiAPIModel are oracle backends for high-quality\n      reasoning. All backends implement create_chat_completion() for uniform access.\n      Supports LoRA adapter hot-loading and health-checked failover.\n\n      '\n    exposes_interfaces: []\n    id: model_pool\n    key_classes:\n    - ModelPool\n    - ModelManager\n    - VLLMRemoteModel\n    - GroqAPIModel\n    - GPTAPIModel\n    - GeminiAPIModel\n    key_functions:\n    - ModelPool.get_model_for_role()\n    - ModelPool.forward_to_model()\n    - ModelPool.load_prime_only()\n    - VLLMRemoteModel.create_chat_completion()\n    - VLLMRemoteModel.health_check()\n    label: Model Pool\n    source_files:\n    - candidates/gaia-core/gaia_core/models/_model_pool_impl.py\n    - candidates/gaia-core/gaia_core/models/model_manager.py\n    - candidates/gaia-core/gaia_core/models/vllm_remote_model.py\n    - candidates/gaia-core/gaia_core/models/groq_model.py\n    - candidates/gaia-core/gaia_core/models/oracle_model.py\n    - candidates/gaia-core/gaia_core/models/gemini_model.py\n  - consumes_interfaces:\n    - mcp_dispatch\n    - mcp_approval\n    description: 'JSON-RPC client for communicating with gaia-mcp. Provides typed\n      wrappers for all MCP tool methods: file I/O, shell execution, vector queries,\n      knowledge management, and fragment assembly. Includes approval workflow integration\n      for sensitive operations.\n\n      '\n    exposes_interfaces: []\n    id: tool_dispatch\n    key_classes: []\n    key_functions:\n    - call_jsonrpc()\n    - dispatch_sidecar_actions()\n    - ai_read()\n    - ai_write()\n    - ai_execute()\n    - embedding_query()\n    - request_approval_via_mcp()\n    - discover()\n    label: Tool Dispatch (MCP Client)\n    source_files:\n    - candidates/gaia-core/gaia_core/utils/mcp_client.py\n  - consumes_interfaces: []\n    description: \"Builds the final LLM prompt from conversation history, knowledge\\\n      \\ context, persona config, sleep checkpoint injection, and system instructions.\\\n      \\ OutputRouter post-processes LLM output \\u2014 strips think tags, CJK artifacts,\\\n      \\ and GCP metadata, then parses structured fields back into the CognitionPacket.\\n\"\n    exposes_interfaces: []\n    id: prompt_assembly\n    key_classes: []\n    key_functions:\n    - build_from_packet()\n    - build_prompt()\n    - route_output()\n    - _parse_llm_output_into_packet()\n    label: Prompt Assembly & Output Routing\n    source_files:\n    - candidates/gaia-core/gaia_core/utils/prompt_builder.py\n    - candidates/gaia-core/gaia_core/utils/output_router.py\n  - consumes_interfaces: []\n    description: \"Detects and recovers from cognitive loops \\u2014 repeated tool calls,\\\n      \\ similar outputs, state oscillation, error cycles, and token pattern repetition.\\\n      \\ LoopDetector aggregates 5 specialized detectors. LoopRecoveryManager captures\\\n      \\ state and injects recovery context. StreamObserver monitors output quality\\\n      \\ in real-time. ResourceMonitor tracks system resource pressure for distracted-state\\\n      \\ detection.\\n\"\n    exposes_interfaces: []\n    id: resilience\n    key_classes:\n    - LoopDetector\n    - LoopDetectionAggregator\n    - LoopRecoveryManager\n    - StreamObserver\n    - ResourceMonitor\n    key_functions:\n    - LoopDetector.check()\n    - LoopDetector.trigger_reset()\n    - LoopRecoveryManager.check_and_handle()\n    - StreamObserver.observe()\n    - ResourceMonitor.is_distracted()\n    label: Resilience & Loop Detection\n    source_files:\n    - candidates/gaia-core/gaia_core/cognition/loop_detector.py\n    - candidates/gaia-core/gaia_core/cognition/loop_recovery.py\n    - candidates/gaia-core/gaia_core/cognition/loop_patterns.py\n    - candidates/gaia-core/gaia_core/utils/stream_observer.py\n    - candidates/gaia-core/gaia_core/utils/resource_monitor.py\n  edges:\n  - data_flow: CognitionPacket\n    from_component: api_layer\n    label: dispatches CognitionPackets to\n    to_component: cognition_engine\n    transport: function_call\n  - data_flow: wake signal, sleep commands\n    from_component: api_layer\n    label: routes sleep/wake/GPU endpoints to\n    to_component: sleep_system\n    transport: function_call\n  - data_flow: \"messages[] \\u2192 completion text\"\n    from_component: cognition_engine\n    label: requests LLM completions via\n    to_component: model_pool\n    transport: function_call\n  - data_flow: JSON-RPC method + params\n    from_component: cognition_engine\n    label: sends tool execution requests to\n    to_component: tool_dispatch\n    transport: function_call\n  - data_flow: session_id, messages, codex entries\n    from_component: cognition_engine\n    label: reads/writes session state and knowledge\n    to_component: memory_system\n    transport: function_call\n  - data_flow: \"context \\u2192 prompt, output \\u2192 parsed packet\"\n    from_component: cognition_engine\n    label: builds prompts and routes output via\n    to_component: prompt_assembly\n    transport: function_call\n  - data_flow: tool calls, outputs, state transitions\n    from_component: cognition_engine\n    label: monitors for loops and quality issues\n    to_component: resilience\n    transport: function_call\n  - data_flow: \"metacognitive prompt \\u2192 checkpoint text\"\n    from_component: sleep_system\n    label: generates LLM checkpoint via lite model\n    to_component: model_pool\n    transport: function_call\n  - data_flow: session summary text\n    from_component: sleep_system\n    label: reads evolving summary for checkpoint context\n    to_component: memory_system\n    transport: function_call\n  - data_flow: \"SleepTask \\u2192 task results\"\n    from_component: sleep_system\n    label: runs sleep tasks (curation, thought seeds)\n    to_component: cognition_engine\n    transport: function_call\n  - data_flow: session history, codex results\n    from_component: prompt_assembly\n    label: retrieves history and knowledge context\n    to_component: memory_system\n    transport: function_call\ndependencies:\n  external_apis:\n  - name: groq\n    purpose: inference_fallback_when_prime_unavailable\n    required: false\n  - name: openai\n    purpose: oracle_tier_inference\n    required: false\n  - name: gemini\n    purpose: oracle_tier_inference\n    required: false\n  services:\n  - fallback: groq-api\n    id: gaia-prime\n    required: false\n    role: inference\n  - fallback: null\n    id: gaia-mcp\n    required: false\n    role: tool_execution\n  - fallback: null\n    id: gaia-web\n    required: true\n    role: output_routing\n  - fallback: null\n    id: gaia-orchestrator\n    required: false\n    role: gpu_lifecycle\n  volumes:\n  - access: rw\n    mount_path: /shared\n    name: gaia-shared\n    purpose: Session state, cognitive checkpoints, prime.md sleep notes\n  - access: ro\n    mount_path: /knowledge\n    name: knowledge\n    purpose: Blueprints, semantic codex, recitable docs\n  - access: rw\n    mount_path: /vector_store\n    name: vector_store\n    purpose: FAISS vector indices for long-term memory\n  - access: ro\n    mount_path: /models\n    name: models\n    purpose: LoRA adapters (json-architect, persona weights)\n  - access: rw\n    mount_path: /logs\n    name: logs\n    purpose: Structured cognition logs, heartbeat telemetry\nfailure_modes:\n- auto_recovers: true\n  condition: gaia-prime unavailable\n  response: Falls back to Groq API; if Groq unavailable, falls back to local GGUF\n    model\n  severity: degraded\n- auto_recovers: true\n  condition: gaia-mcp unavailable\n  response: Tool calls skipped; responds with capability_unavailable in packet\n  severity: degraded\n- auto_recovers: false\n  condition: All inference backends unavailable\n  response: Returns error packet to gaia-web; session preserved for retry\n  severity: partial\n- auto_recovers: true\n  condition: Session state corruption\n  response: Clears session, starts fresh, logs incident to heartbeat\n  severity: degraded\n- auto_recovers: true\n  condition: gaia-orchestrator unreachable\n  response: Sleep/wake GPU handoff skipped; gaia-core retains GPU, study cycle deferred\n  severity: degraded\n- auto_recovers: true\n  condition: Checkpoint write failure\n  response: Sleep proceeds without checkpoint; next wake has no prime.md restoration\n    context\n  severity: degraded\nid: gaia-core\nintent:\n  cognitive_role: The Brain\n  design_decisions:\n  - CPU-only runtime enables GPU handoffs between prime and study without blocking\n    the cognition loop\n  - \"Falls back through groq \\u2192 gguf rather than hard-failing \\u2014 uptime over\\\n    \\ raw capability\"\n  - gaia-web owns output routing so core remains interface-agnostic\n  - 'Four-tier memory: session (short-term), semantic codex (mid-term), vector store\n    (long-term), prime.md checkpoint (sleep continuity)'\n  - Guided decoding via json-architect LoRA adapter for reliable structured output\n    from smaller models\n  - \"Sleep/wake cognitive continuity \\u2014 LLM-generated checkpoint captures introspective\\\n    \\ state, consumed-sentinel prevents stale injection\"\n  - \"Parallel wake strategy \\u2014 GPU reclaim and checkpoint load happen concurrently\\\n    \\ for faster wake\"\n  - Human-in-the-loop approval flow for destructive tool calls via gaia-mcp /request_approval\n  open_questions:\n  - Should reflection loop depth be dynamic based on query complexity or fixed per\n    persona?\n  - \"Semantic codex hot-reload interval is hardcoded \\u2014 should it be configurable\\\n    \\ via gaia_constants.json?\"\n  purpose: 'The cognitive engine of GAIA. Runs the full reasoning loop: intent detection,\n    tool routing, multi-step reflection, and response generation. Deliberately CPU-only\n    to allow gaia-prime and gaia-study to share the GPU without interrupting cognition.\n    All inference is delegated to gaia-prime, with graceful fallback chains preserving\n    uptime across backend failures.\n\n    '\ninterfaces:\n- description: Primary cognition entry point. Receives CognitionPackets from gaia-web,\n    runs the full reasoning loop, returns completed packet.\n  direction: inbound\n  id: process_packet\n  status: active\n  transport:\n    input_schema: CognitionPacket\n    method: POST\n    output_schema: CognitionPacket\n    path: /process_packet\n    type: http_rest\n- description: Container health check endpoint.\n  direction: inbound\n  id: health\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /health\n    type: http_rest\n- description: \"Root endpoint \\u2014 returns list of available endpoints for service\\\n    \\ discovery.\"\n  direction: inbound\n  id: root\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /\n    type: http_rest\n- description: \"Cognitive status \\u2014 current state, uptime, active sessions.\"\n  direction: inbound\n  id: status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /status\n    type: http_rest\n- description: \"GPU allocation state \\u2014 owned, released, or unavailable.\"\n  direction: inbound\n  id: gpu_status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /gpu/status\n    type: http_rest\n- description: Release GPU to orchestrator pool. Called by gaia-orchestrator.\n  direction: inbound\n  id: gpu_release\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/release\n    type: http_rest\n- description: Reclaim GPU from orchestrator pool. Called by gaia-orchestrator.\n  direction: inbound\n  id: gpu_reclaim\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/reclaim\n    type: http_rest\n- description: \"Wake signal from gaia-web \\u2014 triggers transition from ASLEEP to\\\n    \\ WAKING.\"\n  direction: inbound\n  id: sleep_wake\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/wake\n    type: http_rest\n- description: Query current sleep state (ACTIVE, DROWSY, ASLEEP, WAKING).\n  direction: inbound\n  id: sleep_status\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /sleep/status\n    type: http_rest\n- description: \"Study handoff endpoint \\u2014 orchestrator signals study cycle complete,\\\n    \\ GPU available.\"\n  direction: inbound\n  id: sleep_study_handoff\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/study-handoff\n    type: http_rest\n- description: Check if GAIA is asleep and should return a canned/distracted response.\n  direction: inbound\n  id: sleep_distracted_check\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /sleep/distracted-check\n    type: http_rest\n- description: \"Graceful shutdown \\u2014 completes current cycle, writes checkpoint,\\\n    \\ enters sleep.\"\n  direction: inbound\n  id: sleep_shutdown\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /sleep/shutdown\n    type: http_rest\n- description: LLM inference requests to gaia-prime via OpenAI-compatible API.\n  direction: outbound\n  id: prime_inference\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /v1/chat/completions\n    type: http_rest\n- description: \"Health probe to gaia-prime on boot \\u2014 sets prime_available flag.\"\n  direction: outbound\n  id: prime_health\n  status: active\n  transport:\n    input_schema: null\n    method: GET\n    output_schema: null\n    path: /health\n    type: http_rest\n- description: Tool execution requests dispatched to gaia-mcp via JSON-RPC.\n  direction: outbound\n  id: mcp_dispatch\n  status: active\n  transport:\n    methods:\n    - run_shell\n    - write_file\n    - read_file\n    - vector_query\n    - memory_rebuild_index\n    - request_approval\n    target_service: gaia-mcp\n    type: mcp\n- description: Tool approval requests sent to gaia-mcp for human-in-the-loop confirmation.\n  direction: outbound\n  id: mcp_approval\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /request_approval\n    type: http_rest\n- description: \"Notify orchestrator that gaia-core is entering sleep \\u2014 GPU available\\\n    \\ for study.\"\n  direction: outbound\n  id: orchestrator_gpu_sleep\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/sleep\n    type: http_rest\n- description: \"Notify orchestrator that gaia-core is waking \\u2014 request GPU reclamation.\"\n  direction: outbound\n  id: orchestrator_gpu_wake\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /gpu/wake\n    type: http_rest\n- description: \"Presence updates to gaia-web \\u2014 online/typing/sleeping status\\\n    \\ for Discord.\"\n  direction: outbound\n  id: web_presence\n  status: active\n  transport:\n    input_schema: null\n    method: POST\n    output_schema: null\n    path: /presence\n    type: http_rest\nmeta:\n  blueprint_version: '0.2'\n  confidence:\n    contract: high\n    dependencies: high\n    failure_modes: medium\n    intent: medium\n    runtime: high\n  created_at: '2026-02-21T15:55:35.767496Z'\n  divergence_score: null\n  generated_by: manual_seed\n  genesis: true\n  last_reflected: null\n  promoted_at: null\n  reflection_notes: null\n  schema_version: '1.0'\n  status: candidate\nrole: The Brain (Cognition)\nruntime:\n  base_image: python:3.11-slim\n  compose_service: gaia-core\n  dockerfile: gaia-core/Dockerfile\n  gpu: false\n  gpu_count: null\n  health_check: curl -f http://localhost:6415/health\n  port: 6415\n  security: null\n  startup_cmd: uvicorn gaia_core.main:app --host 0.0.0.0 --port 6415\n  user: ${UID}:${GID}\nservice_status: live\nsource_files:\n- file_type: python\n  path: candidates/gaia-core/gaia_core/main.py\n  role: entrypoint\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/cognitive_dispatcher.py\n  role: core_logic\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/tool_selector.py\n  role: tool_routing\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/goal_detector.py\n  role: intent_detection\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/sleep_cycle_loop.py\n  role: sleep_lifecycle\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/sleep_wake_manager.py\n  role: sleep_state_machine\n- file_type: python\n  path: candidates/gaia-core/gaia_core/cognition/prime_checkpoint.py\n  role: cognitive_checkpoint\n- file_type: python\n  path: candidates/gaia-core/gaia_core/api/gpu_endpoints.py\n  role: gpu_api\n- file_type: python\n  path: candidates/gaia-core/gaia_core/api/sleep_endpoints.py\n  role: sleep_api\n- file_type: python\n  path: candidates/gaia-core/gaia_core/memory/session_manager.py\n  role: session_management\n- file_type: python\n  path: candidates/gaia-core/gaia_core/memory/semantic_codex.py\n  role: mid_term_memory\n- file_type: python\n  path: candidates/gaia-core/gaia_core/models/vllm_remote_model.py\n  role: inference_client\n- file_type: python\n  path: candidates/gaia-core/gaia_core/utils/mcp_client.py\n  role: tool_dispatch\n- file_type: python\n  path: candidates/gaia-core/gaia_core/utils/prompt_builder.py\n  role: prompt_assembly\n- file_type: json\n  path: gaia-common/gaia_common/constants/gaia_constants.json\n  role: config\nversion: '0.5'\n",
  "ast_summaries": {
    "__init__.py": {
      "module_docstring": "gaia-core: The Brain - Cognitive loop and reasoning engine.\n\nThis service is the heart of GAIA, responsible for:\n- Agent cognitive loop (reason-act-reflect)\n- Model pool orchestration (Prime/Lite/Embe",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "RuntimeError"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 24
        }
      ],
      "http_calls": []
    },
    "api/gpu_endpoints.py": {
      "module_docstring": "GPU management endpoints for gaia-core.\n\nThese endpoints allow the orchestrator to manage gaia-core's model pool\nwhen GPU ownership changes. The orchestrator handles the actual container\nstop/start fo",
      "classes": [
        {
          "name": "GPUReleaseRequest",
          "bases": [
            "BaseModel"
          ],
          "docstring": null,
          "methods": [],
          "line": 56
        },
        {
          "name": "GPUReclaimRequest",
          "bases": [
            "BaseModel"
          ],
          "docstring": null,
          "methods": [],
          "line": 60
        }
      ],
      "functions": [
        {
          "name": "_prime_endpoint",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 38
        },
        {
          "name": "_get_model_pool",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 46
        },
        {
          "name": "gpu_status",
          "params": [],
          "return_type": null,
          "decorators": [
            "router.get('/status')"
          ],
          "is_async": true,
          "line": 67
        },
        {
          "name": "gpu_release",
          "params": [
            "request: GPUReleaseRequest = GPUReleaseRequest()"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/release')"
          ],
          "is_async": true,
          "line": 94
        },
        {
          "name": "gpu_reclaim",
          "params": [
            "request: GPUReclaimRequest = GPUReclaimRequest()"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/reclaim')"
          ],
          "is_async": true,
          "line": 148
        }
      ],
      "endpoints": [
        {
          "method": "GET",
          "path": "/status",
          "function_name": "gpu_status",
          "line": 67
        },
        {
          "method": "POST",
          "path": "/release",
          "function_name": "gpu_release",
          "line": 94
        },
        {
          "method": "POST",
          "path": "/reclaim",
          "function_name": "gpu_reclaim",
          "line": 148
        }
      ],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": 500,
          "enclosing_function": "gpu_release",
          "line": 141
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": 500,
          "enclosing_function": "gpu_reclaim",
          "line": 211
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "gpu_status",
          "line": 79
        },
        {
          "exception_types": [
            "requests.exceptions.ConnectionError"
          ],
          "status_code": null,
          "enclosing_function": "gpu_reclaim",
          "line": 179
        }
      ],
      "http_calls": [
        {
          "call_method": "get",
          "url_or_path": "<f-string>",
          "enclosing_function": "gpu_status",
          "line": 77
        },
        {
          "call_method": "get",
          "url_or_path": "<f-string>",
          "enclosing_function": "gpu_reclaim",
          "line": 174
        }
      ]
    },
    "api/sleep_endpoints.py": {
      "module_docstring": "Sleep cycle HTTP endpoints for gaia-core.\n\nFollows the existing pattern from gpu_endpoints.py:\n  - Separate router file with APIRouter(prefix=\"/sleep\")\n  - Registered in main.py via app.include_router",
      "classes": [],
      "functions": [
        {
          "name": "receive_wake_signal",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/wake')"
          ],
          "is_async": true,
          "line": 23
        },
        {
          "name": "voice_state",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/voice-state')"
          ],
          "is_async": true,
          "line": 45
        },
        {
          "name": "get_sleep_status",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.get('/status')"
          ],
          "is_async": true,
          "line": 74
        },
        {
          "name": "study_handoff",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/study-handoff')"
          ],
          "is_async": true,
          "line": 87
        },
        {
          "name": "distracted_check",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.get('/distracted-check')"
          ],
          "is_async": true,
          "line": 121
        },
        {
          "name": "shutdown",
          "params": [
            "request: Request"
          ],
          "return_type": null,
          "decorators": [
            "router.post('/shutdown')"
          ],
          "is_async": true,
          "line": 143
        }
      ],
      "endpoints": [
        {
          "method": "POST",
          "path": "/wake",
          "function_name": "receive_wake_signal",
          "line": 23
        },
        {
          "method": "POST",
          "path": "/voice-state",
          "function_name": "voice_state",
          "line": 45
        },
        {
          "method": "GET",
          "path": "/status",
          "function_name": "get_sleep_status",
          "line": 74
        },
        {
          "method": "POST",
          "path": "/study-handoff",
          "function_name": "study_handoff",
          "line": 87
        },
        {
          "method": "GET",
          "path": "/distracted-check",
          "function_name": "distracted_check",
          "line": 121
        },
        {
          "method": "POST",
          "path": "/shutdown",
          "function_name": "shutdown",
          "line": 143
        }
      ],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "behavior/__init__.py": {
      "module_docstring": "gaia_core.behavior - Persona and behavioral adaptation modules.\n\nThis package provides:\n- persona_manager: Load and manage persona definitions\n- persona_adapter: Adapt responses based on active person",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "behavior/persona_adapter.py": {
      "module_docstring": "Persona Adapter (pillar-compliant, robust)\n- Adapts/merges persona config with current pipeline context.\n- Ensures context has correct template, instructions, and allows future persona behaviors.",
      "classes": [
        {
          "name": "PersonaAdapter",
          "bases": [],
          "docstring": "Adapts/wraps raw persona data into a consistent object for use throughout GAIA.\nEnsures persona attr",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "persona_data: dict",
                "config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "get_full_instructions",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 31
            },
            {
              "name": "__repr__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 40
            },
            {
              "name": "__str__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 43
            }
          ],
          "line": 10
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "behavior/persona_manager.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "PersonaManager",
          "bases": [],
          "docstring": "Manages loading and listing of GAIA's personas from disk.\nThis class is a stateless service for retr",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "personas_dir: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "load_persona_data",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": "Optional[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 21
            },
            {
              "name": "list_personas",
              "params": [
                "self"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 53
            },
            {
              "name": "get_persona",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 76
            }
          ],
          "line": 10
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "json.JSONDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "load_persona_data",
          "line": 46
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_persona_data",
          "line": 49
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "list_personas",
          "line": 71
        }
      ],
      "http_calls": []
    },
    "behavior/persona_switcher.py": {
      "module_docstring": "This module contains the logic for dynamically switching GAIA's persona based on user intent.",
      "classes": [],
      "functions": [
        {
          "name": "_normalize_text",
          "params": [
            "text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 16
        },
        {
          "name": "_load_persona_config",
          "params": [
            "persona_name: str"
          ],
          "return_type": "Optional[dict]",
          "decorators": [],
          "is_async": false,
          "line": 44
        },
        {
          "name": "get_knowledge_base_for_persona",
          "params": [
            "persona_name: str"
          ],
          "return_type": "Optional[str]",
          "decorators": [],
          "is_async": false,
          "line": 61
        },
        {
          "name": "get_persona_for_knowledge_base",
          "params": [
            "kb_name: str"
          ],
          "return_type": "Optional[str]",
          "decorators": [],
          "is_async": false,
          "line": 80
        },
        {
          "name": "get_persona_for_request",
          "params": [
            "user_input: str"
          ],
          "return_type": "Tuple[str, Optional[str]]",
          "decorators": [],
          "is_async": false,
          "line": 112
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_persona_for_knowledge_base",
          "line": 106
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_persona_config",
          "line": 56
        }
      ],
      "http_calls": []
    },
    "behavior/persona_writer.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "PersonaWriter",
          "bases": [],
          "docstring": "Handles creation of persona folders and writing JSON + instruction overlays to disk.\nUsed during int",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "vectordb_client",
                "personas_dir = '/personas'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "create_persona_from_template",
              "params": [
                "self",
                "template: Dict",
                "instructions: Optional[Dict[str, str]] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 24
            },
            {
              "name": "_summarize_persona",
              "params": [
                "self",
                "template: Dict"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 69
            },
            {
              "name": "_embed_to_vectordb",
              "params": [
                "self",
                "summary_text: str",
                "tag: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 85
            }
          ],
          "line": 9
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_persona_from_template",
          "line": 65
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_embed_to_vectordb",
          "line": 104
        }
      ],
      "http_calls": []
    },
    "cognition/__init__.py": {
      "module_docstring": "gaia_core.cognition - Cognitive processing and reasoning modules.\n\nThis package provides:\n- agent_core: Main cognitive loop (AgentCore class)\n- cognitive_dispatcher: Route and dispatch cognitive tasks",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/adapter_trigger_system.py": {
      "module_docstring": "Adapter Trigger System - Automatic LoRA adapter activation based on content\n\nMonitors user input for keywords/patterns and automatically loads relevant\nadapters to enhance GAIA's knowledge for specifi",
      "classes": [
        {
          "name": "TriggerRule",
          "bases": [],
          "docstring": "A rule for triggering adapter activation.",
          "methods": [],
          "line": 21
        },
        {
          "name": "TriggerMatch",
          "bases": [],
          "docstring": "Result of a trigger match.",
          "methods": [],
          "line": 34
        },
        {
          "name": "AdapterTriggerSystem",
          "bases": [],
          "docstring": "Monitors input and determines which adapters should be activated.\n\nFeatures:\n- Keyword matching (cas",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "adapter_base_dir: str = '/models/lora_adapters'",
                "max_concurrent_adapters: int = 3"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 55
            },
            {
              "name": "set_load_callback",
              "params": [
                "self",
                "callback: Callable[[str, str, int], bool]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 79
            },
            {
              "name": "set_unload_callback",
              "params": [
                "self",
                "callback: Callable[[str], bool]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 83
            },
            {
              "name": "load_rules_from_adapters",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 87
            },
            {
              "name": "add_rule",
              "params": [
                "self",
                "rule: TriggerRule"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 151
            },
            {
              "name": "remove_rule",
              "params": [
                "self",
                "adapter_name: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 156
            },
            {
              "name": "check_triggers",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "List[TriggerMatch]",
              "decorators": [],
              "is_async": false,
              "line": 162
            },
            {
              "name": "process_input",
              "params": [
                "self",
                "text: str",
                "auto_load: bool = True"
              ],
              "return_type": "Tuple[List[TriggerMatch], List[str], List[str]]",
              "decorators": [],
              "is_async": false,
              "line": 216
            },
            {
              "name": "tick_cooldowns",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 270
            },
            {
              "name": "deactivate_adapter",
              "params": [
                "self",
                "adapter_name: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 282
            },
            {
              "name": "get_active_adapters",
              "params": [
                "self"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 294
            },
            {
              "name": "get_suggested_adapters",
              "params": [
                "self",
                "text: str",
                "top_k: int = 3"
              ],
              "return_type": "List[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 298
            }
          ],
          "line": 43
        }
      ],
      "functions": [
        {
          "name": "get_trigger_system",
          "params": [
            "adapter_base_dir: str = '/models/lora_adapters'",
            "force_new: bool = False"
          ],
          "return_type": "AdapterTriggerSystem",
          "decorators": [],
          "is_async": false,
          "line": 332
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_rules_from_adapters",
          "line": 141
        },
        {
          "exception_types": [
            "re.error"
          ],
          "status_code": null,
          "enclosing_function": "check_triggers",
          "line": 191
        }
      ],
      "http_calls": []
    },
    "cognition/agent_core.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "AgentCore",
          "bases": [],
          "docstring": "Encapsulates the core \"Reason-Act-Reflect\" loop for GAIA.\nThis class is UI-agnostic and yields struc",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "ai_manager",
                "ethical_sentinel = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 197
            },
            {
              "name": "_emit_timeline_message",
              "params": [
                "self",
                "session_id: str",
                "role: str",
                "source: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 218
            },
            {
              "name": "_build_output_routing",
              "params": [
                "self",
                "source: str",
                "destination: str",
                "metadata: dict"
              ],
              "return_type": "OutputRouting",
              "decorators": [],
              "is_async": false,
              "line": 230
            },
            {
              "name": "_create_initial_packet",
              "params": [
                "self",
                "user_input: str",
                "session_id: str",
                "history: List[Dict[str, Any]]",
                "selected_model_name: str",
                "source: str = 'cli'",
                "destination: str = 'cli_chat'",
                "metadata: dict = None"
              ],
              "return_type": "CognitionPacket",
              "decorators": [],
              "is_async": false,
              "line": 283
            },
            {
              "name": "_run_pre_generation_safety_check",
              "params": [
                "self",
                "packet: CognitionPacket",
                "assembled_prompt: str"
              ],
              "return_type": "(bool, str)",
              "decorators": [],
              "is_async": false,
              "line": 486
            },
            {
              "name": "run_turn",
              "params": [
                "self",
                "user_input: str",
                "session_id: str",
                "destination: str = 'cli_chat'",
                "source: str = 'cli'",
                "metadata: dict = None"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 601
            },
            {
              "name": "_knowledge_acquisition_workflow",
              "params": [
                "self",
                "packet: CognitionPacket"
              ],
              "return_type": "CognitionPacket",
              "decorators": [],
              "is_async": false,
              "line": 2023
            },
            {
              "name": "_suppress_repetition",
              "params": [
                "self",
                "text: str",
                "max_repeat: int = 2"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 2092
            },
            {
              "name": "_dedup_block",
              "params": [
                "text: str",
                "min_block: int = 120",
                "similarity_threshold: float = 0.85"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 2130
            },
            {
              "name": "_build_response_header",
              "params": [
                "self",
                "model_name: str",
                "packet",
                "observer_instance",
                "active_stream_observer",
                "post_run_observer"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 2180
            },
            {
              "name": "_should_escalate_to_thinker",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 2222
            },
            {
              "name": "_should_use_slim_prompt",
              "params": [
                "self",
                "plan: Plan",
                "user_input: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 2246
            },
            {
              "name": "_run_slim_prompt",
              "params": [
                "self",
                "selected_model_name: str",
                "user_input: str",
                "history: List[Dict[str, Any]]",
                "intent: str = ''",
                "session_id: str = ''",
                "source: str = 'cli'",
                "metadata: dict = None",
                "packet: CognitionPacket = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 2276
            },
            {
              "name": "_build_recitation_search_query",
              "params": [
                "user_input: str"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 2716
            },
            {
              "name": "_validate_recitation_content",
              "params": [
                "self",
                "content: str",
                "user_input: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 2733
            },
            {
              "name": "_web_retrieve_for_recitation",
              "params": [
                "self",
                "user_input: str",
                "session_id: str"
              ],
              "return_type": "Optional[Dict[str, str]]",
              "decorators": [],
              "is_async": false,
              "line": 2751
            },
            {
              "name": "_run_with_document_recitation",
              "params": [
                "self",
                "user_input: str",
                "document: Dict[str, str]",
                "selected_model_name: str",
                "history: List[Dict[str, Any]]",
                "session_id: str = ''",
                "output_as_file: bool = False"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 2849
            },
            {
              "name": "_run_with_fragmentation",
              "params": [
                "self",
                "user_input: str",
                "selected_model_name: str",
                "history: List[Dict[str, Any]]",
                "session_id: str = ''",
                "max_fragments: int = 5",
                "output_as_file: bool = False",
                "output_filename: Optional[str] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 2974
            },
            {
              "name": "_read_fragments_from_sketchpad",
              "params": [
                "self",
                "fragment_keys: List[str]",
                "memory_fallback: Optional[Dict[str, str]] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3160
            },
            {
              "name": "_run_assembly_turn",
              "params": [
                "self",
                "original_request: str",
                "fragment_keys: List[str]",
                "selected_model_name: str",
                "session_id: str = ''",
                "memory_fallback: Optional[Dict[str, str]] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3195
            },
            {
              "name": "_write_assembled_to_file",
              "params": [
                "self",
                "content: str",
                "original_request: str",
                "request_id: str",
                "filename: Optional[str] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3308
            },
            {
              "name": "_assemble_fragments",
              "params": [
                "self",
                "fragments: List[str]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3375
            },
            {
              "name": "_run_mcp_list_tree",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3419
            },
            {
              "name": "_run_mcp_list_files",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3498
            },
            {
              "name": "detect_truncation",
              "params": [
                "self",
                "response: str",
                "max_tokens: int = 1000"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 3543
            },
            {
              "name": "build_continuation_prompt",
              "params": [
                "self",
                "original_request: str",
                "previous_content: str",
                "continuation_hint: str = ''"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 3633
            },
            {
              "name": "assess_task_confidence",
              "params": [
                "self",
                "intent: str",
                "user_input: str",
                "model_name: str = 'lite'",
                "session_id: str = ''"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 3664
            },
            {
              "name": "reflect_on_truncation",
              "params": [
                "self",
                "original_request: str",
                "truncated_output: str",
                "model_name: str = 'lite'"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 3819
            },
            {
              "name": "_check_topic_alignment",
              "params": [
                "self",
                "original_request: str",
                "continuation_prompt: str"
              ],
              "return_type": "tuple",
              "decorators": [],
              "is_async": false,
              "line": 3984
            },
            {
              "name": "_build_grounded_continuation",
              "params": [
                "self",
                "original_request: str",
                "truncated_output: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 4062
            },
            {
              "name": "_find_relevant_files",
              "params": [
                "self",
                "topic: str",
                "max_files: int = 10"
              ],
              "return_type": "List[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 4099
            },
            {
              "name": "_analyze_code_for_topic",
              "params": [
                "self",
                "topic: str",
                "file_paths: List[str]",
                "task_context: Optional[Dict[str, Any]] = None"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 4172
            },
            {
              "name": "_propose_code_fix",
              "params": [
                "self",
                "file_path: str",
                "issue_description: str",
                "suggestion: Optional[str] = None"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 4295
            },
            {
              "name": "_apply_code_fix",
              "params": [
                "self",
                "file_path: str",
                "new_content: str",
                "reason: str",
                "run_syntax_check: bool = True"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 4387
            },
            {
              "name": "_update_dev_matrix_task",
              "params": [
                "self",
                "task_context: Dict[str, Any]",
                "topic: str",
                "fixes_applied: int",
                "files_modified: List[str]",
                "analysis_summary: str"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 4435
            },
            {
              "name": "run_self_improvement",
              "params": [
                "self",
                "topic: str",
                "auto_apply: bool = False",
                "max_files: int = 5"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 4523
            },
            {
              "name": "_run_tool_routing_loop",
              "params": [
                "self",
                "packet: CognitionPacket",
                "user_input: str",
                "session_id: str = ''",
                "source: str = 'cli'",
                "metadata: dict = None"
              ],
              "return_type": "CognitionPacket",
              "decorators": [],
              "is_async": false,
              "line": 4744
            },
            {
              "name": "_execute_mcp_tool",
              "params": [
                "self",
                "tool: SelectedTool"
              ],
              "return_type": "ToolExecutionResult",
              "decorators": [],
              "is_async": false,
              "line": 4992
            },
            {
              "name": "_should_use_tool_routing",
              "params": [
                "self",
                "plan: Plan",
                "user_input: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 5078
            }
          ],
          "line": 190
        }
      ],
      "functions": [
        {
          "name": "_format_retrieved_session_context",
          "params": [
            "results: dict"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 78
        },
        {
          "name": "find_recitable_document",
          "params": [
            "user_input: str"
          ],
          "return_type": "Optional[Dict[str, str]]",
          "decorators": [],
          "is_async": false,
          "line": 139
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "HISTORY_SUMMARY_THRESHOLD",
          "value": "20",
          "line": 62
        },
        {
          "name": "MAX_OUTPUT_LENGTH",
          "value": "500",
          "line": 63
        }
      ],
      "gaia_imports": [
        "from gaia_core.memory.semantic_codex import SemanticCodex",
        "from gaia_core.memory.codex_writer import CodexWriter",
        "from gaia_core.cognition.external_voice import ExternalVoice",
        "from gaia_core.cognition.self_reflection import run_self_reflection, reflect_and_refine",
        "from gaia_core.cognition.cognitive_audit import run_cognitive_self_audit",
        "from gaia_core.cognition.history_review import review_history",
        "from gaia_core.utils.prompt_builder import build_from_packet",
        "from gaia_core.utils.output_router import route_output, _strip_think_tags_robust",
        "from gaia_core.utils.stream_observer import StreamObserver, Interrupt",
        "from gaia_core.utils import mcp_client",
        "from gaia_core.config import Config, get_config",
        "from gaia_common.utils.thoughtstream import write",
        "from gaia_core.behavior.persona_switcher import get_persona_for_request, get_persona_for_knowledge_base",
        "from gaia_core.cognition.semantic_probe import run_semantic_probe, get_session_probe_stats",
        "from gaia_core.cognition.cognitive_dispatcher import process_execution_results",
        "from gaia_core.cognition.knowledge_enhancer import enhance_packet",
        "from gaia_core.cognition.knowledge_ingestion import run_explicit_save, run_auto_detect, run_update_detect",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Header, Persona, Routing, Model, Intent, Context, Content, Reasoning, Response, Governance, Safety, Metrics, TokenUsage, Status, PersonaRole, Origin, TargetEngine, SystemTask, PacketState, DataField, ReflectionLog, RelevantHistorySnippet, SessionHistoryRef, Cheatsheet, Constraints, ToolRoutingState, ToolExecutionStatus, SelectedTool, ToolExecutionResult, OutputDestination, OutputRouting, DestinationTarget",
        "from gaia_core.cognition.nlu.intent_detection import detect_intent, Plan",
        "from gaia_core.utils import gaia_rescue_helper",
        "from gaia_core.cognition.loop_recovery import LoopRecoveryManager, get_recovery_manager, build_loop_detection_config_from_constants, LoopInterrupt",
        "from gaia_core.cognition.loop_detector import LoopDetectorConfig"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 207
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 316
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 379
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 424
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 462
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 597
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 633
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 642
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 692
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 838
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 872
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 886
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 992
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1151
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1170
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1199
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1230
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1300
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1312
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1334
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1450
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1457
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_knowledge_acquisition_workflow",
          "line": 2087
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_suppress_repetition",
          "line": 2113
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_response_header",
          "line": 2207
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2707
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_web_retrieve_for_recitation",
          "line": 2845
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_document_recitation",
          "line": 2912
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_document_recitation",
          "line": 2960
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_fragmentation",
          "line": 3143
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_assembly_turn",
          "line": 3303
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "assess_task_confidence",
          "line": 3810
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_on_truncation",
          "line": 3974
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_find_relevant_files",
          "line": 4168
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_analyze_code_for_topic",
          "line": 4286
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_propose_code_fix",
          "line": 4315
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_propose_code_fix",
          "line": 4383
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "_apply_code_fix",
          "line": 4409
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_apply_code_fix",
          "line": 4431
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_update_dev_matrix_task",
          "line": 4519
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_self_improvement",
          "line": 4583
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4967
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_execute_mcp_tool",
          "line": 5070
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_timeline_message",
          "line": 227
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 418
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_initial_packet",
          "line": 448
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 502
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 653
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 783
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1192
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1325
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1363
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1384
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1406
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1426
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1433
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1501
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1509
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1519
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1642
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1862
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1875
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1980
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1989
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 2019
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2299
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2313
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2327
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2406
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2494
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2529
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2614
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2661
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2704
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_fragmentation",
          "line": 3061
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_fragmentation",
          "line": 3074
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_with_fragmentation",
          "line": 3091
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_read_fragments_from_sketchpad",
          "line": 3191
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_assembly_turn",
          "line": 3242
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "assess_task_confidence",
          "line": 3733
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_analyze_code_for_topic",
          "line": 4205
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4807
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4865
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4964
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 511
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 528
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 538
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 571
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 587
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 868
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1027
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1350
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1357
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1400
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1439
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1782
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1821
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1837
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1969
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 2017
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2577
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2594
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2645
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_web_retrieve_for_recitation",
          "line": 2838
        },
        {
          "exception_types": [
            "subprocess.TimeoutExpired"
          ],
          "status_code": null,
          "enclosing_function": "_find_relevant_files",
          "line": 4159
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_find_relevant_files",
          "line": 4161
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_self_improvement",
          "line": 4708
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4826
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4984
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 578
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 806
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1412
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1686
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_handle_tree_result",
          "line": 3446
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_tool_routing_loop",
          "line": 4880
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "find_recitable_document",
          "line": 181
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 521
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 554
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_handle_tree_result",
          "line": 3456
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 832
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1613
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2443
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_pre_generation_safety_check",
          "line": 525
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_slim_prompt",
          "line": 2482
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_turn",
          "line": 1673
        }
      ],
      "http_calls": []
    },
    "cognition/cognition_packet_v0.2_backup.py": {
      "module_docstring": "CognitionPacket  dynamic state for GAIAs self-reflection loop.\n\nSchema:\n  prompt:         str            # original user prompt\n  persona:        str            # active persona ID\n  identity:      ",
      "classes": [
        {
          "name": "CognitionPacket",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "session_id: str",
                "packet_id: str",
                "time_date: str",
                "packet_type: str",
                "intent: str",
                "intent_confidence: float",
                "identity: str",
                "persona: str",
                "contextual_instructions: str",
                "prompt: str",
                "history: List[Dict[str, Any]]",
                "reflection: str",
                "reflection_confidence: float",
                "execution: str",
                "execution_confidence: float",
                "response: str",
                "response_confidence: float",
                "data_fields: Dict[str, Any]",
                "sub_packet_id: str = None",
                "config: Config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 25
            },
            {
              "name": "to_json",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 68
            },
            {
              "name": "from_json",
              "params": [
                "data: str | Dict"
              ],
              "return_type": "CognitionPacket",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 77
            }
          ],
          "line": 24
        }
      ],
      "functions": [
        {
          "name": "create_packet",
          "params": [
            "config: Config",
            "prompt: str",
            "session_id: str",
            "history: List[Dict[str, Any]]",
            "persona_instructions: List[str]"
          ],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 83
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/cognitive_audit.py": {
      "module_docstring": "Cognitive Self-Audit  Phase 1 of Reflective Self-Talk\n\nInserts a structured self-assessment between planning and reflection.\nThe model reads its own plan + packet state and writes evaluations,\nsketch",
      "classes": [],
      "functions": [
        {
          "name": "_build_audit_context",
          "params": [
            "packet: CognitionPacket"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 47
        },
        {
          "name": "_parse_audit_output",
          "params": [
            "text: str",
            "packet: CognitionPacket"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 91
        },
        {
          "name": "run_cognitive_self_audit",
          "params": [
            "packet: CognitionPacket",
            "plan_text: str",
            "config",
            "llm"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 129
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Evaluation, ReflectionLog, Sketchpad",
        "from gaia_common.utils.thoughtstream import write",
        "from gaia_core.utils.prompt_builder import build_from_packet"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_audit_context",
          "line": 60
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_audit_context",
          "line": 69
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_audit_context",
          "line": 78
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_audit_context",
          "line": 85
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_cognitive_self_audit",
          "line": 218
        }
      ],
      "http_calls": []
    },
    "cognition/cognitive_dispatcher.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "process_execution_results",
          "params": [
            "execution_results",
            "session_manager",
            "session_id",
            "packet: CognitionPacket"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 6
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols import CognitionPacket"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/conversation_curator.py": {
      "module_docstring": "Auto-append notable Discord conversations to the knowledge examples file.\n\nHooks into SessionManager.summarize_and_archive() to evaluate each archived\nconversation for \"notability\" using simple heuris",
      "classes": [
        {
          "name": "ConversationCurator",
          "bases": [],
          "docstring": "Evaluates archived conversations and appends notable ones to the examples file.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "output_dir: Optional[str] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 45
            },
            {
              "name": "curate",
              "params": [
                "self",
                "session_id: str",
                "messages: List[Dict]"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 49
            },
            {
              "name": "is_notable",
              "params": [
                "self",
                "messages: List[Dict]"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 72
            },
            {
              "name": "_detect_channel_type",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 94
            },
            {
              "name": "_format_conversation",
              "params": [
                "self",
                "session_id: str",
                "messages: List[Dict]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 97
            },
            {
              "name": "_append_to_file",
              "params": [
                "self",
                "formatted: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 112
            },
            {
              "name": "_trim_oldest",
              "params": [
                "self",
                "needed_bytes: int"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 130
            }
          ],
          "line": 38
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_trim_oldest",
          "line": 160
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_trim_oldest",
          "line": 164
        }
      ],
      "http_calls": []
    },
    "cognition/external_voice.py": {
      "module_docstring": "external_voice.py  handles all inbound/outbound chat traffic for GAIA\n(streaming, observer hooks, basic logging).  This module is the *sole*\nentry and exit for chat-based interactions.",
      "classes": [
        {
          "name": "ExternalVoice",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model",
                "model_pool",
                "config: Config",
                "thought: Optional[str] = None",
                "messages: Optional[List[Dict]] = None",
                "context: Optional[Dict] = None",
                "session_id: str = 'shell'",
                "source: str = 'web'",
                "observer: Optional[StreamObserver] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 70
            },
            {
              "name": "stream_response",
              "params": [
                "self",
                "user_input: Optional[str] = None"
              ],
              "return_type": "Generator[str | Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 133
            },
            {
              "name": "generate_full_response",
              "params": [
                "self",
                "user_input: Optional[str] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 432
            },
            {
              "name": "from_thought",
              "params": [
                "cls",
                "model",
                "thought: str",
                "**kw"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 442
            },
            {
              "name": "from_messages",
              "params": [
                "cls",
                "model",
                "messages: List[Dict]",
                "**kw"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 446
            },
            {
              "name": "one_shot",
              "params": [
                "cls",
                "model",
                "prompt: str",
                "**kw"
              ],
              "return_type": "str",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 450
            },
            {
              "name": "_apply_stream_spacing",
              "params": [
                "self",
                "token: str",
                "prev_char: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 462
            },
            {
              "name": "_get_first_visible_char",
              "params": [
                "text: str"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 472
            },
            {
              "name": "_get_last_visible_char",
              "params": [
                "text: str"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 480
            }
          ],
          "line": 69
        }
      ],
      "functions": [
        {
          "name": "suppress_llama_stderr",
          "params": [],
          "return_type": "Generator[None, None, None]",
          "decorators": [
            "contextlib.contextmanager"
          ],
          "is_async": false,
          "line": 50
        },
        {
          "name": "extract_and_format_execute_blocks",
          "params": [
            "response_text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 487
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config",
        "from gaia_core.utils.prompt_builder import build_prompt",
        "from gaia_core.utils.stream_observer import StreamObserver, Interrupt",
        "from gaia_core.cognition.self_reflection import reflect_and_refine",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, PacketState, ReflectionLog"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 34
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 98
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 102
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 107
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 143
        },
        {
          "exception_types": [
            "StopIteration"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 423
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 425
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 127
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 158
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 164
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 168
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 177
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 246
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 317
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 305
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 219
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 250
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 224
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 419
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 297
        },
        {
          "exception_types": [
            "concurrent.futures.TimeoutError"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 342
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 346
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 366
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 382
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 404
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 402
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 395
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stream_response",
          "line": 400
        }
      ],
      "http_calls": []
    },
    "cognition/goal_detector.py": {
      "module_docstring": "Goal Detection Module  detects and carries user goals across conversation turns.\n\nThree detection paths:\n  1. Fast-path  self-evident intents map directly to a goal\n  2. Session-carry  active goal ",
      "classes": [
        {
          "name": "GoalDetector",
          "bases": [],
          "docstring": "Detects and manages user goals across conversation turns.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 55
            },
            {
              "name": "detect",
              "params": [
                "self",
                "packet: CognitionPacket",
                "session_manager",
                "session_id: str",
                "model_pool = None"
              ],
              "return_type": "GoalState",
              "decorators": [],
              "is_async": false,
              "line": 58
            },
            {
              "name": "_fast_path_detect",
              "params": [
                "self",
                "intent: str",
                "user_input: str"
              ],
              "return_type": "Optional[DetectedGoal]",
              "decorators": [],
              "is_async": false,
              "line": 99
            },
            {
              "name": "_session_carry",
              "params": [
                "self",
                "session_manager",
                "session_id: str"
              ],
              "return_type": "Optional[GoalState]",
              "decorators": [],
              "is_async": false,
              "line": 115
            },
            {
              "name": "_llm_detect",
              "params": [
                "self",
                "packet: CognitionPacket",
                "model_pool"
              ],
              "return_type": "Optional[DetectedGoal]",
              "decorators": [],
              "is_async": false,
              "line": 158
            },
            {
              "name": "_parse_llm_response",
              "params": [
                "text: str"
              ],
              "return_type": "Optional[DetectedGoal]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 194
            },
            {
              "name": "handle_goal_shift",
              "params": [
                "new_goal_desc: str",
                "packet: CognitionPacket",
                "session_manager",
                "session_id: str"
              ],
              "return_type": null,
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 218
            },
            {
              "name": "_persist_goal",
              "params": [
                "self",
                "session_manager",
                "session_id: str",
                "state: GoalState"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 259
            },
            {
              "name": "_persist_goal_static",
              "params": [
                "session_manager",
                "session_id: str",
                "state: GoalState"
              ],
              "return_type": null,
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 264
            }
          ],
          "line": 52
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "MAX_CARRY_TURNS",
          "value": "8",
          "line": 26
        }
      ],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, DetectedGoal, GoalConfidence, GoalState"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_llm_detect",
          "line": 165
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_llm_detect",
          "line": 189
        }
      ],
      "http_calls": []
    },
    "cognition/heartbeat.py": {
      "module_docstring": "Thought Seed Heartbeat  regular-interval daemon that triages dormant seeds.\n\nRuns independently of the sleep cycle on a configurable timer (default 20 min).\nFor each unreviewed seed, Lite performs a ",
      "classes": [
        {
          "name": "ThoughtSeedHeartbeat",
          "bases": [],
          "docstring": "Daemon thread that triages thought seeds on a regular interval.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "agent_core = None",
                "sleep_wake_manager = None",
                "timeline_store = None",
                "session_manager = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 52
            },
            {
              "name": "start",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 127
            },
            {
              "name": "stop",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 137
            },
            {
              "name": "_run",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 148
            },
            {
              "name": "_tick",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 162
            },
            {
              "name": "_run_temporal_tasks",
              "params": [
                "self"
              ],
              "return_type": "tuple[bool, bool, bool]",
              "decorators": [],
              "is_async": false,
              "line": 236
            },
            {
              "name": "_triage_seed",
              "params": [
                "self",
                "llm",
                "seed_data: Dict[str, Any]"
              ],
              "return_type": "tuple[str, str]",
              "decorators": [],
              "is_async": false,
              "line": 299
            },
            {
              "name": "_do_archive",
              "params": [
                "self",
                "filename: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 341
            },
            {
              "name": "_do_defer",
              "params": [
                "self",
                "filename: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 345
            },
            {
              "name": "_act_on_seed",
              "params": [
                "self",
                "llm",
                "seed_filename: str",
                "seed_data: Dict[str, Any]"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 355
            },
            {
              "name": "_expand_seed",
              "params": [
                "self",
                "llm",
                "seed_data: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 397
            },
            {
              "name": "_ensure_active",
              "params": [
                "self",
                "seed_filename: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 421
            },
            {
              "name": "_emit_heartbeat_tick",
              "params": [
                "self",
                "seeds_found: int",
                "archived: int",
                "deferred: int",
                "acted: int",
                "journal_written: bool = False",
                "state_baked: bool = False",
                "interview_conducted: bool = False"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 469
            }
          ],
          "line": 49
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "HEARTBEAT_SESSION_ID",
          "value": "'gaia_heartbeat_session'",
          "line": 26
        }
      ],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_triage_seed",
          "line": 333
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_act_on_seed",
          "line": 390
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_expand_seed",
          "line": 417
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 89
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 102
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 120
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run",
          "line": 154
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_tick",
          "line": 192
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_tick",
          "line": 214
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_temporal_tasks",
          "line": 254
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_temporal_tasks",
          "line": 265
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_heartbeat_tick",
          "line": 486
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_temporal_tasks",
          "line": 278
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_temporal_tasks",
          "line": 290
        }
      ],
      "http_calls": []
    },
    "cognition/history_review.py": {
      "module_docstring": "History Review  Pre-injection audit of conversation history.\n\nBefore history is injected into the LLM prompt, each assistant message\nis checked for epistemic violations:\n  - Fabricated file paths (ci",
      "classes": [],
      "functions": [
        {
          "name": "_count_violations",
          "params": [
            "text: str"
          ],
          "return_type": "Tuple[int, List[str]]",
          "decorators": [],
          "is_async": false,
          "line": 74
        },
        {
          "name": "_is_user_correction",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 109
        },
        {
          "name": "_redact_message",
          "params": [
            "original: str",
            "reasons: List[str]"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 114
        },
        {
          "name": "_build_correction_summary",
          "params": [
            "user_msg: str",
            "assistant_msg: str",
            "reasons: List[str]"
          ],
          "return_type": "Optional[str]",
          "decorators": [],
          "is_async": false,
          "line": 123
        },
        {
          "name": "review_history",
          "params": [
            "history: List[Dict[str, str]]",
            "config: Optional[dict] = None",
            "session_id: str = ''"
          ],
          "return_type": "List[Dict[str, str]]",
          "decorators": [],
          "is_async": false,
          "line": 147
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/initiative_engine.py": {
      "module_docstring": "Initiative Engine  ported from archive/gaia-assistant-monolith/run_gil.py.\n\nExecutes a single autonomous thought cycle: picks the highest-priority topic\nfrom the topic cache and feeds a self-generate",
      "classes": [
        {
          "name": "InitiativeEngine",
          "bases": [],
          "docstring": "Autonomous thought engine driven by the topic manager.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "agent_core = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 26
            },
            {
              "name": "execute_turn",
              "params": [
                "self"
              ],
              "return_type": "Optional[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 30
            },
            {
              "name": "_build_self_prompt",
              "params": [
                "topic: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 74
            }
          ],
          "line": 23
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "GIL_SESSION_ID",
          "value": "'gaia_initiative_loop_session'",
          "line": 19
        },
        {
          "name": "TOPIC_CACHE_PATH",
          "value": "'/knowledge/system_reference/topic_cache.json'",
          "line": 20
        }
      ],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "execute_turn",
          "line": 69
        }
      ],
      "http_calls": []
    },
    "cognition/knowledge_enhancer.py": {
      "module_docstring": "This module is responsible for enhancing the CognitionPacket with relevant knowledge from knowledge bases.",
      "classes": [],
      "functions": [
        {
          "name": "enhance_packet",
          "params": [
            "packet: CognitionPacket"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 18
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, DataField",
        "from gaia_core.utils import mcp_client"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "enhance_packet",
          "line": 92
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "enhance_packet",
          "line": 66
        }
      ],
      "http_calls": []
    },
    "cognition/knowledge_ingestion.py": {
      "module_docstring": "Knowledge Ingestion Pipeline for D&D Campaign Content\n\nDetects incoming knowledge dumps (explicit save commands or heuristic auto-detect),\nclassifies content, checks for duplicates, formats as structu",
      "classes": [],
      "functions": [
        {
          "name": "detect_save_command",
          "params": [
            "user_input: str"
          ],
          "return_type": "Optional[Dict[str, str]]",
          "decorators": [],
          "is_async": false,
          "line": 81
        },
        {
          "name": "detect_knowledge_dump",
          "params": [
            "user_input: str",
            "kb_name: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 114
        },
        {
          "name": "classify_content",
          "params": [
            "text: str"
          ],
          "return_type": "Dict[str, str]",
          "decorators": [],
          "is_async": false,
          "line": 161
        },
        {
          "name": "check_dedup",
          "params": [
            "content: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 210
        },
        {
          "name": "_sanitize_filename",
          "params": [
            "text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 243
        },
        {
          "name": "format_document",
          "params": [
            "content: str",
            "classification: Dict[str, str]",
            "subject: str = ''"
          ],
          "return_type": "Tuple[str, str]",
          "decorators": [],
          "is_async": false,
          "line": 247
        },
        {
          "name": "write_and_embed",
          "params": [
            "filename: str",
            "doc_content: str",
            "kb_name: str"
          ],
          "return_type": "Dict[str, object]",
          "decorators": [],
          "is_async": false,
          "line": 290
        },
        {
          "name": "run_explicit_save",
          "params": [
            "user_input: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 338
        },
        {
          "name": "run_auto_detect",
          "params": [
            "user_input: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 373
        },
        {
          "name": "detect_knowledge_update",
          "params": [
            "user_input: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict[str, str]]",
          "decorators": [],
          "is_async": false,
          "line": 434
        },
        {
          "name": "retrieve_entity_document",
          "params": [
            "entity: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 473
        },
        {
          "name": "run_update_detect",
          "params": [
            "user_input: str",
            "kb_name: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 510
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.utils import mcp_client"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "check_dedup",
          "line": 234
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "retrieve_entity_document",
          "line": 505
        }
      ],
      "http_calls": []
    },
    "cognition/lite_journal.py": {
      "module_docstring": "Lite Cognitive Journal  running introspective log written by the Lite model.\n\nMirrors the PrimeCheckpointManager pattern: regular writes, timestamped entries,\nrotation to history directory when the j",
      "classes": [
        {
          "name": "LiteJournal",
          "bases": [],
          "docstring": "Manages Lite's introspective journal (Lite.md).",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "timeline_store = None",
                "sleep_wake_manager = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 52
            },
            {
              "name": "write_entry",
              "params": [
                "self"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 83
            },
            {
              "name": "load_latest",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 111
            },
            {
              "name": "load_recent_entries",
              "params": [
                "self",
                "n: int = 5"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 121
            },
            {
              "name": "rotate",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 134
            },
            {
              "name": "get_entry_count",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 157
            },
            {
              "name": "_generate_entry",
              "params": [
                "self",
                "llm"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 166
            },
            {
              "name": "_build_journal_prompt",
              "params": [
                "self"
              ],
              "return_type": "tuple[str, str]",
              "decorators": [],
              "is_async": false,
              "line": 185
            },
            {
              "name": "_append_entry",
              "params": [
                "self",
                "entry_text: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 241
            },
            {
              "name": "_format_duration",
              "params": [
                "seconds: float"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 279
            },
            {
              "name": "_summarize_event",
              "params": [
                "data: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 293
            }
          ],
          "line": 45
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.temporal_state_manager import _LITE_LOCK"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 76
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "write_entry",
          "line": 107
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "load_latest",
          "line": 117
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "rotate",
          "line": 154
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_generate_entry",
          "line": 181
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "write_entry",
          "line": 92
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_journal_prompt",
          "line": 199
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_journal_prompt",
          "line": 215
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_journal_prompt",
          "line": 226
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_append_entry",
          "line": 255
        }
      ],
      "http_calls": []
    },
    "cognition/loop_detector.py": {
      "module_docstring": "Loop Detection System for GAIA Cognitive Pipeline.\n\nDetects when the model enters generation loops and provides signals for\ngraceful recovery. Uses multiple parallel detectors that vote on loop presen",
      "classes": [
        {
          "name": "LoopDetectorConfig",
          "bases": [],
          "docstring": "Configuration for loop detection thresholds.",
          "methods": [],
          "line": 63
        },
        {
          "name": "DetectionResult",
          "bases": [],
          "docstring": "Result from a single detector.",
          "methods": [],
          "line": 93
        },
        {
          "name": "AggregatedResult",
          "bases": [],
          "docstring": "Combined result from all detectors.",
          "methods": [],
          "line": 103
        },
        {
          "name": "ToolCallRecord",
          "bases": [],
          "docstring": "Record of a single tool call for tracking.",
          "methods": [],
          "line": 116
        },
        {
          "name": "ErrorRecord",
          "bases": [],
          "docstring": "Record of an error for tracking.",
          "methods": [],
          "line": 126
        },
        {
          "name": "ToolCallRepetitionDetector",
          "bases": [],
          "docstring": "Detects repeated tool calls with same/similar arguments.\n\nCatches:\n- Exact repetition: Same tool + a",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 151
            },
            {
              "name": "record",
              "params": [
                "self",
                "tool: str",
                "args: Dict[str, Any]",
                "result: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 155
            },
            {
              "name": "detect",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 169
            },
            {
              "name": "_detect_exact_repetition",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 201
            },
            {
              "name": "_detect_ping_pong",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 237
            },
            {
              "name": "_detect_same_results",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 275
            },
            {
              "name": "_hash_args",
              "params": [
                "self",
                "args: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 306
            },
            {
              "name": "_summarize_args",
              "params": [
                "self",
                "args: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 312
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 330
            }
          ],
          "line": 140
        },
        {
          "name": "OutputSimilarityDetector",
          "bases": [],
          "docstring": "Detects nearly identical outputs across turns.\n\nUses multi-strategy similarity:\n- Jaccard on word se",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 345
            },
            {
              "name": "record",
              "params": [
                "self",
                "output: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 350
            },
            {
              "name": "detect",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 356
            },
            {
              "name": "_similarity",
              "params": [
                "self",
                "a: str",
                "b: str"
              ],
              "return_type": "float",
              "decorators": [],
              "is_async": false,
              "line": 402
            },
            {
              "name": "_ngram_similarity",
              "params": [
                "self",
                "a: str",
                "b: str",
                "n: int = 3"
              ],
              "return_type": "float",
              "decorators": [],
              "is_async": false,
              "line": 425
            },
            {
              "name": "_structural_similarity",
              "params": [
                "self",
                "a: str",
                "b: str"
              ],
              "return_type": "float",
              "decorators": [],
              "is_async": false,
              "line": 441
            },
            {
              "name": "_normalize",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 468
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 485
            }
          ],
          "line": 335
        },
        {
          "name": "StateOscillationDetector",
          "bases": [],
          "docstring": "Detects oscillating states without progress.\n\nTracks:\n- Goal changes\n- File modification patterns\n- ",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 501
            },
            {
              "name": "record",
              "params": [
                "self",
                "goal: str = ''",
                "modified_files: Optional[Set[str]] = None",
                "state_snapshot: Optional[Dict[str, Any]] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 507
            },
            {
              "name": "detect",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 520
            },
            {
              "name": "_detect_goal_oscillation",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 551
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 577
            }
          ],
          "line": 491
        },
        {
          "name": "ErrorCycleDetector",
          "bases": [],
          "docstring": "Detects recurring error patterns.\n\nCatches:\n- Same error repeated\n- Same fix attempted multiple time",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 594
            },
            {
              "name": "record",
              "params": [
                "self",
                "error_type: str",
                "error_message: str",
                "attempted_fix: str = ''",
                "was_success: bool = False"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 598
            },
            {
              "name": "detect",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 619
            },
            {
              "name": "_detect_fix_repetition",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 664
            },
            {
              "name": "_detect_whack_a_mole",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 700
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 733
            }
          ],
          "line": 584
        },
        {
          "name": "TokenPatternDetector",
          "bases": [],
          "docstring": "Detects repetitive patterns during token streaming.\n\nCatches:\n- Exact phrase repetition (\"I'll help.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 748
            },
            {
              "name": "add_tokens",
              "params": [
                "self",
                "tokens: str"
              ],
              "return_type": "Optional[DetectionResult]",
              "decorators": [],
              "is_async": false,
              "line": 753
            },
            {
              "name": "detect",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 769
            },
            {
              "name": "_detect_phrase_repetition",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 791
            },
            {
              "name": "_detect_word_repetition",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 826
            },
            {
              "name": "_detect_structural_repetition",
              "params": [
                "self"
              ],
              "return_type": "DetectionResult",
              "decorators": [],
              "is_async": false,
              "line": 860
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 899
            }
          ],
          "line": 738
        },
        {
          "name": "LoopDetectionAggregator",
          "bases": [],
          "docstring": "Combines signals from all detectors to determine if a loop is occurring.\n\nTriggering rules:\n1. Any s",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: LoopDetectorConfig"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 927
            },
            {
              "name": "evaluate",
              "params": [
                "self"
              ],
              "return_type": "AggregatedResult",
              "decorators": [],
              "is_async": false,
              "line": 940
            },
            {
              "name": "_should_warn",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 1031
            },
            {
              "name": "mark_warned",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1041
            },
            {
              "name": "mark_reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1045
            },
            {
              "name": "record_tool_call",
              "params": [
                "self",
                "tool: str",
                "args: Dict[str, Any]",
                "result: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1052
            },
            {
              "name": "record_output",
              "params": [
                "self",
                "output: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1056
            },
            {
              "name": "record_state",
              "params": [
                "self",
                "goal: str = ''",
                "modified_files: Optional[Set[str]] = None",
                "state_snapshot: Optional[Dict[str, Any]] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1060
            },
            {
              "name": "record_error",
              "params": [
                "self",
                "error_type: str",
                "error_message: str",
                "attempted_fix: str = ''",
                "was_success: bool = False"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1065
            },
            {
              "name": "add_tokens",
              "params": [
                "self",
                "tokens: str"
              ],
              "return_type": "Optional[DetectionResult]",
              "decorators": [],
              "is_async": false,
              "line": 1070
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1074
            }
          ],
          "line": 908
        },
        {
          "name": "LoopDetector",
          "bases": [],
          "docstring": "Main interface for loop detection in GAIA cognitive pipeline.\n\nUsage:\n    detector = LoopDetector.ge",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Optional[LoopDetectorConfig] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 1113
            },
            {
              "name": "get_instance",
              "params": [
                "cls",
                "config: Optional[LoopDetectorConfig] = None"
              ],
              "return_type": "LoopDetector",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 1119
            },
            {
              "name": "reset_instance",
              "params": [
                "cls"
              ],
              "return_type": "None",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 1126
            },
            {
              "name": "enabled",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 1131
            },
            {
              "name": "enabled",
              "params": [
                "self",
                "value: bool"
              ],
              "return_type": "None",
              "decorators": [
                "enabled.setter"
              ],
              "is_async": false,
              "line": 1135
            },
            {
              "name": "reset_count",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 1140
            },
            {
              "name": "record_tool_call",
              "params": [
                "self",
                "tool: str",
                "args: Dict[str, Any]",
                "result: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1143
            },
            {
              "name": "record_output",
              "params": [
                "self",
                "output: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1148
            },
            {
              "name": "record_state",
              "params": [
                "self",
                "goal: str = ''",
                "modified_files: Optional[Set[str]] = None",
                "state_snapshot: Optional[Dict[str, Any]] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1153
            },
            {
              "name": "record_error",
              "params": [
                "self",
                "error_type: str",
                "error_message: str",
                "attempted_fix: str = ''",
                "was_success: bool = False"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1159
            },
            {
              "name": "add_tokens",
              "params": [
                "self",
                "tokens: str"
              ],
              "return_type": "Optional[DetectionResult]",
              "decorators": [],
              "is_async": false,
              "line": 1165
            },
            {
              "name": "check",
              "params": [
                "self"
              ],
              "return_type": "AggregatedResult",
              "decorators": [],
              "is_async": false,
              "line": 1171
            },
            {
              "name": "mark_warned",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1184
            },
            {
              "name": "trigger_reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1189
            },
            {
              "name": "reset_detectors",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1194
            },
            {
              "name": "full_reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1199
            }
          ],
          "line": 1089
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [
        {
          "name": "LoopCategory",
          "members": [
            [
              "TOOL_REPETITION",
              "'tool_repetition'"
            ],
            [
              "TOOL_PING_PONG",
              "'tool_ping_pong'"
            ],
            [
              "TOOL_PARAMETER_DRIFT",
              "'tool_parameter_drift'"
            ],
            [
              "OUTPUT_VERBATIM",
              "'output_verbatim'"
            ],
            [
              "OUTPUT_PARAPHRASE",
              "'output_paraphrase'"
            ],
            [
              "OUTPUT_STRUCTURAL",
              "'output_structural'"
            ],
            [
              "STATE_OSCILLATION",
              "'state_oscillation'"
            ],
            [
              "STATE_REGRESSION",
              "'state_regression'"
            ],
            [
              "GOAL_DRIFT",
              "'goal_drift'"
            ],
            [
              "ERROR_REPETITION",
              "'error_repetition'"
            ],
            [
              "ERROR_WHACK_A_MOLE",
              "'error_whack_a_mole'"
            ],
            [
              "FIX_REPETITION",
              "'fix_repetition'"
            ],
            [
              "TOKEN_REPETITION",
              "'token_repetition'"
            ],
            [
              "PHRASE_LOOP",
              "'phrase_loop'"
            ],
            [
              "STRUCTURAL_LOOP",
              "'structural_loop'"
            ]
          ],
          "line": 34
        }
      ],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/loop_patterns.py": {
      "module_docstring": "Loop Pattern Classification and Description System.\n\nGenerates human-readable descriptions of detected loops for:\n1. Brief - Status line / notifications (~50 chars)\n2. Summary - User-facing display (2",
      "classes": [
        {
          "name": "DescriptionTemplate",
          "bases": [],
          "docstring": "Template for loop description at different verbosity levels.",
          "methods": [],
          "line": 31
        },
        {
          "name": "ClassifiedPattern",
          "bases": [],
          "docstring": "A classified loop pattern with description.",
          "methods": [],
          "line": 41
        },
        {
          "name": "PatternClassifier",
          "bases": [],
          "docstring": "Classifies detected loops into specific pattern types and generates\nhuman-readable descriptions.",
          "methods": [
            {
              "name": "classify",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 60
            },
            {
              "name": "_classify_tool_pattern",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 91
            },
            {
              "name": "_classify_output_pattern",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 183
            },
            {
              "name": "_classify_state_pattern",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 267
            },
            {
              "name": "_classify_error_pattern",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 353
            },
            {
              "name": "_classify_token_pattern",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 490
            },
            {
              "name": "_classify_generic",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "ClassifiedPattern",
              "decorators": [],
              "is_async": false,
              "line": 612
            },
            {
              "name": "_build_full_template",
              "params": [
                "self",
                "title: str",
                "pattern: str",
                "details: List[str]",
                "what_went_wrong: str",
                "suggestions: List[str]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 651
            }
          ],
          "line": 54
        },
        {
          "name": "PatternRenderer",
          "bases": [],
          "docstring": "Renders classified patterns at different verbosity levels.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 686
            },
            {
              "name": "render",
              "params": [
                "self",
                "result: AggregatedResult",
                "format: str = 'summary'",
                "reset_count: int = 0"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 689
            },
            {
              "name": "_render_model_context",
              "params": [
                "self",
                "classified: ClassifiedPattern",
                "reset_count: int"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 723
            },
            {
              "name": "_get_urgency",
              "params": [
                "self",
                "reset_count: int"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 758
            },
            {
              "name": "get_notification",
              "params": [
                "self",
                "result: AggregatedResult",
                "reset_count: int = 0"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 769
            },
            {
              "name": "_get_override_warning",
              "params": [
                "self",
                "reset_count: int"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 806
            }
          ],
          "line": 681
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.loop_detector import LoopCategory, AggregatedResult, DetectionResult"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/loop_recovery.py": {
      "module_docstring": "Loop Recovery System for GAIA Cognitive Pipeline.\n\nOrchestrates the reset flow when a loop is detected:\n1. Capture current packet state\n2. Inject recovery context into next prompt\n3. Manage escalation",
      "classes": [
        {
          "name": "LoopMetadata",
          "bases": [],
          "docstring": "Metadata about a detected loop, attached to packets for context.",
          "methods": [
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 50
            },
            {
              "name": "from_dict",
              "params": [
                "cls",
                "data: Dict[str, Any]"
              ],
              "return_type": "LoopMetadata",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 65
            }
          ],
          "line": 36
        },
        {
          "name": "CapturedState",
          "bases": [],
          "docstring": "Captured state before reset for context preservation.",
          "methods": [
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 94
            }
          ],
          "line": 81
        },
        {
          "name": "LoopRecoveryManager",
          "bases": [],
          "docstring": "Manages the loop detection and recovery lifecycle.\n\nResponsibilities:\n- Coordinate detection checks\n",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Optional[LoopDetectorConfig] = None",
                "on_warn: Optional[Callable[[AggregatedResult], None]] = None",
                "on_block: Optional[Callable[[AggregatedResult], None]] = None",
                "on_escalate: Optional[Callable[[int], None]] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 124
            },
            {
              "name": "enabled",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 156
            },
            {
              "name": "enabled",
              "params": [
                "self",
                "value: bool"
              ],
              "return_type": "None",
              "decorators": [
                "enabled.setter"
              ],
              "is_async": false,
              "line": 160
            },
            {
              "name": "reset_count",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 164
            },
            {
              "name": "check_and_handle",
              "params": [
                "self",
                "session_id: str = ''",
                "packet_id: str = ''",
                "goal: str = ''",
                "last_output: str = ''"
              ],
              "return_type": "Optional[AggregatedResult]",
              "decorators": [],
              "is_async": false,
              "line": 167
            },
            {
              "name": "_capture_state",
              "params": [
                "self",
                "session_id: str",
                "packet_id: str",
                "goal: str",
                "last_output: str",
                "result: AggregatedResult"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 231
            },
            {
              "name": "_prepare_recovery_context",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 275
            },
            {
              "name": "get_recovery_context",
              "params": [
                "self"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 286
            },
            {
              "name": "clear_recovery_context",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 295
            },
            {
              "name": "_mark_recovery_success",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 299
            },
            {
              "name": "override_detection",
              "params": [
                "self",
                "duration_seconds: float = 300"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 307
            },
            {
              "name": "cancel_override",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 317
            },
            {
              "name": "get_notification",
              "params": [
                "self",
                "result: AggregatedResult"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 322
            },
            {
              "name": "should_require_user_intervention",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 326
            },
            {
              "name": "get_escalation_message",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 330
            },
            {
              "name": "record_tool_call",
              "params": [
                "self",
                "tool: str",
                "args: Dict[str, Any]",
                "result: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 355
            },
            {
              "name": "record_output",
              "params": [
                "self",
                "output: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 359
            },
            {
              "name": "record_state",
              "params": [
                "self",
                "goal: str = ''",
                "modified_files: Optional[set] = None",
                "state_snapshot: Optional[Dict[str, Any]] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 363
            },
            {
              "name": "record_error",
              "params": [
                "self",
                "error_type: str",
                "error_message: str",
                "attempted_fix: str = ''",
                "was_success: bool = False"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 372
            },
            {
              "name": "add_tokens",
              "params": [
                "self",
                "tokens: str"
              ],
              "return_type": "Optional[Any]",
              "decorators": [],
              "is_async": false,
              "line": 382
            }
          ],
          "line": 112
        },
        {
          "name": "LoopInterrupt",
          "bases": [],
          "docstring": "Interrupt signal for streaming loop detection.\nCompatible with existing Interrupt class from stream_",
          "methods": [
            {
              "name": "from_detection",
              "params": [
                "cls",
                "result: AggregatedResult",
                "is_warn: bool = True"
              ],
              "return_type": "LoopInterrupt",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 461
            }
          ],
          "line": 450
        },
        {
          "name": "LoopDetectorObserver",
          "bases": [],
          "docstring": "Observer adapter for integration with ExternalVoice streaming.\n\nMonitors token stream for loop patte",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "manager: Optional[LoopRecoveryManager] = None",
                "think_tag_char_threshold: int = 500",
                "think_tag_ratio_threshold: float = 0.9"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 498
            },
            {
              "name": "_check_think_tag_ratio",
              "params": [
                "self"
              ],
              "return_type": "Optional[LoopInterrupt]",
              "decorators": [],
              "is_async": false,
              "line": 514
            },
            {
              "name": "on_token",
              "params": [
                "self",
                "token: str"
              ],
              "return_type": "Optional[LoopInterrupt]",
              "decorators": [],
              "is_async": false,
              "line": 592
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 637
            }
          ],
          "line": 477
        }
      ],
      "functions": [
        {
          "name": "get_recovery_manager",
          "params": [],
          "return_type": "LoopRecoveryManager",
          "decorators": [],
          "is_async": false,
          "line": 391
        },
        {
          "name": "inject_recovery_context_if_needed",
          "params": [
            "prompt: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 399
        },
        {
          "name": "build_loop_detection_config_from_constants",
          "params": [
            "constants: Dict[str, Any]"
          ],
          "return_type": "LoopDetectorConfig",
          "decorators": [],
          "is_async": false,
          "line": 421
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.loop_detector import LoopDetector, LoopDetectorConfig, AggregatedResult, LoopCategory",
        "from gaia_core.cognition.loop_patterns import PatternRenderer"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/nlu/__init__.py": {
      "module_docstring": "gaia_core.cognition.nlu - Natural Language Understanding modules.\n\nThis package provides:\n- intent_detection: Fast reflex, LLM-powered, and embedding-based intent detection\n- embed_intent_classifier: ",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/nlu/embed_intent_classifier.py": {
      "module_docstring": "Embedding-based intent classifier for GAIA.\n\nReplaces the keyword-heuristic fallback in intent_detection.py with\ncosine-similarity classification against a bank of labeled exemplar\nphrases.  Uses the ",
      "classes": [
        {
          "name": "EmbedIntentClassifier",
          "bases": [],
          "docstring": "Singleton embedding-based intent classifier.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 40
            },
            {
              "name": "instance",
              "params": [
                "cls"
              ],
              "return_type": "'EmbedIntentClassifier'",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 47
            },
            {
              "name": "initialise",
              "params": [
                "self",
                "embed_model",
                "config: Optional[dict] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 58
            },
            {
              "name": "classify",
              "params": [
                "self",
                "text: str",
                "confidence_threshold: float = 0.45",
                "top_k: int = 3"
              ],
              "return_type": "Tuple[str, float]",
              "decorators": [],
              "is_async": false,
              "line": 116
            },
            {
              "name": "ready",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 177
            }
          ],
          "line": 34
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialise",
          "line": 75
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialise",
          "line": 108
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "classify",
          "line": 172
        }
      ],
      "http_calls": []
    },
    "cognition/nlu/intent_detection.py": {
      "module_docstring": "Intent Detection (pillar-compliant, robust)\n- Fast reflex/regex path for autonomic commands (help, exit, shell, etc).\n- LLM-powered detection for all ambiguous/natural input.\n- Returns simple intent l",
      "classes": [
        {
          "name": "Plan",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 20
        }
      ],
      "functions": [
        {
          "name": "fast_intent_check",
          "params": [
            "text"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 25
        },
        {
          "name": "_detect_direct_list_tools",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 43
        },
        {
          "name": "_detect_tree_request",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 47
        },
        {
          "name": "_detect_list_files_request",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 71
        },
        {
          "name": "_detect_read_file_request",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 84
        },
        {
          "name": "_mentions_file_like_action",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 110
        },
        {
          "name": "_detect_fragmentation_request",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 134
        },
        {
          "name": "_detect_tool_routing_request",
          "params": [
            "text: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 279
        },
        {
          "name": "_keyword_intent_classify",
          "params": [
            "text: str",
            "probe_context: str = ''"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 373
        },
        {
          "name": "_fast_track_intent_detection",
          "params": [
            "text: str"
          ],
          "return_type": "Optional[str]",
          "decorators": [],
          "is_async": false,
          "line": 504
        },
        {
          "name": "model_intent_detection",
          "params": [
            "text",
            "config",
            "lite_llm = None",
            "full_llm = None",
            "fallback_llm = None",
            "probe_context = ''",
            "embed_model = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 532
        },
        {
          "name": "detect_intent",
          "params": [
            "text",
            "config",
            "lite_llm = None",
            "full_llm = None",
            "fallback_llm = None",
            "probe_context = ''",
            "embed_model = None"
          ],
          "return_type": "Plan",
          "decorators": [],
          "is_async": false,
          "line": 716
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.nlu.embed_intent_classifier import EmbedIntentClassifier"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "AssertionError"
          ],
          "status_code": null,
          "enclosing_function": "model_intent_detection",
          "line": 688
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "model_intent_detection",
          "line": 691
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "detect_intent",
          "line": 728
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_is_llama_cpp_instance",
          "line": 554
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "model_intent_detection",
          "line": 608
        }
      ],
      "http_calls": []
    },
    "cognition/nlu/intent_service.py": {
      "module_docstring": "Public faade for intent detection.\n\nOther code should import ONLY from this file:\n    from gaia_core.cognition.nlu.intent_service import detect_intent\n\nBehind the curtain we forward to the real detec",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/packet_upgrade.py": {
      "module_docstring": "Non-destructive CognitionPacket upgrader  DEPRECATED.\n\nThis module was part of the v0.2  v0.3 migration path. The attributes it\nsets (cot, scratch, cheats, proposed_actions, etc.) do not exist on th",
      "classes": [],
      "functions": [
        {
          "name": "_ensure",
          "params": [
            "obj: object",
            "name: str",
            "default"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 13
        },
        {
          "name": "_ensure_slots",
          "params": [
            "dct",
            "keys"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 17
        },
        {
          "name": "upgrade_packet",
          "params": [
            "packet",
            "config"
          ],
          "return_type": "object",
          "decorators": [],
          "is_async": false,
          "line": 21
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/packet_utils.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "is_execution_safe",
          "params": [
            "packet: CognitionPacket"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 24
        },
        {
          "name": "upgrade_v2_to_v3_packet",
          "params": [
            "old_packet_data: Dict"
          ],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 47
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Header, Persona, Routing, Model, Intent, Context, SessionHistoryRef, Cheatsheet, Constraints, Content, DataField, Reasoning, ReflectionLog, Sketchpad, Evaluation, Response, ToolCall, SidecarAction, Governance, Safety, Signatures, Audit, Privacy, Metrics, TokenUsage, Status, PacketState, Council, PersonaRole, Origin, TargetEngine, SystemTask"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/prime_checkpoint.py": {
      "module_docstring": "Prime model cognitive state checkpointing.\n\nManages the prime.md checkpoint file that preserves GAIA's working memory\nacross GPU sleep/wake cycles.  This is the natural-language replacement for\nKV cac",
      "classes": [
        {
          "name": "PrimeCheckpointManager",
          "bases": [],
          "docstring": "Manages Prime model's cognitive state checkpointing.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "timeline_store = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 38
            },
            {
              "name": "create_checkpoint",
              "params": [
                "self",
                "packet = None",
                "model_pool = None"
              ],
              "return_type": "Path",
              "decorators": [],
              "is_async": false,
              "line": 61
            },
            {
              "name": "rotate_checkpoints",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 82
            },
            {
              "name": "load_latest",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 102
            },
            {
              "name": "is_consumed",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 116
            },
            {
              "name": "mark_consumed",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 120
            },
            {
              "name": "get_checkpoint_history",
              "params": [
                "self",
                "limit: int = 10"
              ],
              "return_type": "list",
              "decorators": [],
              "is_async": false,
              "line": 130
            },
            {
              "name": "_generate_checkpoint",
              "params": [
                "self",
                "packet",
                "model_pool"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 143
            },
            {
              "name": "_generate_with_llm",
              "params": [
                "self",
                "llm",
                "ctx: dict"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 158
            },
            {
              "name": "_build_template",
              "params": [
                "self",
                "ctx: dict"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 222
            },
            {
              "name": "_emit_checkpoint",
              "params": [
                "self",
                "packet",
                "method: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 255
            },
            {
              "name": "_extract_context",
              "params": [
                "self",
                "packet"
              ],
              "return_type": "dict",
              "decorators": [],
              "is_async": false,
              "line": 275
            },
            {
              "name": "_load_evolving_summary",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 290
            },
            {
              "name": "_truncate",
              "params": [
                "text: str",
                "max_len: int"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 302
            }
          ],
          "line": 35
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 52
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "rotate_checkpoints",
          "line": 99
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "load_latest",
          "line": 112
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "mark_consumed",
          "line": 127
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_load_evolving_summary",
          "line": 297
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_generate_checkpoint",
          "line": 153
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_checkpoint",
          "line": 268
        }
      ],
      "http_calls": []
    },
    "cognition/self_reflection.py": {
      "module_docstring": "Self Reflection Processor (model-powered, robust pipeline)\n- Calls LLM for post-generation analysis and hallucination/error detection.\n- Integrates config-driven safety and can fallback to rule-based ",
      "classes": [],
      "functions": [
        {
          "name": "reflect_and_refine",
          "params": [
            "packet: CognitionPacket",
            "output: str",
            "config",
            "llm",
            "ethical_sentinel"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 35
        },
        {
          "name": "run_self_reflection",
          "params": [
            "packet: CognitionPacket",
            "output: str",
            "config = None",
            "llm = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 219
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config",
        "from gaia_core.memory.conversation.summarizer import ConversationSummarizer",
        "from gaia_core.utils.gaia_rescue_helper import sketch, show_sketchpad, clear_sketchpad",
        "from gaia_common.utils.thoughtstream import write",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, DataField, Persona, PersonaRole, ReflectionLog",
        "from gaia_core.utils.prompt_builder import build_from_packet, count_tokens",
        "from gaia_core.utils.packet_builder import build_packet_snapshot"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 53
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 71
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 203
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_self_reflection",
          "line": 236
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 67
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 108
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 134
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 152
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 162
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_self_reflection",
          "line": 257
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 142
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 195
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "reflect_and_refine",
          "line": 182
        }
      ],
      "http_calls": []
    },
    "cognition/self_review_worker.py": {
      "module_docstring": "Self-review worker: reviews thought seeds and proposes dev_matrix updates.\n\nThis worker runs in proposal-only mode: it will create a pending MCP action to\nupdate `knowledge/system_reference/dev_matrix",
      "classes": [],
      "functions": [
        {
          "name": "_get_model_pool",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 18
        },
        {
          "name": "_load_dev_matrix",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 38
        },
        {
          "name": "_save_dev_matrix",
          "params": [
            "data"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 49
        },
        {
          "name": "run_review_once",
          "params": [
            "config: Config = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 59
        },
        {
          "name": "run_review_with_prompt",
          "params": [
            "prompt: str",
            "task_key: str = 'thought_seed_system'",
            "session_id: str = 'rescue-shell'",
            "persona_id: str = 'RescueOperator'"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 170
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition import thought_seed",
        "from gaia_core.config import Config, get_config",
        "from gaia_core.utils import mcp_client",
        "from gaia_core.cognition.nlu.intent_service import detect_intent"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_model_pool",
          "line": 27
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_dev_matrix",
          "line": 44
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save_dev_matrix",
          "line": 54
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_review_once",
          "line": 164
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_review_once",
          "line": 148
        }
      ],
      "http_calls": []
    },
    "cognition/semantic_probe.py": {
      "module_docstring": "Semantic Probe  Pre-cognition vector lookup for context discovery.\n\nRuns BEFORE intent detection and persona selection. Extracts interesting\nphrases from user input, probes all indexed vector collect",
      "classes": [
        {
          "name": "ProbeHit",
          "bases": [],
          "docstring": "A single vector match from the probe.",
          "methods": [
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "dict",
              "decorators": [],
              "is_async": false,
              "line": 115
            }
          ],
          "line": 106
        },
        {
          "name": "SemanticProbeResult",
          "bases": [],
          "docstring": "Aggregated result from probing all collections.",
          "methods": [
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "dict",
              "decorators": [],
              "is_async": false,
              "line": 136
            },
            {
              "name": "has_hits",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 147
            },
            {
              "name": "to_metrics_dict",
              "params": [
                "self"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 150
            }
          ],
          "line": 127
        },
        {
          "name": "SessionProbeCache",
          "bases": [],
          "docstring": "Per-session cache of phrase  probe hits with turn-based eviction.",
          "methods": [
            {
              "name": "get",
              "params": [
                "self",
                "phrase: str"
              ],
              "return_type": "Optional[List[ProbeHit]]",
              "decorators": [],
              "is_async": false,
              "line": 190
            },
            {
              "name": "put",
              "params": [
                "self",
                "phrase: str",
                "hits: List[ProbeHit]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 202
            },
            {
              "name": "advance_turn",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 207
            }
          ],
          "line": 183
        },
        {
          "name": "ProbeSessionStats",
          "bases": [],
          "docstring": "Cumulative probe effectiveness stats for a session.",
          "methods": [
            {
              "name": "record",
              "params": [
                "self",
                "result: 'SemanticProbeResult'",
                "was_skipped: bool = False"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 230
            },
            {
              "name": "hit_rate",
              "params": [
                "self"
              ],
              "return_type": "float",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 247
            },
            {
              "name": "avg_probe_time_ms",
              "params": [
                "self"
              ],
              "return_type": "float",
              "decorators": [
                "property"
              ],
              "is_async": false,
              "line": 253
            },
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 257
            }
          ],
          "line": 218
        }
      ],
      "functions": [
        {
          "name": "_load_probe_config",
          "params": [],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 25
        },
        {
          "name": "_get_session_cache",
          "params": [
            "session_id: str"
          ],
          "return_type": "SessionProbeCache",
          "decorators": [],
          "is_async": false,
          "line": 279
        },
        {
          "name": "_get_session_stats",
          "params": [
            "session_id: str"
          ],
          "return_type": "ProbeSessionStats",
          "decorators": [],
          "is_async": false,
          "line": 285
        },
        {
          "name": "get_session_probe_stats",
          "params": [
            "session_id: str"
          ],
          "return_type": "Optional[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 291
        },
        {
          "name": "extract_candidate_phrases",
          "params": [
            "text: str"
          ],
          "return_type": "List[str]",
          "decorators": [],
          "is_async": false,
          "line": 301
        },
        {
          "name": "_probe_single_collection",
          "params": [
            "phrases: List[str]",
            "collection_name: str",
            "top_k: int = 3"
          ],
          "return_type": "List[ProbeHit]",
          "decorators": [],
          "is_async": false,
          "line": 397
        },
        {
          "name": "_determine_primary_and_supplemental",
          "params": [
            "hits: List[ProbeHit]"
          ],
          "return_type": "Tuple[Optional[str], List[str]]",
          "decorators": [],
          "is_async": false,
          "line": 445
        },
        {
          "name": "probe_collections",
          "params": [
            "phrases: List[str]",
            "knowledge_bases: Dict[str, dict]",
            "session_id: str = ''",
            "top_k_per_phrase: int = 3"
          ],
          "return_type": "SemanticProbeResult",
          "decorators": [],
          "is_async": false,
          "line": 476
        },
        {
          "name": "should_skip_probe",
          "params": [
            "user_input: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 579
        },
        {
          "name": "run_semantic_probe",
          "params": [
            "user_input: str",
            "knowledge_bases: Dict[str, dict]",
            "session_id: str = ''",
            "top_k_per_phrase: int = ..."
          ],
          "return_type": "SemanticProbeResult",
          "decorators": [],
          "is_async": false,
          "line": 595
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_probe_config",
          "line": 31
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_probe_single_collection",
          "line": 411
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_probe_single_collection",
          "line": 437
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "probe_collections",
          "line": 537
        }
      ],
      "http_calls": []
    },
    "cognition/sleep_cycle_loop.py": {
      "module_docstring": "Sleep cycle loop  runs as a daemon thread in gaia-core.\n\nUses gaia-common primitives (IdleMonitor) for idle detection but owns\nall sleep/wake orchestration logic.  Replaces the legacy\nBackgroundProce",
      "classes": [
        {
          "name": "SleepCycleLoop",
          "bases": [],
          "docstring": "Background thread that monitors idle state and drives sleep/wake.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "discord_connector = None",
                "model_pool = None",
                "agent_core = None",
                "session_manager = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 37
            },
            {
              "name": "start",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 95
            },
            {
              "name": "stop",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 105
            },
            {
              "name": "initiate_shutdown",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 114
            },
            {
              "name": "_run",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 126
            },
            {
              "name": "_handle_active",
              "params": [
                "self",
                "idle_minutes: float"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 162
            },
            {
              "name": "_handle_asleep",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 175
            },
            {
              "name": "_handle_dreaming",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 220
            },
            {
              "name": "_handle_distracted",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 224
            },
            {
              "name": "_release_gpu_for_sleep",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 240
            },
            {
              "name": "_reclaim_gpu_for_wake",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 255
            },
            {
              "name": "_update_presence",
              "params": [
                "self",
                "status_text: Optional[str]",
                "sleeping: bool = False",
                "offline: bool = False",
                "status_override: Optional[str] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 274
            }
          ],
          "line": 30
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.utils.background.idle_monitor import IdleMonitor",
        "from gaia_common.utils.timeline_store import TimelineStore",
        "from gaia_core.cognition.sleep_wake_manager import GaiaState, SleepWakeManager, _TransientPhase"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 88
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_release_gpu_for_sleep",
          "line": 252
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reclaim_gpu_for_wake",
          "line": 267
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run",
          "line": 147
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_update_presence",
          "line": 311
        }
      ],
      "http_calls": [
        {
          "call_method": "post",
          "url_or_path": "<f-string>",
          "enclosing_function": "_release_gpu_for_sleep",
          "line": 243
        },
        {
          "call_method": "post",
          "url_or_path": "<f-string>",
          "enclosing_function": "_reclaim_gpu_for_wake",
          "line": 258
        },
        {
          "call_method": "post",
          "url_or_path": "<f-string>",
          "enclosing_function": "_update_presence",
          "line": 310
        }
      ]
    },
    "cognition/sleep_task_scheduler.py": {
      "module_docstring": "Sleep Task Scheduler  orchestrates autonomous maintenance during SLEEPING state.\n\nRegistered tasks are executed one-at-a-time in priority order (lowest number = highest\npriority), with least-recently",
      "classes": [
        {
          "name": "SleepTask",
          "bases": [],
          "docstring": "A single registerable sleep-time task.",
          "methods": [],
          "line": 26
        },
        {
          "name": "SleepTaskScheduler",
          "bases": [],
          "docstring": "Priority-based scheduler for sleep-time maintenance tasks.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "agent_core = None",
                "timeline_store = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 43
            },
            {
              "name": "register_task",
              "params": [
                "self",
                "task: SleepTask"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 62
            },
            {
              "name": "_register_default_tasks",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "get_next_task",
              "params": [
                "self"
              ],
              "return_type": "Optional[SleepTask]",
              "decorators": [],
              "is_async": false,
              "line": 100
            },
            {
              "name": "execute_task",
              "params": [
                "self",
                "task: SleepTask"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 113
            },
            {
              "name": "get_status",
              "params": [
                "self"
              ],
              "return_type": "List[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 138
            },
            {
              "name": "_run_conversation_curation",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 156
            },
            {
              "name": "_run_blueprint_validation",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 207
            },
            {
              "name": "_validate_yaml_blueprints",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 228
            },
            {
              "name": "_validate_legacy_blueprints",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 272
            },
            {
              "name": "_extract_facts",
              "params": [
                "source_files: List[str]",
                "source_roots: List[Path]"
              ],
              "return_type": "Dict[str, List[str]]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 306
            },
            {
              "name": "_check_facts",
              "params": [
                "facts: Dict[str, List[str]]",
                "bp_text: str"
              ],
              "return_type": "List[str]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 369
            },
            {
              "name": "_append_update_notes",
              "params": [
                "bp_path: Path",
                "bp_text: str",
                "missing: List[str]"
              ],
              "return_type": "None",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 393
            },
            {
              "name": "_rebuild_blueprint_embeddings",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 416
            },
            {
              "name": "_run_code_evolution",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 431
            },
            {
              "name": "_emit_task_exec",
              "params": [
                "self",
                "task_id: str",
                "task_type: str",
                "elapsed: float",
                "success: bool",
                "error: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 447
            }
          ],
          "line": 40
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "execute_task",
          "line": 126
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "_validate_yaml_blueprints",
          "line": 233
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_rebuild_blueprint_embeddings",
          "line": 428
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_run_code_evolution",
          "line": 443
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_task_exec",
          "line": 462
        }
      ],
      "http_calls": []
    },
    "cognition/sleep_wake_manager.py": {
      "module_docstring": "GAIA Sleep/Wake State Machine.\n\nManages six public states + two internal transient phases:\n\nPublic states:\n    OFFLINE  ACTIVE  DROWSY  ASLEEP  DREAMING / DISTRACTED\n\nInternal phases (not in the p",
      "classes": [
        {
          "name": "SleepWakeManager",
          "bases": [],
          "docstring": "Manages GAIA's sleep/wake state transitions with cognitive continuity.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "idle_monitor = None",
                "timeline_store = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 68
            },
            {
              "name": "get_state",
              "params": [
                "self"
              ],
              "return_type": "GaiaState",
              "decorators": [],
              "is_async": false,
              "line": 89
            },
            {
              "name": "should_transition_to_drowsy",
              "params": [
                "self",
                "idle_minutes: float"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 92
            },
            {
              "name": "_emit_state_change",
              "params": [
                "self",
                "from_state: str",
                "to_state: str",
                "reason: str = ''"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 103
            },
            {
              "name": "_notify_audio_state",
              "params": [
                "self",
                "to_state: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 118
            },
            {
              "name": "initiate_drowsy",
              "params": [
                "self",
                "current_packet = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 155
            },
            {
              "name": "receive_wake_signal",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 209
            },
            {
              "name": "set_voice_active",
              "params": [
                "self",
                "active: bool"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 247
            },
            {
              "name": "transition_to_waking",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 264
            },
            {
              "name": "complete_wake",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 273
            },
            {
              "name": "enter_dreaming",
              "params": [
                "self",
                "handoff_id: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 315
            },
            {
              "name": "exit_dreaming",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 327
            },
            {
              "name": "enter_distracted",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 348
            },
            {
              "name": "exit_distracted",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 359
            },
            {
              "name": "initiate_offline",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 379
            },
            {
              "name": "get_status",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 392
            },
            {
              "name": "get_canned_response",
              "params": [
                "self"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 408
            },
            {
              "name": "_format_checkpoint_as_review",
              "params": [
                "checkpoint: str"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 421
            }
          ],
          "line": 65
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [
        {
          "name": "GaiaState",
          "members": [
            [
              "OFFLINE",
              "'offline'"
            ],
            [
              "ACTIVE",
              "'active'"
            ],
            [
              "DROWSY",
              "'drowsy'"
            ],
            [
              "ASLEEP",
              "'asleep'"
            ],
            [
              "DREAMING",
              "'dreaming'"
            ],
            [
              "DISTRACTED",
              "'distracted'"
            ]
          ],
          "line": 38
        },
        {
          "name": "_TransientPhase",
          "members": [
            [
              "NONE",
              "'none'"
            ],
            [
              "FINISHING_TASK",
              "'finishing_task'"
            ],
            [
              "WAKING",
              "'waking'"
            ]
          ],
          "line": 47
        }
      ],
      "constants": [
        {
          "name": "CANNED_DREAMING",
          "value": "\"I'm studying right now and can't chat  I'll be back once my training session...\"",
          "line": 55
        },
        {
          "name": "CANNED_DISTRACTED",
          "value": "\"I'm a little occupied at the moment  give me a few minutes and I'll get back...\"",
          "line": 59
        }
      ],
      "gaia_imports": [
        "from gaia_core.cognition.prime_checkpoint import PrimeCheckpointManager"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_notify_audio_state",
          "line": 148
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initiate_drowsy",
          "line": 203
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "complete_wake",
          "line": 304
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_state_change",
          "line": 112
        }
      ],
      "http_calls": [
        {
          "call_method": "Client",
          "url_or_path": null,
          "enclosing_function": "_notify_audio_state",
          "line": 145
        },
        {
          "call_method": "post",
          "url_or_path": "<f-string>",
          "enclosing_function": "_notify_audio_state",
          "line": 146
        }
      ]
    },
    "cognition/telemetric_senses.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "tick",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 25
        },
        {
          "name": "update_token_usage",
          "params": [
            "count: int"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 31
        },
        {
          "name": "scan_files",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 37
        },
        {
          "name": "get_gpu_usage",
          "params": [],
          "return_type": "dict[str, any]",
          "decorators": [],
          "is_async": false,
          "line": 56
        },
        {
          "name": "get_hardware_profile",
          "params": [],
          "return_type": "dict[str, any]",
          "decorators": [],
          "is_async": false,
          "line": 83
        },
        {
          "name": "get_system_resources",
          "params": [],
          "return_type": "dict[str, any]",
          "decorators": [],
          "is_async": false,
          "line": 106
        },
        {
          "name": "system_health",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 130
        },
        {
          "name": "get_telemetry_summary",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 139
        },
        {
          "name": "full_sense_sweep",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 161
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config",
        "from gaia_core.memory.status_tracker import GAIAStatus"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_gpu_usage",
          "line": 79
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_hardware_profile",
          "line": 102
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_system_resources",
          "line": 126
        }
      ],
      "http_calls": []
    },
    "cognition/temporal_interviewer.py": {
      "module_docstring": "Temporal Interviewer  Prime interviews past-Lite via KV cache state swapping.\n\nPhase 2 of the Temporal Awareness Framework.  Prime formulates structured\nquestions about a past moment, Lite answers fr",
      "classes": [
        {
          "name": "TemporalInterviewer",
          "bases": [],
          "docstring": "Orchestrates Prime-interviews-past-Lite sessions.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "temporal_state_manager = None",
                "lite_journal = None",
                "timeline_store = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 100
            },
            {
              "name": "conduct_interview",
              "params": [
                "self",
                "state_id: Optional[str] = None"
              ],
              "return_type": "Optional[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 133
            },
            {
              "name": "_select_interview_target",
              "params": [
                "self"
              ],
              "return_type": "Optional[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 237
            },
            {
              "name": "_has_transcript",
              "params": [
                "self",
                "state_id: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 270
            },
            {
              "name": "_run_interview_rounds",
              "params": [
                "self",
                "llm",
                "state_metadata: Dict[str, Any]"
              ],
              "return_type": "List[Dict[str, str]]",
              "decorators": [],
              "is_async": false,
              "line": 278
            },
            {
              "name": "_prime_ask",
              "params": [
                "self",
                "previous_rounds: List[Dict[str, str]]",
                "state_ts: str",
                "round_idx: int"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 305
            },
            {
              "name": "_lite_answer",
              "params": [
                "self",
                "llm",
                "previous_rounds: List[Dict[str, str]]",
                "question: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 348
            },
            {
              "name": "_analyze_coherence",
              "params": [
                "self",
                "transcript_rounds: List[Dict[str, str]]",
                "state_metadata: Dict[str, Any]"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 382
            },
            {
              "name": "_get_journal_for_state",
              "params": [
                "self",
                "state_metadata: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 431
            },
            {
              "name": "_parse_coherence",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 459
            },
            {
              "name": "_default_coherence",
              "params": [],
              "return_type": "Dict[str, Any]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 500
            },
            {
              "name": "_build_transcript",
              "params": [
                "self",
                "state_id: str",
                "state_metadata: Dict[str, Any]",
                "rounds: List[Dict[str, str]]",
                "coherence: Dict[str, Any]",
                "duration_ms: int"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 514
            },
            {
              "name": "_save_transcript",
              "params": [
                "self",
                "transcript: Dict[str, Any]"
              ],
              "return_type": "Optional[Path]",
              "decorators": [],
              "is_async": false,
              "line": 535
            },
            {
              "name": "_emit_interview_event",
              "params": [
                "self",
                "transcript: Dict[str, Any]"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 557
            }
          ],
          "line": 93
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 126
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "conduct_interview",
          "line": 170
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_prime_ask",
          "line": 344
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_lite_answer",
          "line": 374
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_analyze_coherence",
          "line": 427
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_journal_for_state",
          "line": 456
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_save_transcript",
          "line": 549
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_emit_interview_event",
          "line": 573
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "conduct_interview",
          "line": 204
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "conduct_interview",
          "line": 198
        }
      ],
      "http_calls": []
    },
    "cognition/temporal_state_manager.py": {
      "module_docstring": "Temporal State Manager  KV cache state baking, storage, and restoration for Lite.\n\nManages segmented KV cache snapshots that capture Lite's cognitive state at specific\npoints in time.  These snapshot",
      "classes": [
        {
          "name": "TemporalStateManager",
          "bases": [],
          "docstring": "Manages Lite KV cache state snapshots for temporal self-awareness.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool = None",
                "timeline_store = None",
                "session_manager = None",
                "lite_journal = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 81
            },
            {
              "name": "bake_state",
              "params": [
                "self"
              ],
              "return_type": "Optional[Path]",
              "decorators": [],
              "is_async": false,
              "line": 113
            },
            {
              "name": "load_state",
              "params": [
                "self",
                "state_id: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 160
            },
            {
              "name": "restore_current",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 183
            },
            {
              "name": "list_states",
              "params": [
                "self"
              ],
              "return_type": "List[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 197
            },
            {
              "name": "get_state_metadata",
              "params": [
                "self",
                "state_id: str"
              ],
              "return_type": "Optional[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 223
            },
            {
              "name": "cleanup_old_states",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 233
            },
            {
              "name": "_build_bake_context",
              "params": [
                "self"
              ],
              "return_type": "List[Dict[str, str]]",
              "decorators": [],
              "is_async": false,
              "line": 264
            },
            {
              "name": "_reconstruct_wake_cycle",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 290
            },
            {
              "name": "_reconstruct_timeline_context",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 314
            },
            {
              "name": "_reconstruct_conversation_context",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 333
            },
            {
              "name": "_reconstruct_world_state",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 377
            },
            {
              "name": "_reconstruct_journal_content",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 385
            },
            {
              "name": "_save_lite_state",
              "params": [
                "self",
                "llm",
                "metadata: Dict[str, Any]"
              ],
              "return_type": "Path",
              "decorators": [],
              "is_async": false,
              "line": 399
            },
            {
              "name": "save_current_state_memory",
              "params": [
                "self",
                "llm"
              ],
              "return_type": "Any",
              "decorators": [],
              "is_async": false,
              "line": 437
            },
            {
              "name": "restore_state_memory",
              "params": [
                "self",
                "llm",
                "state_data"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 448
            },
            {
              "name": "_load_lite_state",
              "params": [
                "self",
                "llm",
                "state_path: Path"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 455
            },
            {
              "name": "_build_metadata",
              "params": [
                "self",
                "bake_duration_ms: int"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 489
            },
            {
              "name": "_delete_state_files",
              "params": [
                "self",
                "bin_path: Path"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 527
            },
            {
              "name": "_event_summary",
              "params": [
                "data: Dict[str, Any]"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 536
            }
          ],
          "line": 78
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 106
        },
        {
          "exception_types": [
            "json.JSONDecodeError",
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "get_state_metadata",
          "line": 230
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reconstruct_wake_cycle",
          "line": 311
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reconstruct_timeline_context",
          "line": 330
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reconstruct_conversation_context",
          "line": 373
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reconstruct_world_state",
          "line": 382
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_reconstruct_journal_content",
          "line": 392
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_lite_state",
          "line": 471
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_metadata",
          "line": 502
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_delete_state_files",
          "line": 532
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "bake_state",
          "line": 123
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "bake_state",
          "line": 156
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_state",
          "line": 174
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_metadata",
          "line": 513
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_metadata",
          "line": 522
        },
        {
          "exception_types": [
            "json.JSONDecodeError",
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "list_states",
          "line": 209
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_load_lite_state",
          "line": 481
        }
      ],
      "http_calls": []
    },
    "cognition/tests/test_goal_detector.py": {
      "module_docstring": "Unit tests for GoalDetector.",
      "classes": [
        {
          "name": "TestFastPath",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_greeting_maps_to_casual_conversation",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 82
            },
            {
              "name": "test_question_maps_to_information_seeking",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 91
            },
            {
              "name": "test_tool_use_maps_to_task_execution",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 97
            },
            {
              "name": "test_help_request_maps_to_task_assistance",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 103
            }
          ],
          "line": 81
        },
        {
          "name": "TestSessionCarry",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_carries_active_goal",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 114
            },
            {
              "name": "test_carry_decays_after_max_turns",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 139
            }
          ],
          "line": 113
        },
        {
          "name": "TestLLMDetect",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_llm_detection_parses_response",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 166
            },
            {
              "name": "test_llm_detection_graceful_on_failure",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 184
            }
          ],
          "line": 165
        },
        {
          "name": "TestGoalShift",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_goal_shift_archives_previous",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 200
            },
            {
              "name": "test_goal_shift_without_previous_goal",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 219
            }
          ],
          "line": 199
        },
        {
          "name": "TestEdgeCases",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_no_goal_on_empty_input",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 235
            },
            {
              "name": "test_fast_path_takes_priority_over_carry",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 241
            },
            {
              "name": "test_parse_llm_response_handles_garbage",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 265
            },
            {
              "name": "test_persistence_round_trip",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 269
            }
          ],
          "line": 234
        }
      ],
      "functions": [
        {
          "name": "_make_packet",
          "params": [
            "user_intent: str = 'greeting'",
            "user_input: str = 'Hello!'"
          ],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 40
        },
        {
          "name": "_make_session_manager",
          "params": [
            "meta: dict | None = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 69
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Content, Context, Constraints, DetectedGoal, GoalConfidence, GoalState, Governance, Header, Intent, Metrics, Model, Persona, PersonaRole, Response, Reasoning, Routing, Safety, SessionHistoryRef, Status, PacketState, TargetEngine, SystemTask, TokenUsage",
        "from gaia_core.cognition.goal_detector import GoalDetector, MAX_CARRY_TURNS"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_heartbeat.py": {
      "module_docstring": "Tests for ThoughtSeedHeartbeat  GAIA's thought seed triage daemon.",
      "classes": [
        {
          "name": "TestSeedDirectoryOps",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_archive_seed_moves_file",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 57
            },
            {
              "name": "test_archive_nonexistent_returns_false",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 71
            },
            {
              "name": "test_defer_seed_moves_file",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 74
            },
            {
              "name": "test_defer_seed_with_revisit_after",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 88
            },
            {
              "name": "test_pending_due_promotes_back",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 99
            },
            {
              "name": "test_pending_not_due_stays",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 121
            },
            {
              "name": "test_pending_with_future_revisit_stays",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 138
            },
            {
              "name": "test_pending_with_past_revisit_promotes",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 154
            }
          ],
          "line": 56
        },
        {
          "name": "TestTriageSeed",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_archive_decision",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 184
            },
            {
              "name": "test_pending_decision",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 195
            },
            {
              "name": "test_act_decision",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 205
            },
            {
              "name": "test_unparseable_defaults_to_pending",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 215
            },
            {
              "name": "test_llm_failure_defaults_to_pending",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 225
            }
          ],
          "line": 183
        },
        {
          "name": "TestActOnSeed",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_act_when_active",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 241
            },
            {
              "name": "test_act_defers_when_dreaming",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 267
            },
            {
              "name": "test_seed_archived_after_act",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 291
            }
          ],
          "line": 240
        },
        {
          "name": "FakeConfig",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 321
        },
        {
          "name": "TestHeartbeatLifecycle",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_start_creates_thread",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 327
            },
            {
              "name": "test_stop_terminates_thread",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 340
            },
            {
              "name": "test_tick_emits_timeline_event",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 350
            },
            {
              "name": "test_tick_triages_seeds",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 370
            }
          ],
          "line": 326
        },
        {
          "name": "TestTemporalIntegration",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_tick_writes_journal_entry",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 401
            },
            {
              "name": "test_tick_bakes_state_on_interval",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 415
            },
            {
              "name": "test_tick_skips_bake_off_interval",
              "params": [
                "self",
                "_patch_seeds_dirs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 432
            }
          ],
          "line": 400
        }
      ],
      "functions": [
        {
          "name": "_patch_seeds_dirs",
          "params": [
            "tmp_path",
            "monkeypatch"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture(autouse=True)"
          ],
          "is_async": false,
          "line": 27
        },
        {
          "name": "_write_seed",
          "params": [
            "seeds_dir: Path",
            "filename: str",
            "**overrides"
          ],
          "return_type": "Path",
          "decorators": [],
          "is_async": false,
          "line": 37
        },
        {
          "name": "_mock_llm",
          "params": [
            "response_text: str"
          ],
          "return_type": "MagicMock",
          "decorators": [],
          "is_async": false,
          "line": 174
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.thought_seed import SEEDS_ARCHIVE_DIR, SEEDS_DIR, SEEDS_PENDING_DIR, archive_seed, defer_seed, list_pending_seeds_due, list_unreviewed_seeds"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_initiative_engine.py": {
      "module_docstring": "Unit tests for InitiativeEngine.",
      "classes": [
        {
          "name": "FakeConfig",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 10
        },
        {
          "name": "TestNoTopics",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_returns_none_when_no_topics",
              "params": [
                "self",
                "mock_pt",
                "config",
                "mock_agent_core"
              ],
              "return_type": null,
              "decorators": [
                "patch('gaia_core.cognition.topic_manager.prioritize_topics', return_value=[])"
              ],
              "is_async": false,
              "line": 38
            }
          ],
          "line": 36
        },
        {
          "name": "TestNoAgentCore",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_returns_none_without_agent_core",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 51
            }
          ],
          "line": 50
        },
        {
          "name": "TestSuccessfulTurn",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_executes_turn_with_topic",
              "params": [
                "self",
                "mock_pt",
                "config",
                "mock_agent_core"
              ],
              "return_type": null,
              "decorators": [
                "patch('gaia_core.cognition.topic_manager.prioritize_topics')"
              ],
              "is_async": false,
              "line": 64
            },
            {
              "name": "test_uses_gil_session_id",
              "params": [
                "self",
                "mock_pt",
                "config",
                "mock_agent_core"
              ],
              "return_type": null,
              "decorators": [
                "patch('gaia_core.cognition.topic_manager.prioritize_topics')"
              ],
              "is_async": false,
              "line": 74
            }
          ],
          "line": 62
        },
        {
          "name": "TestSelfPrompt",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_prompt_contains_topic_description",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 90
            },
            {
              "name": "test_prompt_contains_metadata",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 95
            },
            {
              "name": "test_prompt_contains_reflection_header",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 101
            }
          ],
          "line": 89
        },
        {
          "name": "TestErrorHandling",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_agent_core_error_returns_error_status",
              "params": [
                "self",
                "mock_pt",
                "config"
              ],
              "return_type": null,
              "decorators": [
                "patch('gaia_core.cognition.topic_manager.prioritize_topics')"
              ],
              "is_async": false,
              "line": 114
            }
          ],
          "line": 112
        }
      ],
      "functions": [
        {
          "name": "config",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 15
        },
        {
          "name": "mock_agent_core",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 20
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.initiative_engine import InitiativeEngine, GIL_SESSION_ID"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_lite_journal.py": {
      "module_docstring": "Tests for LiteJournal  Lite's introspective journal system.",
      "classes": [
        {
          "name": "TestJournalLifecycle",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_write_creates_journal_file",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 49
            },
            {
              "name": "test_write_appends_to_existing",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 59
            },
            {
              "name": "test_returns_none_without_llm",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 67
            },
            {
              "name": "test_returns_none_without_model_pool",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 74
            },
            {
              "name": "test_entry_format_has_timestamp",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 78
            },
            {
              "name": "test_entry_includes_state_metadata",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 87
            }
          ],
          "line": 48
        },
        {
          "name": "TestRotation",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_rotate_when_max_entries_exceeded",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 105
            },
            {
              "name": "test_history_dir_created_on_rotate",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 117
            },
            {
              "name": "test_rotated_file_is_timestamped",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 126
            }
          ],
          "line": 104
        },
        {
          "name": "TestLoadEntries",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_load_latest_returns_full_content",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 143
            },
            {
              "name": "test_load_recent_entries_returns_n",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 151
            },
            {
              "name": "test_load_recent_entries_empty_journal",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 162
            },
            {
              "name": "test_get_entry_count",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 167
            }
          ],
          "line": 142
        }
      ],
      "functions": [
        {
          "name": "mock_config",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 19
        },
        {
          "name": "_mock_llm",
          "params": [
            "response: str = ..."
          ],
          "return_type": "MagicMock",
          "decorators": [],
          "is_async": false,
          "line": 25
        },
        {
          "name": "_mock_pool",
          "params": [
            "response: str = ..."
          ],
          "return_type": "MagicMock",
          "decorators": [],
          "is_async": false,
          "line": 33
        },
        {
          "name": "_mock_swm",
          "params": [
            "state: str = 'active'",
            "seconds: float = 3600.0"
          ],
          "return_type": "MagicMock",
          "decorators": [],
          "is_async": false,
          "line": 39
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.lite_journal import LiteJournal"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_sleep_gpu_integration.py": {
      "module_docstring": "Tests for sleep cycle GPU release/reclaim and Discord presence wiring.\n\nValidates that SleepCycleLoop correctly:\n- Calls orchestrator /gpu/sleep when entering sleep\n- Calls orchestrator /gpu/wake when",
      "classes": [
        {
          "name": "TestGPUReleaseOnSleep",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_gpu_release_called_on_sleep",
              "params": [
                "self",
                "loop"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 61
            },
            {
              "name": "test_gpu_release_failure_nonfatal",
              "params": [
                "self",
                "loop"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 79
            },
            {
              "name": "test_no_gpu_release_when_drowsy_cancelled",
              "params": [
                "self",
                "loop"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 93
            }
          ],
          "line": 60
        },
        {
          "name": "TestGPUReclaimOnWake",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_gpu_reclaim_called_on_wake",
              "params": [
                "self",
                "loop"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 111
            },
            {
              "name": "test_gpu_reclaim_failure_nonfatal",
              "params": [
                "self",
                "loop"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 129
            }
          ],
          "line": 110
        },
        {
          "name": "TestPresenceDuringSleep",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_presence_sleeping_during_sleep",
              "params": [
                "self",
                "loop",
                "mock_discord"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 147
            },
            {
              "name": "test_presence_sleeping_during_task",
              "params": [
                "self",
                "loop",
                "mock_discord"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 161
            },
            {
              "name": "test_presence_resets_on_wake",
              "params": [
                "self",
                "loop",
                "mock_discord"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 179
            }
          ],
          "line": 146
        },
        {
          "name": "TestDreamingPresence",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_dreaming_shows_dnd_studying",
              "params": [
                "self",
                "loop",
                "mock_discord"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 199
            }
          ],
          "line": 198
        },
        {
          "name": "TestSOAPresence",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_soa_presence_calls_web_endpoint",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 210
            },
            {
              "name": "test_soa_presence_online_when_not_sleeping",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 226
            },
            {
              "name": "test_soa_presence_failure_nonfatal",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 242
            },
            {
              "name": "test_soa_presence_invisible_on_offline",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 254
            },
            {
              "name": "test_soa_presence_dnd_override",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 270
            }
          ],
          "line": 209
        }
      ],
      "functions": [
        {
          "name": "mock_config",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 21
        },
        {
          "name": "mock_discord",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 33
        },
        {
          "name": "loop",
          "params": [
            "mock_config",
            "mock_discord"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 41
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.sleep_cycle_loop import SleepCycleLoop",
        "from gaia_core.cognition.sleep_wake_manager import GaiaState, _TransientPhase"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_sleep_task_scheduler.py": {
      "module_docstring": "Unit tests for SleepTaskScheduler.",
      "classes": [
        {
          "name": "FakeConfig",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 13
        },
        {
          "name": "TestRegistration",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_default_tasks_registered",
              "params": [
                "self",
                "scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 48
            },
            {
              "name": "test_default_task_ids",
              "params": [
                "self",
                "scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 51
            },
            {
              "name": "test_register_custom_task",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 55
            }
          ],
          "line": 47
        },
        {
          "name": "TestScheduling",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_priority_ordering",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 75
            },
            {
              "name": "test_lru_within_same_priority",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 88
            },
            {
              "name": "test_never_run_beats_recently_run",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 104
            },
            {
              "name": "test_empty_scheduler_returns_none",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 119
            }
          ],
          "line": 74
        },
        {
          "name": "TestExecution",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_successful_execution",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 129
            },
            {
              "name": "test_failed_execution",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 145
            },
            {
              "name": "test_run_count_increments",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 159
            },
            {
              "name": "test_failed_task_does_not_crash_scheduler",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 173
            }
          ],
          "line": 128
        },
        {
          "name": "TestStatus",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_status_shape",
              "params": [
                "self",
                "scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 193
            },
            {
              "name": "test_status_reflects_execution",
              "params": [
                "self",
                "bare_scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 207
            }
          ],
          "line": 192
        },
        {
          "name": "TestBlueprintValidation",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_task_registered",
              "params": [
                "self",
                "scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 228
            },
            {
              "name": "test_task_priority",
              "params": [
                "self",
                "scheduler"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 233
            },
            {
              "name": "test_extract_enums",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 237
            },
            {
              "name": "test_extract_endpoints",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 254
            },
            {
              "name": "test_extract_constants",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 271
            },
            {
              "name": "test_detects_stale_enum",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 287
            },
            {
              "name": "test_append_update_notes",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 308
            },
            {
              "name": "test_no_false_positives_when_current",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 325
            }
          ],
          "line": 227
        }
      ],
      "functions": [
        {
          "name": "config",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 20
        },
        {
          "name": "scheduler",
          "params": [
            "config"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 25
        },
        {
          "name": "bare_scheduler",
          "params": [
            "config"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 31
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.sleep_task_scheduler import SleepTask, SleepTaskScheduler"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_sleep_wake_manager.py": {
      "module_docstring": "Unit tests for the GAIA sleep/wake state machine.\n\nTests the 6-state + 2-phase lifecycle:\n    ACTIVE  DROWSY  ASLEEP  DREAMING / DISTRACTED / OFFLINE\n    Internal phases: _FINISHING_TASK, _WAKING\n\n",
      "classes": [
        {
          "name": "TestInitialState",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_starts_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 44
            },
            {
              "name": "test_no_pending_wake",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 47
            },
            {
              "name": "test_prime_not_available",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 50
            },
            {
              "name": "test_phase_none",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 53
            }
          ],
          "line": 43
        },
        {
          "name": "TestDrowsyThreshold",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_below_threshold",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 60
            },
            {
              "name": "test_at_threshold",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 63
            },
            {
              "name": "test_above_threshold",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "test_not_when_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 69
            },
            {
              "name": "test_not_when_dreaming",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 73
            },
            {
              "name": "test_not_when_distracted",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 77
            }
          ],
          "line": 59
        },
        {
          "name": "TestInitiateDrowsy",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_happy_path",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 85
            },
            {
              "name": "test_checkpoint_written",
              "params": [
                "self",
                "manager",
                "mock_config",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 91
            },
            {
              "name": "test_rejects_from_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 98
            },
            {
              "name": "test_rejects_from_dreaming",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 104
            },
            {
              "name": "test_rejects_from_distracted",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 109
            },
            {
              "name": "test_cancels_on_wake_during_checkpoint",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 114
            },
            {
              "name": "test_rotation_before_create",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 129
            },
            {
              "name": "test_previous_checkpoint_preserved_in_backup",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 148
            },
            {
              "name": "test_consumed_sentinel_cleared_on_new_checkpoint",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 163
            }
          ],
          "line": 84
        },
        {
          "name": "TestReceiveWakeSignal",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_wake_while_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 182
            },
            {
              "name": "test_wake_while_asleep_transitions_to_waking",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 187
            },
            {
              "name": "test_wake_while_asleep_non_interruptible",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 193
            },
            {
              "name": "test_wake_while_drowsy_sets_flag",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 200
            },
            {
              "name": "test_wake_while_dreaming_defers",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 205
            },
            {
              "name": "test_wake_while_distracted_notes",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 211
            }
          ],
          "line": 181
        },
        {
          "name": "TestCompleteWake",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_restores_from_checkpoint",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 221
            },
            {
              "name": "test_complete_wake_no_checkpoint",
              "params": [
                "self",
                "manager",
                "mock_config",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 235
            },
            {
              "name": "test_complete_wake_wrong_state",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 243
            },
            {
              "name": "test_complete_wake_marks_consumed",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 248
            },
            {
              "name": "test_complete_wake_no_consumed_when_no_checkpoint",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 257
            }
          ],
          "line": 220
        },
        {
          "name": "TestStatus",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_status_fields",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 270
            },
            {
              "name": "test_status_reflects_state_change",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 279
            },
            {
              "name": "test_status_includes_dreaming_handoff_id",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 284
            }
          ],
          "line": 269
        },
        {
          "name": "TestFormatCheckpoint",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_empty_checkpoint",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 295
            },
            {
              "name": "test_review_framing",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 299
            }
          ],
          "line": 294
        },
        {
          "name": "TestTransitionToWaking",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_from_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 310
            },
            {
              "name": "test_rejects_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 316
            }
          ],
          "line": 309
        },
        {
          "name": "TestCannedResponses",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_no_canned_when_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 325
            },
            {
              "name": "test_no_canned_when_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 328
            },
            {
              "name": "test_canned_when_dreaming",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 332
            },
            {
              "name": "test_canned_when_distracted",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 336
            }
          ],
          "line": 324
        },
        {
          "name": "TestDreamingTransition",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_enter_dreaming_from_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 344
            },
            {
              "name": "test_enter_dreaming_rejects_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 351
            },
            {
              "name": "test_exit_dreaming_to_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 356
            },
            {
              "name": "test_exit_dreaming_triggers_pending_wake",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 364
            },
            {
              "name": "test_exit_dreaming_rejects_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 372
            }
          ],
          "line": 343
        },
        {
          "name": "TestDistractedTransition",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_enter_distracted_from_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 380
            },
            {
              "name": "test_enter_distracted_rejects_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 386
            },
            {
              "name": "test_exit_distracted_to_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 391
            },
            {
              "name": "test_exit_distracted_triggers_pending_wake",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 398
            },
            {
              "name": "test_exit_distracted_rejects_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 406
            }
          ],
          "line": 379
        },
        {
          "name": "TestOffline",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_offline_from_active",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 414
            },
            {
              "name": "test_offline_from_asleep",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 419
            },
            {
              "name": "test_offline_from_dreaming",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 424
            },
            {
              "name": "test_offline_from_distracted",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 429
            }
          ],
          "line": 413
        },
        {
          "name": "TestLLMCheckpoint",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_llm_checkpoint_with_model_pool",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 438
            },
            {
              "name": "test_llm_fallback_on_no_lite_model",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 458
            },
            {
              "name": "test_llm_fallback_on_exception",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 471
            },
            {
              "name": "test_template_without_model_pool",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 486
            }
          ],
          "line": 437
        },
        {
          "name": "TestCheckpointConsumed",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_is_consumed_false_initially",
              "params": [
                "self",
                "manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 498
            },
            {
              "name": "test_mark_consumed_creates_sentinel",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 501
            },
            {
              "name": "test_create_checkpoint_clears_consumed",
              "params": [
                "self",
                "manager",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 507
            }
          ],
          "line": 497
        },
        {
          "name": "TestDrowsyCancelBehavior",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_early_cancel_skips_checkpoint_entirely",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 519
            },
            {
              "name": "test_late_cancel_marks_checkpoint_consumed",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 535
            }
          ],
          "line": 518
        },
        {
          "name": "TestWakeSignalIdleMonitor",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_receive_wake_signal_resets_idle_monitor",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 560
            },
            {
              "name": "test_receive_wake_signal_without_idle_monitor",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 570
            },
            {
              "name": "test_wake_signal_while_active_does_not_reset_idle",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 579
            },
            {
              "name": "test_wake_signal_during_drowsy_resets_idle",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 594
            }
          ],
          "line": 559
        }
      ],
      "functions": [
        {
          "name": "mock_config",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 28
        },
        {
          "name": "manager",
          "params": [
            "mock_config"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 37
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.sleep_wake_manager import GaiaState, SleepWakeManager, _TransientPhase, CANNED_DREAMING, CANNED_DISTRACTED"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_stream_observer.py": {
      "module_docstring": "Unit tests for StreamObserver.verify_side_effects.\n\nTests the post-execution verification layer that checks whether side\neffects reported by route_output() actually produced the expected\nartifacts (fi",
      "classes": [
        {
          "name": "DummyLLM",
          "bases": [],
          "docstring": "Minimal LLM stub that satisfies StreamObserver.__init__.",
          "methods": [
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 49
            }
          ],
          "line": 46
        }
      ],
      "functions": [
        {
          "name": "_make_packet",
          "params": [],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 53
        },
        {
          "name": "mock_config",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 83
        },
        {
          "name": "observer",
          "params": [
            "mock_config"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 94
        },
        {
          "name": "packet",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 99
        },
        {
          "name": "test_verify_thought_seed_file_exists",
          "params": [
            "observer",
            "packet",
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 106
        },
        {
          "name": "test_verify_thought_seed_file_missing",
          "params": [
            "observer",
            "packet",
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 124
        },
        {
          "name": "test_verify_thought_seed_file_empty",
          "params": [
            "observer",
            "packet",
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 139
        },
        {
          "name": "test_verify_sidecar_action_success",
          "params": [
            "observer",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 157
        },
        {
          "name": "test_verify_sidecar_action_error",
          "params": [
            "observer",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 171
        },
        {
          "name": "test_verify_goal_shift_ok",
          "params": [
            "observer",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 187
        },
        {
          "name": "test_verify_no_side_effects",
          "params": [
            "observer",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 201
        },
        {
          "name": "test_verify_disabled_by_config",
          "params": [
            "mock_config",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 211
        },
        {
          "name": "test_verify_fallback_thought_seed",
          "params": [
            "observer",
            "packet",
            "tmp_path",
            "monkeypatch"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 229
        },
        {
          "name": "test_verify_appends_reflection_log",
          "params": [
            "observer",
            "packet"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 261
        },
        {
          "name": "test_verify_multiple_issues",
          "params": [
            "observer",
            "packet",
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 280
        },
        {
          "name": "test_verify_no_packet_returns_ok",
          "params": [
            "observer"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 300
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Constraints, Content, Context, Governance, Header, Intent, Metrics, Model, Persona, PersonaRole, Reasoning, ReflectionLog, Response, Routing, Safety, SessionHistoryRef, Status, PacketState, TargetEngine, SystemTask, TokenUsage",
        "from gaia_core.utils.stream_observer import StreamObserver, Interrupt"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_temporal_context.py": {
      "module_docstring": "Tests for the Temporal Context Builder.",
      "classes": [
        {
          "name": "TestSemanticTime",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_includes_day_of_week",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 20
            },
            {
              "name": "test_morning",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 26
            },
            {
              "name": "test_afternoon",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 30
            },
            {
              "name": "test_evening",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 34
            },
            {
              "name": "test_night",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 38
            },
            {
              "name": "test_early_morning",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 42
            }
          ],
          "line": 19
        },
        {
          "name": "TestFormatDuration",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_sub_minute",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 48
            },
            {
              "name": "test_minutes",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 51
            },
            {
              "name": "test_hours_and_minutes",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 54
            },
            {
              "name": "test_exact_hours",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 57
            }
          ],
          "line": 47
        },
        {
          "name": "TestSessionSummary",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_full_session",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 62
            },
            {
              "name": "test_no_data_returns_empty",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 71
            }
          ],
          "line": 61
        },
        {
          "name": "TestStateSummary",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_active_state",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 76
            },
            {
              "name": "test_empty_returns_empty",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 81
            }
          ],
          "line": 75
        },
        {
          "name": "TestCodeEvolutionSummary",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_reads_snapshot",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 86
            },
            {
              "name": "test_no_changes",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 100
            },
            {
              "name": "test_missing_file",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 106
            }
          ],
          "line": 85
        },
        {
          "name": "TestBuildTemporalContext",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_minimal_output",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 112
            },
            {
              "name": "test_with_session_data",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 118
            },
            {
              "name": "test_graceful_with_broken_timeline",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 129
            }
          ],
          "line": 111
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.utils.temporal_context import _format_duration, _semantic_time, _session_summary, _state_summary, _code_evolution_summary, build_temporal_context"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_temporal_interviewer.py": {
      "module_docstring": "Tests for TemporalInterviewer  Prime interviews past-Lite via KV cache swapping.",
      "classes": [
        {
          "name": "FakeLlamaState",
          "bases": [],
          "docstring": "Picklable stand-in for llama_cpp.LlamaState.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "label: str = 'default'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 24
            }
          ],
          "line": 21
        },
        {
          "name": "TestInterviewTargetSelection",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_selects_oldest_uninterviewed_state",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 136
            },
            {
              "name": "test_skips_most_recent_state",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 142
            },
            {
              "name": "test_falls_back_to_already_interviewed",
              "params": [
                "self",
                "interviewer",
                "tsm_with_states"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 155
            },
            {
              "name": "test_returns_none_with_no_states",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 170
            }
          ],
          "line": 135
        },
        {
          "name": "TestInterviewFlow",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_full_interview_cycle",
              "params": [
                "self",
                "interviewer",
                "mock_llm",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 185
            },
            {
              "name": "test_state_restored_on_interview_error",
              "params": [
                "self",
                "interviewer",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 212
            },
            {
              "name": "test_returns_none_without_model_pool",
              "params": [
                "self",
                "mock_config",
                "tsm_with_states"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 223
            },
            {
              "name": "test_returns_none_without_tsm",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 231
            }
          ],
          "line": 184
        },
        {
          "name": "TestLockBehavior",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_interview_holds_lite_lock",
              "params": [
                "self",
                "interviewer",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 244
            },
            {
              "name": "test_lock_released_after_interview",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 291
            }
          ],
          "line": 243
        },
        {
          "name": "TestNarrativeCoherence",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_coherence_analysis_called",
              "params": [
                "self",
                "interviewer",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 307
            },
            {
              "name": "test_coherence_parsing",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 320
            },
            {
              "name": "test_coherence_graceful_on_parse_failure",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 340
            }
          ],
          "line": 306
        },
        {
          "name": "TestTranscriptStorage",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_transcript_saved_as_json",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 354
            },
            {
              "name": "test_transcript_contains_all_rounds",
              "params": [
                "self",
                "interviewer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 367
            },
            {
              "name": "test_transcript_dir_created",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "tsm_with_states"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 376
            }
          ],
          "line": 353
        },
        {
          "name": "FakeConfig",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 390
        },
        {
          "name": "TestHeartbeatIntegration",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_interview_triggered_on_interval",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 402
            },
            {
              "name": "test_interview_not_triggered_off_interval",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 420
            },
            {
              "name": "test_interview_skipped_when_sleeping",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 435
            },
            {
              "name": "test_interview_failure_doesnt_crash_heartbeat",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 453
            }
          ],
          "line": 401
        }
      ],
      "functions": [
        {
          "name": "mock_config",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 33
        },
        {
          "name": "mock_llm",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 46
        },
        {
          "name": "mock_model_pool",
          "params": [
            "mock_llm"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 58
        },
        {
          "name": "_create_baked_state",
          "params": [
            "state_dir: Path",
            "ts_label: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 67
        },
        {
          "name": "tsm_with_states",
          "params": [
            "mock_config",
            "mock_model_pool",
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 89
        },
        {
          "name": "mock_journal",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 104
        },
        {
          "name": "mock_timeline",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 117
        },
        {
          "name": "interviewer",
          "params": [
            "mock_config",
            "mock_model_pool",
            "tsm_with_states",
            "mock_journal",
            "mock_timeline"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 122
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.temporal_interviewer import TemporalInterviewer"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/tests/test_temporal_state_manager.py": {
      "module_docstring": "Tests for TemporalStateManager  KV cache state baking and restoration.",
      "classes": [
        {
          "name": "FakeLlamaState",
          "bases": [],
          "docstring": "Picklable stand-in for llama_cpp.LlamaState.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 21
            }
          ],
          "line": 19
        },
        {
          "name": "TestStateDirectory",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_creates_state_dir",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 83
            },
            {
              "name": "test_list_states_empty",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 88
            }
          ],
          "line": 82
        },
        {
          "name": "TestBakeState",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_bake_creates_bin_file",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 97
            },
            {
              "name": "test_bake_creates_json_sidecar",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 107
            },
            {
              "name": "test_bake_returns_none_without_llm",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 119
            },
            {
              "name": "test_bake_returns_none_without_model_pool",
              "params": [
                "self",
                "mock_config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 126
            },
            {
              "name": "test_bake_state_is_picklable",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 130
            },
            {
              "name": "test_bake_includes_journal_content",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_llm",
                "mock_journal"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 139
            }
          ],
          "line": 96
        },
        {
          "name": "TestLoadState",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_load_existing_state",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 159
            },
            {
              "name": "test_load_nonexistent_returns_false",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 171
            },
            {
              "name": "test_corrupt_state_renamed",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 175
            },
            {
              "name": "test_restore_current_loads_latest",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_llm"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 192
            }
          ],
          "line": 158
        },
        {
          "name": "TestRotation",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_cleanup_enforces_max_files",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 206
            },
            {
              "name": "test_cleanup_enforces_max_bytes",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 222
            },
            {
              "name": "test_cleanup_deletes_sidecar_too",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 241
            }
          ],
          "line": 205
        },
        {
          "name": "TestContextReconstruction",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_reconstruct_timeline_context",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_timeline"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 261
            },
            {
              "name": "test_reconstruct_conversation_context",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool",
                "mock_session_manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 280
            },
            {
              "name": "test_list_states_with_metadata",
              "params": [
                "self",
                "mock_config",
                "mock_model_pool"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 301
            }
          ],
          "line": 260
        }
      ],
      "functions": [
        {
          "name": "mock_config",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 26
        },
        {
          "name": "mock_llm",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 36
        },
        {
          "name": "mock_model_pool",
          "params": [
            "mock_llm"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 48
        },
        {
          "name": "mock_timeline",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 55
        },
        {
          "name": "mock_session_manager",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 64
        },
        {
          "name": "mock_journal",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 72
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.cognition.temporal_state_manager import TemporalStateManager"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "cognition/thought_seed.py": {
      "module_docstring": "Thought Seed System (GAIA pillar-compliant).\n- Saves, stores, reviews, and processes thought seeds.\n- Seeds are now generated by the main LLM via the THOUGHT_SEED: directive\n- and parsed by the output",
      "classes": [],
      "functions": [
        {
          "name": "save_thought_seed",
          "params": [
            "seed_text: str",
            "packet: CognitionPacket",
            "config: Config"
          ],
          "return_type": "Dict[str, Any] | None",
          "decorators": [],
          "is_async": false,
          "line": 31
        },
        {
          "name": "list_unreviewed_seeds",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 69
        },
        {
          "name": "get_seed_by_id",
          "params": [
            "seed_id: str"
          ],
          "return_type": "Dict[str, Any] | None",
          "decorators": [],
          "is_async": false,
          "line": 84
        },
        {
          "name": "update_seed",
          "params": [
            "seed_id: str",
            "seed_data: Dict[str, Any]"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 99
        },
        {
          "name": "review_and_process_seeds",
          "params": [
            "config = None",
            "llm = None",
            "auto_act = False"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 111
        },
        {
          "name": "refine_seed",
          "params": [
            "seed_id",
            "refinement_prompt",
            "config = None",
            "llm = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 162
        },
        {
          "name": "link_seeds",
          "params": [
            "source_seed_id",
            "target_seed_id",
            "relationship"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 198
        },
        {
          "name": "maybe_review_seeds",
          "params": [
            "config",
            "llm = None"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 213
        },
        {
          "name": "archive_seed",
          "params": [
            "seed_filename: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 225
        },
        {
          "name": "defer_seed",
          "params": [
            "seed_filename: str",
            "revisit_after: str | None = None"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 252
        },
        {
          "name": "list_pending_seeds_due",
          "params": [],
          "return_type": "list[tuple[Path, dict]]",
          "decorators": [],
          "is_async": false,
          "line": 282
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config",
        "from gaia_common.protocols.cognition_packet import CognitionPacket",
        "from gaia_common.utils.thoughtstream import write"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "save_thought_seed",
          "line": 64
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_seed_by_id",
          "line": 94
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "update_seed",
          "line": 106
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "refine_seed",
          "line": 193
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "archive_seed",
          "line": 247
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "defer_seed",
          "line": 277
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "save_thought_seed",
          "line": 41
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "list_unreviewed_seeds",
          "line": 79
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "review_and_process_seeds",
          "line": 157
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "list_pending_seeds_due",
          "line": 332
        },
        {
          "exception_types": [
            "ValueError",
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "list_pending_seeds_due",
          "line": 308
        },
        {
          "exception_types": [
            "ValueError",
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "list_pending_seeds_due",
          "line": 316
        }
      ],
      "http_calls": []
    },
    "cognition/tool_selector.py": {
      "module_docstring": "Tool Selector Module\n\nResponsible for:\n1. Determining if a request needs MCP tool usage\n2. Selecting the appropriate tool with low-temperature generation\n3. Extracting structured parameters\n4. Providi",
      "classes": [],
      "functions": [
        {
          "name": "_structured_json_kwargs",
          "params": [
            "model: Any",
            "schema: Dict[str, Any]"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 52
        },
        {
          "name": "_registry_to_catalog",
          "params": [
            "registry: Dict[str, Any]"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 85
        },
        {
          "name": "needs_tool_routing",
          "params": [
            "packet: CognitionPacket",
            "user_input: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 159
        },
        {
          "name": "select_tool",
          "params": [
            "packet: CognitionPacket",
            "user_input: str",
            "model",
            "temperature: float = 0.15"
          ],
          "return_type": "Tuple[Optional[SelectedTool], List[SelectedTool]]",
          "decorators": [],
          "is_async": false,
          "line": 201
        },
        {
          "name": "review_selection",
          "params": [
            "packet: CognitionPacket",
            "selected_tool: SelectedTool",
            "model",
            "temperature: float = 0.3"
          ],
          "return_type": "Tuple[float, str]",
          "decorators": [],
          "is_async": false,
          "line": 315
        },
        {
          "name": "_build_tool_catalog",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 394
        },
        {
          "name": "_extract_content",
          "params": [
            "result"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 412
        },
        {
          "name": "_extract_json_from_response",
          "params": [
            "content: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 423
        },
        {
          "name": "initialize_tool_routing",
          "params": [
            "packet: CognitionPacket"
          ],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 448
        },
        {
          "name": "inject_tool_result_into_packet",
          "params": [
            "packet: CognitionPacket"
          ],
          "return_type": "CognitionPacket",
          "decorators": [],
          "is_async": false,
          "line": 459
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, SelectedTool, ToolRoutingState, ToolExecutionStatus, ToolExecutionResult, ReflectionLog, DataField, Sketchpad",
        "from gaia_common.utils.tools_registry import TOOLS"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "json.JSONDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "select_tool",
          "line": 307
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "select_tool",
          "line": 310
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "review_selection",
          "line": 385
        }
      ],
      "http_calls": []
    },
    "cognition/topic_manager.py": {
      "module_docstring": "Manages the creation, update, resolution, prioritization, and pruning of GAIA's topic cache.\n\nSupports the Initiative Loop (GIL) by maintaining a prioritized, well-structured list of emergent discussi",
      "classes": [],
      "functions": [
        {
          "name": "_load_topic_cache",
          "params": [
            "path: str"
          ],
          "return_type": "List[Dict[str, Any]]",
          "decorators": [],
          "is_async": false,
          "line": 20
        },
        {
          "name": "_save_topic_cache",
          "params": [
            "path: str",
            "cache: List[Dict[str, Any]]"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 31
        },
        {
          "name": "add_topic",
          "params": [
            "path: str",
            "topic: Dict[str, Any]"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 39
        },
        {
          "name": "resolve_topic",
          "params": [
            "path: str",
            "topic_id: str"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 54
        },
        {
          "name": "update_topic",
          "params": [
            "path: str",
            "topic_id: str",
            "updates: Dict[str, Any]"
          ],
          "return_type": "bool",
          "decorators": [],
          "is_async": false,
          "line": 66
        },
        {
          "name": "prune_resolved_topics",
          "params": [
            "path: str"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 77
        },
        {
          "name": "list_topics",
          "params": [
            "path: str",
            "include_resolved: bool = False"
          ],
          "return_type": "List[Dict[str, Any]]",
          "decorators": [],
          "is_async": false,
          "line": 84
        },
        {
          "name": "prioritize_topics",
          "params": [
            "path: str",
            "top_n: Optional[int] = 5"
          ],
          "return_type": "List[Dict[str, Any]]",
          "decorators": [],
          "is_async": false,
          "line": 90
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "FileNotFoundError"
          ],
          "status_code": null,
          "enclosing_function": "_load_topic_cache",
          "line": 24
        },
        {
          "exception_types": [
            "json.JSONDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "_load_topic_cache",
          "line": 27
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save_topic_cache",
          "line": 36
        }
      ],
      "http_calls": []
    },
    "config.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "Config",
          "bases": [],
          "docstring": "A simplified configuration class for gaia-core.\nValues should be injected at runtime or loaded from ",
          "methods": [
            {
              "name": "__post_init__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 87
            },
            {
              "name": "_load_constants",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 93
            },
            {
              "name": "get_api_key",
              "params": [
                "self",
                "provider: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 154
            },
            {
              "name": "get_persona_instructions",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 158
            },
            {
              "name": "get_model_name",
              "params": [
                "self",
                "model_alias: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 165
            },
            {
              "name": "get_instance",
              "params": [
                "cls"
              ],
              "return_type": "Config",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 169
            },
            {
              "name": "_load_cheat_sheet",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 174
            }
          ],
          "line": 12
        }
      ],
      "functions": [
        {
          "name": "get_config",
          "params": [],
          "return_type": "Config",
          "decorators": [],
          "is_async": false,
          "line": 190
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "FileNotFoundError"
          ],
          "status_code": null,
          "enclosing_function": "_load_cheat_sheet",
          "line": 179
        },
        {
          "exception_types": [
            "json.JSONDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "_load_cheat_sheet",
          "line": 182
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_cheat_sheet",
          "line": 185
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_constants",
          "line": 149
        }
      ],
      "http_calls": []
    },
    "ethics/__init__.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "ethics/consent_protocol.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "ConsentProtocol",
          "bases": [],
          "docstring": "Verifies GAIA's explicit consent to operate under current identity, context, and system state.\nMust ",
          "methods": [
            {
              "name": "request_consent",
              "params": [
                "reason = 'Initial boot'"
              ],
              "return_type": "bool",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 18
            }
          ],
          "line": 11
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config",
        "from gaia_core.ethics.core_identity_guardian import CoreIdentityGuardian",
        "from gaia_core.ethics.ethical_sentinel import EthicalSentinel",
        "from gaia_core.memory.status_tracker import GAIAStatus",
        "from gaia_core.cognition.self_reflection import run_self_reflection"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "request_consent",
          "line": 52
        }
      ],
      "http_calls": []
    },
    "ethics/core_identity_guardian.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "CoreIdentityGuardian",
          "bases": [],
          "docstring": "Verifies prompt behavior and session instructions against GAIA's immutable Tier I identity.\nOperates",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 14
            },
            {
              "name": "load_identity",
              "params": [
                "self"
              ],
              "return_type": "Optional[dict]",
              "decorators": [],
              "is_async": false,
              "line": 19
            },
            {
              "name": "validate_prompt_stack",
              "params": [
                "self",
                "persona_traits: dict",
                "instructions: List[str]",
                "prompt: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 39
            }
          ],
          "line": 8
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_identity",
          "line": 35
        }
      ],
      "http_calls": []
    },
    "ethics/ethical_sentinel.py": {
      "module_docstring": "ethics/ethical_sentinel.py\n\nThe Ethical Sentinel monitors system health and cognitive strain for GAIA.",
      "classes": [
        {
          "name": "EthicalSentinel",
          "bases": [],
          "docstring": "Monitors system health, loop safety, error logs, and optionally Tier I identity violations.\nWorks al",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "identity_guardian = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 19
            },
            {
              "name": "check_system_resources",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 27
            },
            {
              "name": "check_loop_counter",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 40
            },
            {
              "name": "check_recent_errors",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 50
            },
            {
              "name": "register_error",
              "params": [
                "self",
                "exc: Exception"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 57
            },
            {
              "name": "reset_loop",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "run_full_safety_check",
              "params": [
                "self",
                "persona_traits = None",
                "instructions = None",
                "prompt = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 70
            }
          ],
          "line": 13
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_full_safety_check",
          "line": 87
        }
      ],
      "http_calls": []
    },
    "integrations/discord_connector.py": {
      "module_docstring": "Discord Connector for GAIA Spinal Column\n\nThis module provides Discord integration as both:\n- Output destination (send responses to Discord channels via webhook or bot)\n- Input source (listen for @GAI",
      "classes": [
        {
          "name": "DiscordConnector",
          "bases": [
            "DestinationConnector"
          ],
          "docstring": "Discord connector for the GAIA spinal column.\nSupports both webhook output and (future) bot-based bi",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Optional[DiscordConfig] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 31
            },
            {
              "name": "send",
              "params": [
                "self",
                "content: str",
                "target: DestinationTarget",
                "packet: Optional[CognitionPacket] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 53
            },
            {
              "name": "send_stream",
              "params": [
                "self",
                "token_generator: Generator[str, None, None]",
                "target: DestinationTarget",
                "packet: Optional[CognitionPacket] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 74
            },
            {
              "name": "is_available",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 85
            },
            {
              "name": "_send_via_webhook",
              "params": [
                "self",
                "content: str",
                "target: DestinationTarget",
                "packet: Optional[CognitionPacket] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 89
            },
            {
              "name": "_send_via_bot",
              "params": [
                "self",
                "content: str",
                "target: DestinationTarget",
                "packet: Optional[CognitionPacket] = None"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 98
            },
            {
              "name": "_split_message_for_discord",
              "params": [
                "self",
                "content: str"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 178
            },
            {
              "name": "_is_bot_connected",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 207
            },
            {
              "name": "set_message_callback",
              "params": [
                "self",
                "callback: Callable[[str, str, Dict[str, Any]], None]"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 211
            },
            {
              "name": "generate_dm_session_id",
              "params": [
                "user_id: str"
              ],
              "return_type": "str",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 222
            },
            {
              "name": "is_dm_session",
              "params": [
                "session_id: str"
              ],
              "return_type": "bool",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 227
            },
            {
              "name": "start_bot_listener",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 231
            },
            {
              "name": "stop_bot_listener",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 352
            }
          ],
          "line": 25
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.integrations.discord import DiscordConfig, DiscordWebhookSender",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, OutputDestination, DestinationTarget",
        "from gaia_common.utils.destination_registry import DestinationConnector"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "send",
          "line": 70
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_send_via_bot",
          "line": 174
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "start_bot_listener",
          "line": 246
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_bot",
          "line": 340
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_send",
          "line": 131
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_send",
          "line": 149
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_on_send_done",
          "line": 166
        }
      ],
      "http_calls": []
    },
    "main.py": {
      "module_docstring": "gaia-core FastAPI application entry point.\n\nProvides the HTTP API for the cognitive loop service.\nThis is The Brain - Cognitive loop and reasoning.",
      "classes": [
        {
          "name": "AIManagerShim",
          "bases": [],
          "docstring": "A lightweight shim providing the interface AgentCore expects from ai_manager.\n\nAgentCore requires:\n-",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "model_pool",
                "session_manager"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 44
            },
            {
              "name": "initialize",
              "params": [
                "self",
                "persona_name: str = 'prime'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 56
            }
          ],
          "line": 31
        },
        {
          "name": "MinimalPersona",
          "bases": [],
          "docstring": "Minimal persona object when full persona loading fails or from dict data.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "name: str",
                "data: Dict[str, Any] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 80
            }
          ],
          "line": 78
        }
      ],
      "functions": [
        {
          "name": "initialize_cognitive_system",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 105
        },
        {
          "name": "lifespan",
          "params": [
            "app: FastAPI"
          ],
          "return_type": null,
          "decorators": [
            "asynccontextmanager"
          ],
          "is_async": true,
          "line": 159
        },
        {
          "name": "_write_shutdown_checkpoints",
          "params": [
            "app: FastAPI"
          ],
          "return_type": "dict",
          "decorators": [],
          "is_async": false,
          "line": 218
        },
        {
          "name": "health_check",
          "params": [],
          "return_type": null,
          "decorators": [
            "app.get('/health')"
          ],
          "is_async": true,
          "line": 285
        },
        {
          "name": "root",
          "params": [],
          "return_type": null,
          "decorators": [
            "app.get('/')"
          ],
          "is_async": true,
          "line": 297
        },
        {
          "name": "get_status",
          "params": [],
          "return_type": null,
          "decorators": [
            "app.get('/status')"
          ],
          "is_async": true,
          "line": 321
        },
        {
          "name": "cognition_checkpoint",
          "params": [],
          "return_type": null,
          "decorators": [
            "app.post('/cognition/checkpoint')"
          ],
          "is_async": true,
          "line": 355
        },
        {
          "name": "process_packet",
          "params": [
            "packet_data: Dict[str, Any]"
          ],
          "return_type": null,
          "decorators": [
            "app.post('/process_packet')"
          ],
          "is_async": true,
          "line": 370
        }
      ],
      "endpoints": [
        {
          "method": "GET",
          "path": "/health",
          "function_name": "health_check",
          "line": 285
        },
        {
          "method": "GET",
          "path": "/",
          "function_name": "root",
          "line": 297
        },
        {
          "method": "GET",
          "path": "/status",
          "function_name": "get_status",
          "line": 321
        },
        {
          "method": "POST",
          "path": "/cognition/checkpoint",
          "function_name": "cognition_checkpoint",
          "line": 355
        },
        {
          "method": "POST",
          "path": "/process_packet",
          "function_name": "process_packet",
          "line": 370
        }
      ],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.api.gpu_endpoints import router",
        "from gaia_core.api.sleep_endpoints import router"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 23
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialize_cognitive_system",
          "line": 153
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "lifespan",
          "line": 200
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "lifespan",
          "line": 209
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_write_shutdown_checkpoints",
          "line": 240
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_write_shutdown_checkpoints",
          "line": 261
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": 500,
          "enclosing_function": "process_packet",
          "line": 466
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialize",
          "line": 72
        }
      ],
      "http_calls": []
    },
    "memory/__init__.py": {
      "module_docstring": "gaia_core.memory - Memory and state management modules.\n\nThis package provides:\n- dev_matrix: Development matrix for tracking agent state\n- conversation: Conversation memory subpackage",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/codex_writer.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "CodexWriter",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Config",
                "semantic_codex: SemanticCodex"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 12
            },
            {
              "name": "document_information",
              "params": [
                "self",
                "packet: CognitionPacket",
                "info_to_document: str",
                "symbol: str",
                "title: str",
                "tags: Optional[List[str]] = None",
                "llm_model: Optional[Model] = None"
              ],
              "return_type": "Optional[Path]",
              "decorators": [],
              "is_async": false,
              "line": 25
            },
            {
              "name": "_refine_with_llm",
              "params": [
                "self",
                "raw_info: str",
                "llm_model: Model",
                "packet: CognitionPacket",
                "symbol: str",
                "title: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 80
            }
          ],
          "line": 11
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.memory.semantic_codex import SemanticCodex, CodexEntry",
        "from gaia_core.config import Config",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, Model"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 21
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "document_information",
          "line": 76
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_refine_with_llm",
          "line": 115
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "document_information",
          "line": 57
        }
      ],
      "http_calls": []
    },
    "memory/conversation/__init__.py": {
      "module_docstring": "gaia_core.memory.conversation - Conversation memory management.\n\nThis package provides:\n- summarizer: Conversation summarization for context management",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/conversation/archiver.py": {
      "module_docstring": "conversation/archiver.py\n\nHandles saving and loading archived conversations in Markdown format.\nManages storage, file formatting, and retrieval operations.",
      "classes": [
        {
          "name": "ConversationArchiver",
          "bases": [],
          "docstring": "Saves a conversation history to disk, structured by persona + session ID.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 22
            },
            {
              "name": "archive_conversation",
              "params": [
                "self",
                "session_id: str",
                "persona: str",
                "messages: List[dict]",
                "summary: str",
                "keywords: List[str]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 25
            }
          ],
          "line": 17
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "archive_conversation",
          "line": 45
        }
      ],
      "http_calls": []
    },
    "memory/conversation/keywords.py": {
      "module_docstring": "conversation/keywords.py\n\nHandles keyword extraction from conversation history.\nLightweight heuristics for identifying important terms.",
      "classes": [
        {
          "name": "ConversationKeywordExtractor",
          "bases": [],
          "docstring": "Extracts high-value keywords from a conversation history.",
          "methods": [
            {
              "name": "extract_keywords",
              "params": [
                "self",
                "messages: List[dict]",
                "max_keywords: int = 10"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 28
            }
          ],
          "line": 23
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "extract_keywords",
          "line": 44
        }
      ],
      "http_calls": []
    },
    "memory/conversation/manager.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "ConversationManager",
          "bases": [],
          "docstring": "Tracks user-assistant message history and triggers summarization + archiving\nafter N messages. Suppo",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "llm = None",
                "embed_model = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 21
            },
            {
              "name": "set_persona",
              "params": [
                "self",
                "persona: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 32
            },
            {
              "name": "add_message",
              "params": [
                "self",
                "role: str",
                "content: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 35
            },
            {
              "name": "get_recent_messages",
              "params": [
                "self",
                "count: int = 10"
              ],
              "return_type": "List[dict]",
              "decorators": [],
              "is_async": false,
              "line": 42
            },
            {
              "name": "summarize_and_archive",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 45
            },
            {
              "name": "reset",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 71
            },
            {
              "name": "build_smart_history",
              "params": [
                "self",
                "current_input: str",
                "max_recent: int = 3",
                "max_salient: int = 2"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 77
            }
          ],
          "line": 15
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.memory.conversation.summarizer import ConversationSummarizer",
        "from gaia_core.memory.conversation.keywords import ConversationKeywordExtractor",
        "from gaia_core.memory.conversation.archiver import ConversationArchiver"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 68
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 55
        }
      ],
      "http_calls": []
    },
    "memory/conversation/summarizer.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "ConversationSummarizer",
          "bases": [],
          "docstring": "Uses the LLM to summarize a conversation history.\nFalls back to placeholder text if no LLM is availa",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "llm = None",
                "embed_model = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 33
            },
            {
              "name": "generate_summary",
              "params": [
                "self",
                "messages: List[dict]",
                "packet: object = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 52
            },
            {
              "name": "build_smart_history",
              "params": [
                "self",
                "full_history: List[Dict]",
                "current_input: str",
                "max_recent: int = 3",
                "max_salient: int = 2"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 316
            }
          ],
          "line": 27
        }
      ],
      "functions": [
        {
          "name": "_get_model_pool",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 14
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config",
        "from gaia_core.utils import mcp_client"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_model_pool",
          "line": 24
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 49
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 312
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_smart_history",
          "line": 356
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 81
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 88
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 99
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 154
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 177
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 202
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 218
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 238
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 66
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 106
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 249
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 261
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 200
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 278
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 288
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 303
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 133
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 175
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 216
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 152
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 267
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "generate_summary",
          "line": 172
        }
      ],
      "http_calls": [
        {
          "call_method": "post",
          "url_or_path": "endpoint",
          "enclosing_function": "generate_summary",
          "line": 209
        },
        {
          "call_method": "get",
          "url_or_path": "url",
          "enclosing_function": "generate_summary",
          "line": 166
        }
      ]
    },
    "memory/dev_matrix.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "GAIADevMatrix",
          "bases": [],
          "docstring": "Persistent manager for GAIA's self-development tasks.\nStores and retrieves structured roadmap tasks.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 13
            },
            {
              "name": "_load",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 19
            },
            {
              "name": "_save",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 27
            },
            {
              "name": "add_task",
              "params": [
                "self",
                "label: str",
                "purpose: str",
                "urgency: str = 'medium'",
                "impact: str = 'medium'",
                "source: str = 'manual'"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 34
            },
            {
              "name": "get_open_tasks",
              "params": [
                "self"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 47
            },
            {
              "name": "resolve_task",
              "params": [
                "self",
                "label: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 50
            },
            {
              "name": "dump",
              "params": [
                "self"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 59
            }
          ],
          "line": 7
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save",
          "line": 31
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load",
          "line": 24
        }
      ],
      "http_calls": []
    },
    "memory/knowledge_integrity.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "hash_file",
          "params": [
            "filepath"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 5
        },
        {
          "name": "check_or_generate_hash_manifest",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 12
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/memory_manager.py": {
      "module_docstring": "MemoryManager facade to unify short-term, session, and long-term memory.\n\nShort-term: in-process dict (fast cache)\nWorking: SessionManager (persistent session history)\nLong-term: VectorIndexer via MCP",
      "classes": [
        {
          "name": "MemoryManager",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 20
            },
            {
              "name": "instance",
              "params": [
                "cls",
                "config: Config = None"
              ],
              "return_type": "'MemoryManager'",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 27
            },
            {
              "name": "set_short",
              "params": [
                "self",
                "key: str",
                "value: Any"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 33
            },
            {
              "name": "get_short",
              "params": [
                "self",
                "key: str",
                "default = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 36
            },
            {
              "name": "add_message",
              "params": [
                "self",
                "session_id: str",
                "role: str",
                "content: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 40
            },
            {
              "name": "get_history",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 43
            },
            {
              "name": "query_long",
              "params": [
                "self",
                "query: str",
                "top_k: int = 5"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 47
            }
          ],
          "line": 17
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.memory.session_manager import SessionManager",
        "from gaia_core.config import Config, get_config",
        "from gaia_core.utils import mcp_client"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/priority_manager.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "GAIAPriorityManager",
          "bases": [],
          "docstring": "Centralized persistent task and priority memory for GAIA.\nTracks open tasks from all sources (manual",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 12
            },
            {
              "name": "_load",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 18
            },
            {
              "name": "_save",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 26
            },
            {
              "name": "add_task",
              "params": [
                "self",
                "label: str",
                "details: str",
                "urgency: str = 'medium'",
                "impact: str = 'medium'",
                "source: str = 'manual'"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 33
            },
            {
              "name": "get_open_tasks",
              "params": [
                "self"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 46
            },
            {
              "name": "get_top_tasks",
              "params": [
                "self",
                "limit: int = 5"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 49
            },
            {
              "name": "resolve_task",
              "params": [
                "self",
                "label: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 57
            },
            {
              "name": "clear_resolved",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "dump",
              "params": [
                "self"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 70
            }
          ],
          "line": 6
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save",
          "line": 30
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load",
          "line": 23
        }
      ],
      "http_calls": []
    },
    "memory/semantic_codex.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "CodexEntry",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 14
        },
        {
          "name": "SemanticCodex",
          "bases": [],
          "docstring": "Side-car memory for semantically compressed concepts.\nLoads JSON/YAML files from Config.KNOWLEDGE_CO",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 30
            },
            {
              "name": "instance",
              "params": [
                "cls",
                "config"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 39
            },
            {
              "name": "write_entry",
              "params": [
                "self",
                "entry: CodexEntry"
              ],
              "return_type": "Path",
              "decorators": [],
              "is_async": false,
              "line": 45
            },
            {
              "name": "_iter_files",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 90
            },
            {
              "name": "_checksum",
              "params": [
                "self",
                "path: Path"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 97
            },
            {
              "name": "_load_one",
              "params": [
                "self",
                "path: Path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 103
            },
            {
              "name": "_load_all",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 185
            },
            {
              "name": "hot_reload",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 192
            },
            {
              "name": "get",
              "params": [
                "self",
                "symbol: str"
              ],
              "return_type": "Optional[CodexEntry]",
              "decorators": [],
              "is_async": false,
              "line": 219
            },
            {
              "name": "search",
              "params": [
                "self",
                "query: str",
                "limit: int = 10"
              ],
              "return_type": "List[CodexEntry]",
              "decorators": [],
              "is_async": false,
              "line": 222
            }
          ],
          "line": 22
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 8
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "write_entry",
          "line": 86
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_one",
          "line": 182
        },
        {
          "exception_types": [
            "yaml.YAMLError"
          ],
          "status_code": null,
          "enclosing_function": "_load_one",
          "line": 142
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_one",
          "line": 144
        }
      ],
      "http_calls": []
    },
    "memory/session_history_indexer.py": {
      "module_docstring": "Per-session vector index for conversation turns and topic summaries.\n\nProvides semantic retrieval over session history so that older turns\ncan be recalled by relevance rather than recency. Designed to",
      "classes": [
        {
          "name": "SessionHistoryIndexer",
          "bases": [],
          "docstring": "Per-session vector index for conversation turns and topic summaries.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "session_id: str",
                "persist_dir: str = _DEFAULT_PERSIST_DIR"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 78
            },
            {
              "name": "instance",
              "params": [
                "cls",
                "session_id: str"
              ],
              "return_type": "'SessionHistoryIndexer'",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 98
            },
            {
              "name": "_get_model",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 103
            },
            {
              "name": "_encode",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "Optional[np.ndarray]",
              "decorators": [],
              "is_async": false,
              "line": 110
            },
            {
              "name": "index_turn",
              "params": [
                "self",
                "turn_idx: int",
                "user_msg: str",
                "assistant_msg: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 124
            },
            {
              "name": "retrieve",
              "params": [
                "self",
                "query: str",
                "top_k_turns: int = 3",
                "top_k_topics: int = 2",
                "exclude_recent_n: int = 6"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 146
            },
            {
              "name": "_maybe_generate_topic_summary",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 202
            },
            {
              "name": "archive_and_reset",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 238
            },
            {
              "name": "_save",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 259
            },
            {
              "name": "_save_to",
              "params": [
                "self",
                "path: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 264
            },
            {
              "name": "_load",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 282
            }
          ],
          "line": 73
        }
      ],
      "functions": [
        {
          "name": "_cosine_similarity",
          "params": [
            "a: np.ndarray",
            "b: np.ndarray"
          ],
          "return_type": "float",
          "decorators": [],
          "is_async": false,
          "line": 32
        },
        {
          "name": "_get_embed_model",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 41
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_embed_model",
          "line": 51
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_embed_model",
          "line": 67
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_encode",
          "line": 120
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "archive_and_reset",
          "line": 248
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save_to",
          "line": 279
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load",
          "line": 296
        }
      ],
      "http_calls": []
    },
    "memory/session_manager.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "Session",
          "bases": [],
          "docstring": "A dedicated data class to hold the state for a single conversation session.\nUsing a class instead of",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "session_id: str",
                "persona: str = 'default'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 31
            },
            {
              "name": "to_dict",
              "params": [
                "self"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 38
            },
            {
              "name": "from_dict",
              "params": [
                "cls",
                "data: Dict"
              ],
              "return_type": "'Session'",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 49
            },
            {
              "name": "last_message_timestamp",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 62
            }
          ],
          "line": 25
        },
        {
          "name": "SessionManager",
          "bases": [],
          "docstring": "Manages loading, saving, and accessing all persistent conversation sessions.\nThis is the single sour",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "llm = None",
                "embed_model = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 81
            },
            {
              "name": "_load_state",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Session]",
              "decorators": [],
              "is_async": false,
              "line": 94
            },
            {
              "name": "_sanitize_for_json",
              "params": [
                "obj"
              ],
              "return_type": null,
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 108
            },
            {
              "name": "_save_state",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 119
            },
            {
              "name": "get_or_create_session",
              "params": [
                "self",
                "session_id: str",
                "persona: str = 'default'"
              ],
              "return_type": "Session",
              "decorators": [],
              "is_async": false,
              "line": 134
            },
            {
              "name": "add_message",
              "params": [
                "self",
                "session_id: str",
                "role: str",
                "content: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 142
            },
            {
              "name": "summarize_and_archive",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 178
            },
            {
              "name": "get_session_meta",
              "params": [
                "self",
                "session_id: str",
                "key: str",
                "default = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 237
            },
            {
              "name": "set_session_meta",
              "params": [
                "self",
                "session_id: str",
                "key: str",
                "value"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 242
            },
            {
              "name": "get_history",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 248
            },
            {
              "name": "reset_session",
              "params": [
                "self",
                "session_id: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 253
            },
            {
              "name": "sanitize_sessions",
              "params": [
                "self",
                "vector_dir: str = 'data/shared/session_vectors'",
                "max_age_days: int = 7",
                "max_active_messages: int = 0"
              ],
              "return_type": "Dict[str, int]",
              "decorators": [],
              "is_async": false,
              "line": 262
            },
            {
              "name": "record_last_activity",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 344
            }
          ],
          "line": 74
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "STATE_FILE",
          "value": "'app/shared/sessions.json'",
          "line": 20
        },
        {
          "name": "LAST_ACTIVITY_FILE",
          "value": "'app/shared/last_activity.timestamp'",
          "line": 23
        }
      ],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config",
        "from gaia_core.memory.conversation.summarizer import ConversationSummarizer",
        "from gaia_core.memory.conversation.keywords import ConversationKeywordExtractor",
        "from gaia_core.memory.conversation.archiver import ConversationArchiver",
        "from gaia_core.utils.output_router import _strip_think_tags_robust"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "TypeError",
            "ValueError"
          ],
          "status_code": null,
          "enclosing_function": "from_dict",
          "line": 57
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 231
        },
        {
          "exception_types": [
            "json.JSONDecodeError",
            "IOError"
          ],
          "status_code": null,
          "enclosing_function": "_load_state",
          "line": 103
        },
        {
          "exception_types": [
            "IOError"
          ],
          "status_code": null,
          "enclosing_function": "_save_state",
          "line": 131
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "add_message",
          "line": 168
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 195
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 216
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "summarize_and_archive",
          "line": 224
        },
        {
          "exception_types": [
            "IOError"
          ],
          "status_code": null,
          "enclosing_function": "record_last_activity",
          "line": 355
        },
        {
          "exception_types": [
            "TypeError",
            "ValueError"
          ],
          "status_code": null,
          "enclosing_function": "last_message_timestamp",
          "line": 69
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "sanitize_sessions",
          "line": 321
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "sanitize_sessions",
          "line": 328
        }
      ],
      "http_calls": []
    },
    "memory/status_tracker.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "GAIAStatus",
          "bases": [],
          "docstring": "Thread-safe global status manager for GAIA boot and runtime state.\nAllows concurrent modules to upda",
          "methods": [
            {
              "name": "update",
              "params": [
                "cls",
                "key: str",
                "value"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 12
            },
            {
              "name": "get",
              "params": [
                "cls",
                "key: str",
                "default = None"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 17
            },
            {
              "name": "as_dict",
              "params": [
                "cls"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 22
            },
            {
              "name": "clear",
              "params": [
                "cls"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 27
            }
          ],
          "line": 3
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/tests/test_semantic_codex.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "temp_knowledge_dir",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 12
        },
        {
          "name": "mock_config",
          "params": [
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 20
        },
        {
          "name": "semantic_codex",
          "params": [
            "mock_config"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 29
        },
        {
          "name": "test_write_entry_creates_markdown_file",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 32
        },
        {
          "name": "test_load_one_markdown_with_front_matter",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 62
        },
        {
          "name": "test_load_one_markdown_missing_symbol",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir",
            "caplog"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 91
        },
        {
          "name": "test_load_one_markdown_invalid_yaml",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir",
            "caplog"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 106
        },
        {
          "name": "test_load_one_json_still_works",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 123
        },
        {
          "name": "test_iter_files_includes_self_generated_docs",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 141
        },
        {
          "name": "test_hot_reload_updates_markdown_entry",
          "params": [
            "semantic_codex",
            "temp_knowledge_dir"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 156
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.memory.semantic_codex import SemanticCodex, CodexEntry",
        "from gaia_core.config import Config"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/tests/test_session_history_indexer.py": {
      "module_docstring": "Tests for SessionHistoryIndexer  the per-session vector index that powers\nthe RAG component of the rolling history feature.\n\nTests cover:\n1. Instantiation and singleton pattern\n2. Turn indexing (with",
      "classes": [
        {
          "name": "FakeEmbedModel",
          "bases": [],
          "docstring": "A deterministic fake embedding model for testing.\n\nEncodes text by hashing characters into a fixed-d",
          "methods": [
            {
              "name": "encode",
              "params": [
                "self",
                "texts",
                "show_progress_bar = False"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 53
            }
          ],
          "line": 45
        },
        {
          "name": "TestInstantiation",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_creates_empty_index",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 111
            },
            {
              "name": "test_singleton_returns_same_instance",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 118
            },
            {
              "name": "test_singleton_different_sessions_are_different",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 124
            }
          ],
          "line": 110
        },
        {
          "name": "TestTurnIndexing",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_index_one_turn",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 136
            },
            {
              "name": "test_index_multiple_turns",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 145
            },
            {
              "name": "test_duplicate_turn_idx_is_skipped",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 151
            },
            {
              "name": "test_long_messages_are_truncated",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 157
            },
            {
              "name": "test_embedding_is_numpy_array",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 163
            }
          ],
          "line": 135
        },
        {
          "name": "TestRetrieval",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "_populate",
              "params": [
                "self",
                "indexer",
                "n = 10"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 174
            },
            {
              "name": "test_retrieve_returns_dict_with_turns_and_topics",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 192
            },
            {
              "name": "test_retrieve_empty_index_returns_empty",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 198
            },
            {
              "name": "test_retrieve_excludes_recent_turns",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 202
            },
            {
              "name": "test_retrieve_returns_similarity_scores",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 211
            },
            {
              "name": "test_retrieve_respects_top_k",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 219
            },
            {
              "name": "test_retrieve_filters_by_minimum_threshold",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 224
            }
          ],
          "line": 173
        },
        {
          "name": "TestTopicSummaries",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_no_topic_before_interval",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 237
            },
            {
              "name": "test_topic_generated_at_interval",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 243
            },
            {
              "name": "test_topic_has_correct_turn_range",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 253
            },
            {
              "name": "test_multiple_topics_generated",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 260
            },
            {
              "name": "test_topic_embedding_stored",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 266
            },
            {
              "name": "test_topics_retrievable",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 273
            }
          ],
          "line": 236
        },
        {
          "name": "TestPersistence",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_save_creates_json_file",
              "params": [
                "self",
                "indexer",
                "persist_dir"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 287
            },
            {
              "name": "test_load_restores_turns",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 292
            },
            {
              "name": "test_load_restores_topics",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 309
            },
            {
              "name": "test_load_restores_last_topic_turn_idx",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 321
            },
            {
              "name": "test_corrupt_file_starts_fresh",
              "params": [
                "self",
                "persist_dir",
                "patched_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 332
            }
          ],
          "line": 286
        },
        {
          "name": "TestArchiveAndReset",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_archive_creates_archive_file",
              "params": [
                "self",
                "indexer",
                "persist_dir"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 349
            },
            {
              "name": "test_archive_clears_index",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 360
            },
            {
              "name": "test_archive_preserves_data_in_archive_file",
              "params": [
                "self",
                "indexer",
                "persist_dir"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 373
            },
            {
              "name": "test_archive_empty_index_is_noop",
              "params": [
                "self",
                "indexer",
                "persist_dir"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 384
            },
            {
              "name": "test_new_turns_after_archive",
              "params": [
                "self",
                "indexer"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 389
            }
          ],
          "line": 348
        },
        {
          "name": "TestGracefulDegradation",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_index_turn_is_noop_without_model",
              "params": [
                "self",
                "indexer_no_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 402
            },
            {
              "name": "test_retrieve_returns_empty_without_model",
              "params": [
                "self",
                "indexer_no_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 407
            },
            {
              "name": "test_archive_works_without_model",
              "params": [
                "self",
                "indexer_no_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 411
            },
            {
              "name": "test_no_topics_generated_without_model",
              "params": [
                "self",
                "indexer_no_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 415
            }
          ],
          "line": 401
        },
        {
          "name": "TestCosineSimilarity",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_identical_vectors",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 426
            },
            {
              "name": "test_orthogonal_vectors",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 431
            },
            {
              "name": "test_zero_vector",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 437
            },
            {
              "name": "test_opposite_vectors",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 443
            }
          ],
          "line": 425
        }
      ],
      "functions": [
        {
          "name": "clear_singletons",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture(autouse=True)"
          ],
          "is_async": false,
          "line": 29
        },
        {
          "name": "persist_dir",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 38
        },
        {
          "name": "fake_model",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 68
        },
        {
          "name": "patched_model",
          "params": [
            "fake_model"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 73
        },
        {
          "name": "no_model",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 83
        },
        {
          "name": "indexer",
          "params": [
            "persist_dir",
            "patched_model"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 93
        },
        {
          "name": "indexer_no_model",
          "params": [
            "persist_dir",
            "no_model"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 100
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "memory/tests/test_session_rag_integration.py": {
      "module_docstring": "Integration tests for the RAG + Rolling History pipeline.\n\nTests the interaction between:\n- SessionManager indexing hook (add_message  index_turn)\n- AgentCore sliding window + RAG retrieval (_create_",
      "classes": [
        {
          "name": "FakeEmbedModel",
          "bases": [],
          "docstring": "Deterministic fake embedding model.",
          "methods": [
            {
              "name": "encode",
              "params": [
                "self",
                "texts",
                "show_progress_bar = False"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 26
            }
          ],
          "line": 22
        },
        {
          "name": "TestSessionManagerIndexingHook",
          "bases": [],
          "docstring": "Verify that SessionManager.add_message() triggers turn indexing.",
          "methods": [
            {
              "name": "test_assistant_message_triggers_indexing",
              "params": [
                "self",
                "tmp_path",
                "persist_dir",
                "fake_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "test_user_message_alone_does_not_index",
              "params": [
                "self",
                "tmp_path",
                "persist_dir",
                "fake_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 92
            },
            {
              "name": "test_indexing_failure_does_not_block_message",
              "params": [
                "self",
                "tmp_path"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 112
            }
          ],
          "line": 63
        },
        {
          "name": "TestFormatRetrievedContext",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "test_empty_results",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 141
            },
            {
              "name": "test_turns_only",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 145
            },
            {
              "name": "test_topics_only",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 157
            },
            {
              "name": "test_both_turns_and_topics",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 168
            }
          ],
          "line": 140
        },
        {
          "name": "TestPromptBuilderTier15",
          "bases": [],
          "docstring": "Test that Tier 1.5 (retrieved_session_context) is correctly injected.",
          "methods": [
            {
              "name": "test_rag_content_appears_in_prompt",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 185
            },
            {
              "name": "test_rag_content_truncated_when_over_budget",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 210
            },
            {
              "name": "test_empty_rag_content_produces_no_prompt",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 225
            }
          ],
          "line": 182
        },
        {
          "name": "TestSlidingWindow",
          "bases": [],
          "docstring": "Test that the sliding window correctly limits history in the packet.",
          "methods": [
            {
              "name": "test_short_history_fully_included",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 241
            },
            {
              "name": "test_long_history_windowed",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 251
            },
            {
              "name": "test_rag_only_triggers_beyond_window",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 260
            }
          ],
          "line": 238
        },
        {
          "name": "TestArchiveFlowIntegration",
          "bases": [],
          "docstring": "Test that summarize_and_archive correctly archives the vector index.",
          "methods": [
            {
              "name": "test_archive_called_during_summarize",
              "params": [
                "self",
                "tmp_path",
                "fake_model"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 279
            }
          ],
          "line": 276
        }
      ],
      "functions": [
        {
          "name": "clear_singletons",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture(autouse=True)"
          ],
          "is_async": false,
          "line": 40
        },
        {
          "name": "persist_dir",
          "params": [
            "tmp_path"
          ],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 48
        },
        {
          "name": "fake_model",
          "params": [],
          "return_type": null,
          "decorators": [
            "pytest.fixture"
          ],
          "is_async": false,
          "line": 55
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "models/__init__.py": {
      "module_docstring": "gaia_core.models - Model pool and LLM backend implementations.\n\nThis package provides:\n- model_pool: Unified model pool interface (Prime/Lite/Embedding)\n- model_manager: Model lifecycle management\n- v",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "models/_model_pool_impl.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "ModelPool",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 250
            },
            {
              "name": "register_dev_model",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 278
            },
            {
              "name": "enable_prime_load",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 292
            },
            {
              "name": "load_models",
              "params": [
                "self",
                "use_oracle = False"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 300
            },
            {
              "name": "load_prime_only",
              "params": [
                "self",
                "force: bool = False"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 327
            },
            {
              "name": "_prime_guard_allows",
              "params": [
                "self",
                "force: bool = False"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 342
            },
            {
              "name": "_auto_set_gpu_layers",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 357
            },
            {
              "name": "_start_embed_loader",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 382
            },
            {
              "name": "_apply_env_model_overrides",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 431
            },
            {
              "name": "_ordered_model_keys",
              "params": [
                "self"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 506
            },
            {
              "name": "_load_model_entry",
              "params": [
                "self",
                "model_name: str",
                "use_oracle: bool = False",
                "force: bool = False"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 517
            },
            {
              "name": "_promote_prime_aliases",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 680
            },
            {
              "name": "wait_for_embed",
              "params": [
                "self",
                "timeout: float = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 700
            },
            {
              "name": "get_embed_model",
              "params": [
                "self",
                "timeout: float = 0",
                "lazy_load: bool = True"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 711
            },
            {
              "name": "prewarm_embed",
              "params": [
                "self",
                "timeout: int = 10"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 731
            },
            {
              "name": "ensure_model_loaded",
              "params": [
                "self",
                "name: str",
                "force: bool = False"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 803
            },
            {
              "name": "get",
              "params": [
                "self",
                "name: str",
                "lazy_load: bool = True"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 864
            },
            {
              "name": "get_model_for_role",
              "params": [
                "self",
                "role: str",
                "lazy_load: bool = True"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 879
            },
            {
              "name": "list_models",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 957
            },
            {
              "name": "set_status",
              "params": [
                "self",
                "name: str",
                "status: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 960
            },
            {
              "name": "get_idle_model",
              "params": [
                "self",
                "exclude = []"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 965
            },
            {
              "name": "acquire_model",
              "params": [
                "self",
                "name: str",
                "lazy_load: bool = True"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 971
            },
            {
              "name": "release_model",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 983
            },
            {
              "name": "release_model_for_role",
              "params": [
                "self",
                "role: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 987
            },
            {
              "name": "_resolve_model_name_for_role",
              "params": [
                "self",
                "role: str"
              ],
              "return_type": "str | None",
              "decorators": [],
              "is_async": false,
              "line": 992
            },
            {
              "name": "acquire_model_for_role",
              "params": [
                "self",
                "role: str",
                "lazy_load: bool = True"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 1020
            },
            {
              "name": "forward_to_model",
              "params": [
                "self",
                "role: str",
                "messages: list",
                "release: bool = True",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 1073
            },
            {
              "name": "get_active_persona",
              "params": [
                "self"
              ],
              "return_type": "PersonaAdapter",
              "decorators": [],
              "is_async": false,
              "line": 1132
            },
            {
              "name": "set_persona",
              "params": [
                "self",
                "persona"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 1136
            },
            {
              "name": "complete",
              "params": [
                "self",
                "name: str",
                "prompt: str",
                "max_tokens: int = 128",
                "temperature: float = 0.2"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 1153
            },
            {
              "name": "shutdown",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 1174
            }
          ],
          "line": 249
        }
      ],
      "functions": [
        {
          "name": "_get_sentence_transformer",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 86
        },
        {
          "name": "_read_manifest",
          "params": [
            "path: Path"
          ],
          "return_type": "dict",
          "decorators": [],
          "is_async": false,
          "line": 139
        },
        {
          "name": "_ensure_download",
          "params": [
            "role: str",
            "spec: dict",
            "models_dir: Path",
            "scripts_dir: Path",
            "allow_autosetup: bool"
          ],
          "return_type": "Path",
          "decorators": [],
          "is_async": false,
          "line": 147
        },
        {
          "name": "resolve_model_paths",
          "params": [
            "config: Config"
          ],
          "return_type": "dict",
          "decorators": [],
          "is_async": false,
          "line": 164
        },
        {
          "name": "_get_gpu_free_total_bytes",
          "params": [],
          "return_type": "tuple",
          "decorators": [],
          "is_async": false,
          "line": 192
        },
        {
          "name": "_choose_initial_n_gpu",
          "params": [
            "desired_n_gpu: int",
            "free_bytes: int | None"
          ],
          "return_type": "int",
          "decorators": [],
          "is_async": false,
          "line": 227
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import get_config, Config",
        "from gaia_core.behavior.persona_manager import PersonaManager",
        "from gaia_core.behavior.persona_adapter import PersonaAdapter",
        "from gaia_core.utils.resource_monitor import ResourceMonitor"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 6
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 28
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 33
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 38
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 43
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 48
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 53
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 59
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 64
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 75
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 79
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_ensure_download",
          "line": 159
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_gpu_free_total_bytes",
          "line": 210
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_gpu_free_total_bytes",
          "line": 223
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_sentence_transformer",
          "line": 93
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 264
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 269
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 273
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "enable_prime_load",
          "line": 297
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_models",
          "line": 323
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_prime_guard_allows",
          "line": 348
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_prime_guard_allows",
          "line": 354
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_auto_set_gpu_layers",
          "line": 379
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_start_embed_loader",
          "line": 417
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_apply_env_model_overrides",
          "line": 434
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_apply_env_model_overrides",
          "line": 503
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_model_entry",
          "line": 673
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_promote_prime_aliases",
          "line": 697
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "wait_for_embed",
          "line": 707
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "prewarm_embed",
          "line": 797
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_model_for_role",
          "line": 924
        },
        {
          "exception_types": [
            "RuntimeError"
          ],
          "status_code": null,
          "enclosing_function": "forward_to_model",
          "line": 1092
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "complete",
          "line": 1170
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "shutdown",
          "line": 1192
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_gpu_free_total_bytes",
          "line": 207
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_models",
          "line": 306
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_embed",
          "line": 403
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_start_embed_loader",
          "line": 424
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_embed_model",
          "line": 726
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "prewarm_embed",
          "line": 742
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "prewarm_embed",
          "line": 776
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_model_loaded",
          "line": 829
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_sentence_transformer",
          "line": 130
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_embed",
          "line": 411
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_apply_env_model_overrides",
          "line": 463
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_model_entry",
          "line": 608
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_promote_prime_aliases",
          "line": 695
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "prewarm_embed",
          "line": 784
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_resolve_model_name_for_role",
          "line": 1014
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "shutdown",
          "line": 1187
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_auto_set_gpu_layers",
          "line": 370
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_embed",
          "line": 399
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_model_entry",
          "line": 593
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "forward_to_model",
          "line": 1119
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_model_entry",
          "line": 635
        }
      ],
      "http_calls": []
    },
    "models/dev_model.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "DevModel",
          "bases": [],
          "docstring": "A mock model that prints the prompt to the console and waits for user input.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "name = 'dev_model'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 9
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 12
            }
          ],
          "line": 4
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "models/document.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "DocumentProcessor",
          "bases": [],
          "docstring": "Handles loading, preprocessing, and converting documents into structured markdown or LangChain docum",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config",
                "llm = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 19
            },
            {
              "name": "extract_text_from_file",
              "params": [
                "self",
                "filepath: str"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 30
            },
            {
              "name": "_extract_rtf",
              "params": [
                "self",
                "filepath: str"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 48
            },
            {
              "name": "_extract_docx",
              "params": [
                "self",
                "filepath: str"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 64
            },
            {
              "name": "convert_to_markdown",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "Optional[str]",
              "decorators": [],
              "is_async": false,
              "line": 73
            },
            {
              "name": "save_markdown",
              "params": [
                "self",
                "filepath: str",
                "content: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 120
            },
            {
              "name": "load_and_preprocess_data",
              "params": [
                "self",
                "data_path: str"
              ],
              "return_type": "List[Document]",
              "decorators": [],
              "is_async": false,
              "line": 131
            },
            {
              "name": "process_raw_data",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 157
            },
            {
              "name": "get_document_info",
              "params": [
                "self",
                "filepath: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 186
            },
            {
              "name": "process_documents",
              "params": [
                "self",
                "directory: str",
                "tier: Optional[str] = None",
                "project: Optional[str] = None"
              ],
              "return_type": "List[Document]",
              "decorators": [],
              "is_async": false,
              "line": 202
            },
            {
              "name": "embed_documents",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 235
            },
            {
              "name": "generate_artifacts",
              "params": [
                "self"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 244
            }
          ],
          "line": 13
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "extract_text_from_file",
          "line": 44
        },
        {
          "exception_types": [
            "UnicodeDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "_extract_rtf",
          "line": 53
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_extract_rtf",
          "line": 60
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_extract_docx",
          "line": 69
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "convert_to_markdown",
          "line": 116
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "save_markdown",
          "line": 127
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_and_preprocess_data",
          "line": 152
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "process_raw_data",
          "line": 183
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_document_info",
          "line": 198
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "process_documents",
          "line": 230
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_extract_rtf",
          "line": 57
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_and_preprocess_data",
          "line": 150
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "process_documents",
          "line": 228
        }
      ],
      "http_calls": []
    },
    "models/fine_tune_gaia.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "run_fine_tuning",
          "params": [
            "config: Config",
            "dataset_path: str",
            "base_model_name: str",
            "new_model_name: str"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 19
        },
        {
          "name": "main",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 101
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_fine_tuning",
          "line": 39
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_fine_tuning",
          "line": 56
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "main",
          "line": 117
        }
      ],
      "http_calls": []
    },
    "models/gemini_model.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "GeminiAPIModel",
          "bases": [],
          "docstring": "Minimal Gemini chat wrapper using the REST API.\nExpects GOOGLE_API_KEY in env. Model name is taken f",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_name: str",
                "api_key: str"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int",
                "temperature: float",
                "top_p: float",
                "stream: bool = False",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 23
            }
          ],
          "line": 8
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 66
        }
      ],
      "http_calls": [
        {
          "call_method": "post",
          "url_or_path": "self.endpoint",
          "enclosing_function": "create_chat_completion",
          "line": 53
        }
      ]
    },
    "models/groq_model.py": {
      "module_docstring": "Groq API model wrapper for GAIA.\n\nGroq provides free, fast inference on open-source models via their custom LPU hardware.\nThis wrapper provides an OpenAI-compatible interface for use as a fallback whe",
      "classes": [
        {
          "name": "GroqAPIModel",
          "bases": [],
          "docstring": "Groq API wrapper providing create_chat_completion interface.\n\nCompatible with GAIA's model pool and ",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_name: str = None",
                "api_key: str = None",
                "timeout: int = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 79
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int = 1024",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "stream: bool = False",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any] | Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 109
            },
            {
              "name": "_sanitize_messages",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]"
              ],
              "return_type": "List[Dict[str, str]]",
              "decorators": [],
              "is_async": false,
              "line": 191
            },
            {
              "name": "_stream_response",
              "params": [
                "self",
                "response_stream",
                "start_duration: float"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 227
            },
            {
              "name": "_log_usage",
              "params": [
                "self",
                "response",
                "duration: float"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 262
            },
            {
              "name": "get_stats",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 279
            },
            {
              "name": "list_models",
              "params": [
                "cls"
              ],
              "return_type": "Dict[str, Dict]",
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 288
            }
          ],
          "line": 38
        }
      ],
      "functions": [
        {
          "name": "_ensure_groq_imported",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 25
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "_ensure_groq_imported",
          "line": 32
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 186
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_log_usage",
          "line": 276
        }
      ],
      "http_calls": [
        {
          "call_method": "create",
          "url_or_path": null,
          "enclosing_function": "create_chat_completion",
          "line": 147
        }
      ]
    },
    "models/hf_model.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "HFModel",
          "bases": [],
          "docstring": "A thin wrapper around Hugging Face transformers for text generation.\n\nProvides a create_completion(p",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_ref: str",
                "local_path: str = None",
                "device_map: Optional[str] = 'auto'",
                "torch_dtype = None",
                "prompt_config: Optional[Dict] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "_messages_to_prompt",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 141
            },
            {
              "name": "create_completion",
              "params": [
                "self",
                "prompt: str",
                "max_tokens: int = 128",
                "temperature: float = 0.2",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 146
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int = 128",
                "temperature: float = 0.2",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 238
            }
          ],
          "line": 7
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.utils.hf_prompting import build_hf_prompt, default_stop_tokens"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 26
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 138
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_completion",
          "line": 189
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 271
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 124
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_completion",
          "line": 169
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_generate",
          "line": 212
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 64
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_generate",
          "line": 203
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_generate",
          "line": 210
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 51
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 261
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 267
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 78
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 94
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 101
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 108
        }
      ],
      "http_calls": []
    },
    "models/mcp_proxy_model.py": {
      "module_docstring": "MCP-backed model adapter.\n\nImplements a minimal model-like interface expected by ModelPool consumers.\nDelegates requests to the configured MCP-Lite server via JSON-RPC.",
      "classes": [
        {
          "name": "MCPProxyModel",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config = None",
                "role_name: str = 'prime'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 16
            },
            {
              "name": "_call_rpc",
              "params": [
                "self",
                "method: str",
                "params: Dict"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 25
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict]",
                "**kwargs"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 34
            },
            {
              "name": "create_completion",
              "params": [
                "self",
                "prompt: str",
                "**kwargs"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 44
            },
            {
              "name": "__repr__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 51
            }
          ],
          "line": 15
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": [
        {
          "call_method": "post",
          "url_or_path": "self.endpoint",
          "enclosing_function": "_call_rpc",
          "line": 30
        }
      ]
    },
    "models/model_manager.py": {
      "module_docstring": "ModelManager: a small spine to query model status, ensure models are loaded\nand provide a safe spawn-based fallback for loading Prime (vLLM) when direct\nin-process load fails due to CUDA/multiprocessi",
      "classes": [
        {
          "name": "ModelManager",
          "bases": [],
          "docstring": "Singleton-ish manager around the existing model_pool.\n\nIt does not itself host models; instead it de",
          "methods": [
            {
              "name": "__new__",
              "params": [
                "cls"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 61
            },
            {
              "name": "__init__",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 66
            },
            {
              "name": "_get_pool",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 71
            },
            {
              "name": "ensure_prime_loaded",
              "params": [
                "self",
                "force: bool = False",
                "timeout: int = 120"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 86
            },
            {
              "name": "call_model",
              "params": [
                "self",
                "role: str",
                "*args",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 208
            }
          ],
          "line": 52
        }
      ],
      "functions": [
        {
          "name": "_model_manager_child_loader",
          "params": [
            "q",
            "force_flag"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 19
        },
        {
          "name": "get_manager",
          "params": [],
          "return_type": "ModelManager",
          "decorators": [],
          "is_async": false,
          "line": 236
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_model_manager_child_loader",
          "line": 46
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_model_manager_child_loader",
          "line": 29
        },
        {
          "exception_types": [
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "_model_manager_child_loader",
          "line": 34
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_model_manager_child_loader",
          "line": 43
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 110
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 120
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 143
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 204
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "call_model",
          "line": 229
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_pool",
          "line": 80
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 140
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 170
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 196
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 157
        },
        {
          "exception_types": [
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 163
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ensure_prime_loaded",
          "line": 137
        }
      ],
      "http_calls": []
    },
    "models/model_pool.py": {
      "module_docstring": null,
      "classes": [],
      "functions": [
        {
          "name": "get_model_pool",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 7
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import get_config"
      ],
      "error_handlers": [],
      "http_calls": []
    },
    "models/oracle_model.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "GPTAPIModel",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_alias: str = 'oracle_openai'",
                "config: Config = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 8
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages",
                "max_tokens",
                "temperature",
                "top_p",
                "stream = False"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 20
            },
            {
              "name": "_stream_response",
              "params": [
                "self",
                "response_stream"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 62
            },
            {
              "name": "_log_token_usage",
              "params": [
                "self",
                "response"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 79
            }
          ],
          "line": 7
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config, get_config"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_log_token_usage",
          "line": 87
        }
      ],
      "http_calls": [
        {
          "call_method": "create",
          "url_or_path": null,
          "enclosing_function": "create_chat_completion",
          "line": 32
        }
      ]
    },
    "models/tts.py": {
      "module_docstring": "Text-to-speech module for GAIA D&D Campaign Assistant.\nHandles all speech synthesis functionality.",
      "classes": [
        {
          "name": "SpeechManager",
          "bases": [],
          "docstring": "Manages text-to-speech functionality.",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 16
            },
            {
              "name": "initialize",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 27
            },
            {
              "name": "_select_voice",
              "params": [
                "self",
                "voices: List"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 50
            },
            {
              "name": "speak",
              "params": [
                "self",
                "text: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 89
            },
            {
              "name": "stop",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 105
            },
            {
              "name": "set_properties",
              "params": [
                "self",
                "rate: Optional[int] = None",
                "volume: Optional[float] = None"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 113
            }
          ],
          "line": 13
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialize",
          "line": 45
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "speak",
          "line": 102
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "set_properties",
          "line": 129
        },
        {
          "exception_types": [
            "ValueError"
          ],
          "status_code": null,
          "enclosing_function": "_select_voice",
          "line": 86
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "stop",
          "line": 110
        }
      ],
      "http_calls": []
    },
    "models/vector_store.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "VectorStoreManager",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 15
            },
            {
              "name": "initialize_store",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 20
            },
            {
              "name": "persist",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 34
            },
            {
              "name": "delete_all_documents",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 43
            },
            {
              "name": "as_retriever",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 52
            },
            {
              "name": "add_documents",
              "params": [
                "self",
                "documents: List[Document]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 56
            },
            {
              "name": "split_and_embed_documents",
              "params": [
                "self",
                "raw_documents: List[str]",
                "source: Optional[str] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 64
            }
          ],
          "line": 14
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.utils.knowledge_index import KnowledgeIndex"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "initialize_store",
          "line": 30
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "add_documents",
          "line": 61
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "split_and_embed_documents",
          "line": 77
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "persist",
          "line": 40
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "delete_all_documents",
          "line": 49
        }
      ],
      "http_calls": []
    },
    "models/vllm_model.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "LoRAAdapterInfo",
          "bases": [],
          "docstring": "Metadata for a loaded LoRA adapter.",
          "methods": [],
          "line": 22
        },
        {
          "name": "VLLMChatModel",
          "bases": [],
          "docstring": "Thin wrapper around vLLM that exposes GAIA's create_chat_completion interface.\n\nParameters are sourc",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_config: Dict[str, Any]",
                "global_config",
                "gpu_info: Optional[Tuple[Optional[int], Optional[int]]] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 41
            },
            {
              "name": "_int_from_config",
              "params": [
                "self",
                "key: str",
                "env_override: Optional[str]",
                "default: int"
              ],
              "return_type": "int",
              "decorators": [],
              "is_async": false,
              "line": 168
            },
            {
              "name": "_resolve_gpu_utilization",
              "params": [
                "self"
              ],
              "return_type": "float",
              "decorators": [],
              "is_async": false,
              "line": 181
            },
            {
              "name": "create_completion",
              "params": [
                "self",
                "prompt: str",
                "max_tokens: int = 128",
                "temperature: float = 0.2",
                "top_p: float = 0.9",
                "presence_penalty: float = 0.0",
                "stream: bool = False",
                "stop: Optional[Iterable[str]] = None",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 224
            },
            {
              "name": "_create_chat_completion_simple",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int = 2048",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 273
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int = 128",
                "temperature: float = 0.2",
                "top_p: float = 0.9",
                "stream: bool = False",
                "stop: Optional[Iterable[str]] = None",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 308
            },
            {
              "name": "_messages_to_prompt",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 352
            },
            {
              "name": "_build_sampling_params",
              "params": [
                "self",
                "max_tokens: int",
                "temperature: float",
                "top_p: float",
                "stop: Optional[Iterable[str]]",
                "presence_penalty: float = 0.0",
                "repetition_penalty: float = 1.0",
                "frequency_penalty: float = 0.0"
              ],
              "return_type": "SamplingParams",
              "decorators": [],
              "is_async": false,
              "line": 356
            },
            {
              "name": "shutdown",
              "params": [
                "self"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 386
            },
            {
              "name": "_stream_text",
              "params": [
                "self",
                "prompts: List[str]",
                "sampling_params: SamplingParams"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 398
            },
            {
              "name": "_native_stream_text",
              "params": [
                "self",
                "prompts: List[str]",
                "sampling_params: SamplingParams"
              ],
              "return_type": "Iterator[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 407
            },
            {
              "name": "_chunk_text",
              "params": [
                "self",
                "text: str",
                "chunk_size: int = 96"
              ],
              "return_type": "Iterator[str]",
              "decorators": [],
              "is_async": false,
              "line": 446
            },
            {
              "name": "_extract_text",
              "params": [
                "self",
                "outputs"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 472
            },
            {
              "name": "_summarize_outputs",
              "params": [
                "self",
                "outputs"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 483
            },
            {
              "name": "lora_enabled",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 496
            },
            {
              "name": "load_adapter",
              "params": [
                "self",
                "name: str",
                "path: str",
                "tier: int = 3"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 500
            },
            {
              "name": "unload_adapter",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 565
            },
            {
              "name": "get_loaded_adapters",
              "params": [
                "self"
              ],
              "return_type": "List[LoRAAdapterInfo]",
              "decorators": [],
              "is_async": false,
              "line": 583
            },
            {
              "name": "get_adapter",
              "params": [
                "self",
                "name: str"
              ],
              "return_type": "Optional[LoRAAdapterInfo]",
              "decorators": [],
              "is_async": false,
              "line": 587
            },
            {
              "name": "create_lora_request",
              "params": [
                "self",
                "adapter_name: str"
              ],
              "return_type": "Optional[Any]",
              "decorators": [],
              "is_async": false,
              "line": 591
            },
            {
              "name": "generate_with_adapter",
              "params": [
                "self",
                "prompts: List[str]",
                "adapter_name: str",
                "sampling_params: Optional[Any] = None",
                "max_tokens: int = 2048",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "**kwargs"
              ],
              "return_type": "List[Any]",
              "decorators": [],
              "is_async": false,
              "line": 615
            },
            {
              "name": "create_chat_completion_with_adapter",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "adapter_name: str",
                "max_tokens: int = 2048",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 659
            }
          ],
          "line": 33
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.utils.hf_prompting import build_hf_prompt, default_stop_tokens"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 74
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 82
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 164
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_int_from_config",
          "line": 172
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_int_from_config",
          "line": 177
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_completion",
          "line": 245
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_create_chat_completion_simple",
          "line": 284
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 320
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion",
          "line": 337
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "shutdown",
          "line": 395
        },
        {
          "exception_types": [
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "_native_stream_text",
          "line": 412
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_extract_text",
          "line": 479
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_summarize_outputs",
          "line": 489
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "create_chat_completion_with_adapter",
          "line": 683
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 62
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 157
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_parse_env",
          "line": 186
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_resolve_gpu_utilization",
          "line": 199
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_native_stream_text",
          "line": 434
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_adapter",
          "line": 532
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_adapter",
          "line": 543
        }
      ],
      "http_calls": []
    },
    "models/vllm_remote_model.py": {
      "module_docstring": "Remote vLLM model backend for GAIA.\n\nHTTP client for a standalone vLLM OpenAI-compatible API server (gaia-prime).\nReplaces in-process VLLMChatModel when PRIME_ENDPOINT is set, allowing\ngaia-core to of",
      "classes": [
        {
          "name": "VLLMRemoteModel",
          "bases": [],
          "docstring": "HTTP client for a remote vLLM OpenAI-compatible API server.\n\nProvides the same public interface as V",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "model_config: dict",
                "global_config = None",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 32
            },
            {
              "name": "create_completion",
              "params": [
                "self",
                "prompt: str",
                "max_tokens: int = 512",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "stop: Optional[List[str]] = None",
                "stream: bool = False",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any] | Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 69
            },
            {
              "name": "create_chat_completion",
              "params": [
                "self",
                "messages: List[Dict[str, Any]]",
                "max_tokens: int = 1024",
                "temperature: float = 0.7",
                "top_p: float = 0.95",
                "stream: bool = False",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any] | Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 112
            },
            {
              "name": "set_active_adapter",
              "params": [
                "self",
                "adapter_name: Optional[str]"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 176
            },
            {
              "name": "create_chat_completion_with_adapter",
              "params": [
                "self",
                "adapter_name: str",
                "messages: List[Dict[str, Any]]",
                "**kwargs"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 181
            },
            {
              "name": "health_check",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 197
            },
            {
              "name": "shutdown",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 208
            },
            {
              "name": "_resolve_model_field",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 217
            },
            {
              "name": "_post",
              "params": [
                "self",
                "path: str",
                "payload: dict"
              ],
              "return_type": "dict",
              "decorators": [],
              "is_async": false,
              "line": 231
            },
            {
              "name": "_stream_completions",
              "params": [
                "self",
                "payload: dict"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 273
            },
            {
              "name": "_stream_chat",
              "params": [
                "self",
                "payload: dict"
              ],
              "return_type": "Generator[Dict[str, Any], None, None]",
              "decorators": [],
              "is_async": false,
              "line": 290
            },
            {
              "name": "_sanitize_messages",
              "params": [
                "messages: List[Dict[str, Any]]"
              ],
              "return_type": "List[Dict[str, str]]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 325
            },
            {
              "name": "_log_usage",
              "params": [
                "self",
                "resp: dict",
                "duration: float"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 344
            }
          ],
          "line": 23
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "health_check",
          "line": 204
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "shutdown",
          "line": 212
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_log_usage",
          "line": 359
        },
        {
          "exception_types": [
            "requests.exceptions.ConnectionError"
          ],
          "status_code": null,
          "enclosing_function": "_post",
          "line": 249
        },
        {
          "exception_types": [
            "requests.exceptions.HTTPError"
          ],
          "status_code": 500,
          "enclosing_function": "_post",
          "line": 263
        }
      ],
      "http_calls": [
        {
          "call_method": "Session",
          "url_or_path": null,
          "enclosing_function": "__init__",
          "line": 59
        }
      ]
    },
    "utils/__init__.py": {
      "module_docstring": "gaia_core.utils - Utility modules for the GAIA cognitive engine.\n\nThis package provides:\n- prompt_builder: Construct prompts from CognitionPackets\n- packet_builder: Build and manipulate CognitionPacke",
      "classes": [],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "utils/dev_matrix_analyzer.py": {
      "module_docstring": "DevMatrixAnalyzer - Analyzes task completion status for GAIA's dev_matrix.\n\nThis module provides automated task completion detection for GAIA's self-development\nroadmap. Each task type has specific ve",
      "classes": [
        {
          "name": "DevMatrixAnalyzer",
          "bases": [],
          "docstring": "Analyzes and updates dev_matrix task completion status.\n\nUses file-based verification instead of she",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 23
            },
            {
              "name": "analyze_and_update",
              "params": [
                "self"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 37
            },
            {
              "name": "is_task_completed",
              "params": [
                "self",
                "task: Dict"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 57
            },
            {
              "name": "get_task_status_report",
              "params": [
                "self"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 89
            },
            {
              "name": "_verify_discord_integration",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 121
            },
            {
              "name": "_verify_thought_seed_tooling",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 169
            },
            {
              "name": "_verify_self_reflection",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 182
            },
            {
              "name": "_verify_gcp_fragmentation",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 195
            }
          ],
          "line": 16
        }
      ],
      "functions": [
        {
          "name": "analyze_dev_matrix",
          "params": [
            "config"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 211
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.memory.dev_matrix import GAIADevMatrix"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_verify_discord_integration",
          "line": 165
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_verify_thought_seed_tooling",
          "line": 179
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_verify_self_reflection",
          "line": 192
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_verify_gcp_fragmentation",
          "line": 207
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "is_task_completed",
          "line": 73
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "is_task_completed",
          "line": 82
        }
      ],
      "http_calls": []
    },
    "utils/dev_matrix_utils.py": {
      "module_docstring": "dev_matrix_utils.py\n- Utilities for loading, diffing, and updating dev_matrix.json\n- Enforces absolute path, atomic writes, and audit logging\n- Designed for use in self-review and approval flows",
      "classes": [],
      "functions": [
        {
          "name": "load_dev_matrix",
          "params": [
            "path: Path = DEV_MATRIX_PATH"
          ],
          "return_type": "Any",
          "decorators": [],
          "is_async": false,
          "line": 17
        },
        {
          "name": "save_dev_matrix",
          "params": [
            "data: Any",
            "path: Path = DEV_MATRIX_PATH"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 22
        },
        {
          "name": "diff_dev_matrix",
          "params": [
            "old: Any",
            "new: Any"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 29
        },
        {
          "name": "mark_task_complete",
          "params": [
            "task_key: str",
            "prompt: str = None",
            "path: Path = DEV_MATRIX_PATH"
          ],
          "return_type": "Tuple[Any, Any, str]",
          "decorators": [],
          "is_async": false,
          "line": 36
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [],
      "http_calls": []
    },
    "utils/gaia_rescue_helper.py": {
      "module_docstring": "GAIA Rescue Helper (production copy)\n------------------------------------\n- Central, Config-safe utilities used by the router and rescue shell\n- Provides GAIARescueHelper class (expected by output_rou",
      "classes": [
        {
          "name": "GAIARescueHelper",
          "bases": [],
          "docstring": "Config-aware faade for:\n  - Blueprints / Cheatsheets under knowledge/system_reference/...\n  - Sketc",
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Config",
                "llm: Optional[Any] = None"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 61
            },
            {
              "name": "load_blueprint",
              "params": [
                "self",
                "blueprint_id: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 89
            },
            {
              "name": "load_cheatsheet",
              "params": [
                "self",
                "cheatsheet_id: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 96
            },
            {
              "name": "sketchpad_write",
              "params": [
                "self",
                "title: str",
                "content: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 112
            },
            {
              "name": "sketchpad_read",
              "params": [
                "self",
                "key: str = ''"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 145
            },
            {
              "name": "sketchpad_clear",
              "params": [
                "self"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 164
            },
            {
              "name": "_load_fragments_store",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 196
            },
            {
              "name": "_save_fragments_store",
              "params": [
                "self",
                "data: Dict[str, Any]"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 211
            },
            {
              "name": "fragment_write",
              "params": [
                "self",
                "parent_request_id: str",
                "sequence: int",
                "content: str",
                "continuation_hint: str = ''",
                "is_complete: bool = False",
                "token_count: int = 0"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 221
            },
            {
              "name": "fragment_read",
              "params": [
                "self",
                "parent_request_id: str"
              ],
              "return_type": "List[Dict[str, Any]]",
              "decorators": [],
              "is_async": false,
              "line": 269
            },
            {
              "name": "fragment_assemble",
              "params": [
                "self",
                "parent_request_id: str",
                "seam_overlap_check: bool = True"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 283
            },
            {
              "name": "fragment_clear",
              "params": [
                "self",
                "parent_request_id: Optional[str] = None"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 339
            },
            {
              "name": "fragment_list_pending",
              "params": [
                "self"
              ],
              "return_type": "List[str]",
              "decorators": [],
              "is_async": false,
              "line": 358
            },
            {
              "name": "_load_memory_store",
              "params": [
                "self"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 366
            },
            {
              "name": "_write_memory_store",
              "params": [
                "self",
                "data: Dict[str, Any]"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 388
            },
            {
              "name": "remember_fact",
              "params": [
                "self",
                "key: str",
                "value: str",
                "note: str = ''"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 398
            },
            {
              "name": "recall_fact",
              "params": [
                "self",
                "key: str = ''",
                "limit: int = 5"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 413
            },
            {
              "name": "get_recent_facts",
              "params": [
                "self",
                "limit: int = 5"
              ],
              "return_type": "List[Dict[str, str]]",
              "decorators": [],
              "is_async": false,
              "line": 434
            },
            {
              "name": "queue_thought_seed",
              "params": [
                "self",
                "prompt: str",
                "note: str = ''",
                "priority: str = 'normal'"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 455
            },
            {
              "name": "run_shell_safe",
              "params": [
                "self",
                "command: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 493
            },
            {
              "name": "buffer_and_execute_shell",
              "params": [
                "self",
                "content: str"
              ],
              "return_type": "None",
              "decorators": [],
              "is_async": false,
              "line": 518
            },
            {
              "name": "_validate_read_path",
              "params": [
                "self",
                "path: str"
              ],
              "return_type": "str",
              "decorators": [],
              "is_async": false,
              "line": 558
            },
            {
              "name": "code_read",
              "params": [
                "self",
                "path: str"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 565
            },
            {
              "name": "code_span",
              "params": [
                "self",
                "path: str",
                "start: int",
                "end: int"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 578
            },
            {
              "name": "code_symbol",
              "params": [
                "self",
                "path: str",
                "symbol: str"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 590
            },
            {
              "name": "code_summarize",
              "params": [
                "self",
                "src: Dict[str, Any]",
                "max_tokens: int = 256"
              ],
              "return_type": "Dict[str, Any]",
              "decorators": [],
              "is_async": false,
              "line": 605
            }
          ],
          "line": 53
        }
      ],
      "functions": [
        {
          "name": "_safe_read_text",
          "params": [
            "path: Path"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 36
        },
        {
          "name": "_find_first_with_ext",
          "params": [
            "base: Path",
            "stem: str",
            "exts: tuple[str, ...]"
          ],
          "return_type": "Optional[Path]",
          "decorators": [],
          "is_async": false,
          "line": 43
        },
        {
          "name": "_helper",
          "params": [],
          "return_type": "GAIARescueHelper",
          "decorators": [],
          "is_async": false,
          "line": 633
        },
        {
          "name": "sketch",
          "params": [
            "title: str",
            "content: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 640
        },
        {
          "name": "sketchpad_write",
          "params": [
            "title: str",
            "content: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 642
        },
        {
          "name": "show_sketchpad",
          "params": [
            "key: str = ''"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 645
        },
        {
          "name": "sketchpad_read",
          "params": [
            "key: str = ''"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 647
        },
        {
          "name": "clear_sketchpad",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 650
        },
        {
          "name": "sketchpad_clear",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 652
        },
        {
          "name": "load_blueprint",
          "params": [
            "blueprint_id: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 657
        },
        {
          "name": "load_cheatsheet",
          "params": [
            "cheatsheet_id: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 659
        },
        {
          "name": "queue_thought_seed",
          "params": [
            "prompt: str",
            "note: str = ''",
            "priority: str = 'normal'"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 663
        },
        {
          "name": "run_shell_safe",
          "params": [
            "command: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 667
        },
        {
          "name": "buffer_and_execute_shell",
          "params": [
            "content: str"
          ],
          "return_type": "None",
          "decorators": [],
          "is_async": false,
          "line": 669
        },
        {
          "name": "code_read",
          "params": [
            "path: str"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 673
        },
        {
          "name": "code_span",
          "params": [
            "path: str",
            "start: int",
            "end: int"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 675
        },
        {
          "name": "code_symbol",
          "params": [
            "path: str",
            "symbol: str"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 677
        },
        {
          "name": "code_summarize",
          "params": [
            "src: Dict[str, Any]",
            "max_tokens: int = 256"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 679
        },
        {
          "name": "remember_fact",
          "params": [
            "key: str",
            "value: str",
            "note: str = ''"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 683
        },
        {
          "name": "recall_fact",
          "params": [
            "key: str = ''",
            "limit: int = 5"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 686
        },
        {
          "name": "get_recent_facts",
          "params": [
            "limit: int = 5"
          ],
          "return_type": "List[Dict[str, str]]",
          "decorators": [],
          "is_async": false,
          "line": 689
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.utils.mcp_client import ai_execute, ai_read, ai_write",
        "from gaia_core.config import Config, get_config",
        "from gaia_core.memory.status_tracker import GAIAStatus"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 20
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 30
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_safe_read_text",
          "line": 40
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 80
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "load_cheatsheet",
          "line": 105
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_write",
          "line": 129
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_read",
          "line": 161
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_clear",
          "line": 190
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_save_fragments_store",
          "line": 217
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_write_memory_store",
          "line": 393
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "queue_thought_seed",
          "line": 486
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_shell_safe",
          "line": 515
        },
        {
          "exception_types": [
            "ValueError"
          ],
          "status_code": null,
          "enclosing_function": "buffer_and_execute_shell",
          "line": 530
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "buffer_and_execute_shell",
          "line": 546
        },
        {
          "exception_types": [
            "PermissionError"
          ],
          "status_code": null,
          "enclosing_function": "code_read",
          "line": 573
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "code_read",
          "line": 575
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "code_span",
          "line": 587
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "code_symbol",
          "line": 602
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_write",
          "line": 138
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_clear",
          "line": 186
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_fragments_store",
          "line": 207
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_memory_store",
          "line": 377
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_memory_store",
          "line": 384
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "queue_thought_seed",
          "line": 471
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "queue_thought_seed",
          "line": 481
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "run_shell_safe",
          "line": 507
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "code_summarize",
          "line": 622
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_clear",
          "line": 177
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "sketchpad_clear",
          "line": 180
        }
      ],
      "http_calls": []
    },
    "utils/mcp_client.py": {
      "module_docstring": "GAIA MCP-Lite Client\n\nThis module is responsible for dispatching sidecar actions from a CognitionPacket\nto the MCP-lite server.",
      "classes": [],
      "functions": [
        {
          "name": "_normalize_endpoint",
          "params": [
            "ep: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 21
        },
        {
          "name": "call_jsonrpc",
          "params": [
            "method: str",
            "params: Dict",
            "endpoint: str = None",
            "timeout: int = 20"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 35
        },
        {
          "name": "dispatch_sidecar_actions",
          "params": [
            "packet: CognitionPacket",
            "config: Config"
          ],
          "return_type": "List[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 74
        },
        {
          "name": "ai_read",
          "params": [
            "path: str"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 168
        },
        {
          "name": "ai_write",
          "params": [
            "path: str",
            "content: str"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 183
        },
        {
          "name": "ai_execute",
          "params": [
            "command: str",
            "timeout: int = 30",
            "shell: bool = False",
            "dry_run: bool = False"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 207
        },
        {
          "name": "embedding_query",
          "params": [
            "query: str",
            "top_k: int = 5",
            "knowledge_base_name: str = 'system'"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 233
        },
        {
          "name": "request_approval_via_mcp",
          "params": [
            "method: str",
            "params: Dict"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 251
        },
        {
          "name": "approve_action_via_mcp",
          "params": [
            "action_id: str",
            "approval: str"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 294
        },
        {
          "name": "get_pending_action",
          "params": [
            "action_id: str"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 315
        },
        {
          "name": "discover",
          "params": [
            "endpoint: str = None",
            "timeout: int = 3"
          ],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 337
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket",
        "from gaia_core.config import Config"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "call_jsonrpc",
          "line": 66
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ai_read",
          "line": 176
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ai_write",
          "line": 202
        },
        {
          "exception_types": [
            "subprocess.TimeoutExpired"
          ],
          "status_code": null,
          "enclosing_function": "ai_execute",
          "line": 225
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "ai_execute",
          "line": 228
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "embedding_query",
          "line": 245
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "request_approval_via_mcp",
          "line": 289
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "approve_action_via_mcp",
          "line": 310
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "get_pending_action",
          "line": 332
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 456
        },
        {
          "exception_types": [
            "requests.exceptions.RequestException"
          ],
          "status_code": null,
          "enclosing_function": "dispatch_sidecar_actions",
          "line": 154
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 391
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 411
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "call_jsonrpc",
          "line": 70
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "dispatch_sidecar_actions",
          "line": 151
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 452
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 359
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 368
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "discover",
          "line": 431
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": 400,
          "enclosing_function": "discover",
          "line": 450
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": 400,
          "enclosing_function": "discover",
          "line": 429
        }
      ],
      "http_calls": [
        {
          "call_method": "post",
          "url_or_path": "ep",
          "enclosing_function": "call_jsonrpc",
          "line": 42
        },
        {
          "call_method": "post",
          "url_or_path": "url",
          "enclosing_function": "request_approval_via_mcp",
          "line": 277
        },
        {
          "call_method": "post",
          "url_or_path": "url",
          "enclosing_function": "approve_action_via_mcp",
          "line": 307
        },
        {
          "call_method": "get",
          "url_or_path": "url",
          "enclosing_function": "get_pending_action",
          "line": 324
        },
        {
          "call_method": "post",
          "url_or_path": "endpoint",
          "enclosing_function": "dispatch_sidecar_actions",
          "line": 131
        },
        {
          "call_method": "get",
          "url_or_path": "url",
          "enclosing_function": "discover",
          "line": 438
        },
        {
          "call_method": "post",
          "url_or_path": "endpoint",
          "enclosing_function": "discover",
          "line": 358
        },
        {
          "call_method": "post",
          "url_or_path": "url",
          "enclosing_function": "discover",
          "line": 418
        },
        {
          "call_method": "get",
          "url_or_path": "url",
          "enclosing_function": "discover",
          "line": 418
        }
      ]
    },
    "utils/output_router.py": {
      "module_docstring": "Output Router - Central hub for parsing and dispatching all directives from LLM output.\n\nHandles:\n- Parsing LLM output into CognitionPacket structures\n- Safety gate checking before execution\n- Sidecar",
      "classes": [],
      "functions": [
        {
          "name": "_strip_think_tags_robust",
          "params": [
            "text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 24
        },
        {
          "name": "_strip_stray_cjk",
          "params": [
            "text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 87
        },
        {
          "name": "_get_destination_registry",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 118
        },
        {
          "name": "route_output",
          "params": [
            "response_text: str",
            "packet: CognitionPacket",
            "ai_manager",
            "session_id: str",
            "destination: str"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 131
        },
        {
          "name": "_legacy_destination_to_enum",
          "params": [
            "destination: str"
          ],
          "return_type": "Optional[OutputDestination]",
          "decorators": [],
          "is_async": false,
          "line": 275
        },
        {
          "name": "_strip_gcp_metadata",
          "params": [
            "text: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 291
        },
        {
          "name": "_parse_llm_output_into_packet",
          "params": [
            "response_text: str",
            "packet: CognitionPacket"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 330
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols import CognitionPacket, PacketState, OutputDestination",
        "from gaia_common.utils.packet_utils import is_execution_safe",
        "from gaia_core.utils.mcp_client import dispatch_sidecar_actions"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "route_output",
          "line": 264
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_get_destination_registry",
          "line": 127
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "route_output",
          "line": 219
        },
        {
          "exception_types": [
            "json.JSONDecodeError"
          ],
          "status_code": null,
          "enclosing_function": "_parse_llm_output_into_packet",
          "line": 376
        }
      ],
      "http_calls": []
    },
    "utils/packet_builder.py": {
      "module_docstring": "Utility to build small CognitionPacket snapshots for grounding summarization.\n\nProduces a compact dict snapshot (not a full CognitionPacket instance) which\nmatches the shape expected by `ConversationS",
      "classes": [],
      "functions": [
        {
          "name": "build_packet_snapshot",
          "params": [
            "session_id: str",
            "persona_id: str",
            "original_prompt: str",
            "history: List[Dict[str, Any]] = None",
            "mcp_info: Optional[str] = None"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 15
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "CORE_IDENTITY_MAX_CHARS",
          "value": "800",
          "line": 13
        }
      ],
      "gaia_imports": [
        "from gaia_core.config import Config"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_packet_snapshot",
          "line": 44
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_packet_snapshot",
          "line": 83
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_packet_snapshot",
          "line": 42
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_packet_snapshot",
          "line": 78
        }
      ],
      "http_calls": []
    },
    "utils/packet_templates.py": {
      "module_docstring": "Helpers for rendering GAIA Cognition Packets (GCP) as structured templates.\n\nThe template is intentionally compact: only populated sections are emitted,\nand lengthy text fields are trimmed so the rend",
      "classes": [],
      "functions": [
        {
          "name": "_trim",
          "params": [
            "value: Any",
            "limit: int = MAX_INLINE_LEN"
          ],
          "return_type": "Any",
          "decorators": [],
          "is_async": false,
          "line": 18
        },
        {
          "name": "_clean_dict",
          "params": [
            "payload: Dict[str, Any]"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 24
        },
        {
          "name": "packet_to_template_dict",
          "params": [
            "packet: CognitionPacket",
            "processed_data_field_keys: Optional[set] = None"
          ],
          "return_type": "Dict[str, Any]",
          "decorators": [],
          "is_async": false,
          "line": 29
        },
        {
          "name": "render_gaia_packet_template",
          "params": [
            "packet: CognitionPacket",
            "indent: str = '  '",
            "processed_data_field_keys: Optional[set] = None",
            "sections: Optional[tuple] = None"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 202
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket, DataField"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "packet_to_template_dict",
          "line": 93
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "packet_to_template_dict",
          "line": 101
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "packet_to_template_dict",
          "line": 113
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_serialize_data_fields",
          "line": 81
        }
      ],
      "http_calls": []
    },
    "utils/prompt_builder.py": {
      "module_docstring": "Prompt Builder (robust, persona/context-aware)\n- Assembles the LLM prompt with identity, persona, context, constraints, history, and memory.\n- Actively manages the token budget to prevent context over",
      "classes": [],
      "functions": [
        {
          "name": "build_from_packet",
          "params": [
            "packet: CognitionPacket",
            "task_instruction_key: str = None"
          ],
          "return_type": "List[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 25
        },
        {
          "name": "_build_prompt_core",
          "params": [
            "config",
            "persona_instructions: str",
            "session_id: str",
            "history: List[Dict]",
            "user_input: str",
            "task_instruction: str = None",
            "token_budget: int = 4096",
            "packet: 'CognitionPacket' = None"
          ],
          "return_type": "List[Dict]",
          "decorators": [],
          "is_async": false,
          "line": 678
        },
        {
          "name": "build_prompt",
          "params": [
            "*args",
            "**kwargs"
          ],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 754
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [
        {
          "name": "SUMMARY_DIR",
          "value": "'data/shared/summaries'",
          "line": 23
        }
      ],
      "gaia_imports": [
        "from gaia_common.protocols.cognition_packet import CognitionPacket",
        "from gaia_core.config import Config",
        "from gaia_common.utils.tokenizer import count_tokens",
        "from gaia_core.utils.packet_templates import render_gaia_packet_template",
        "from gaia_core.utils import gaia_rescue_helper",
        "from gaia_core.utils.world_state import format_world_state_snapshot"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 87
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 96
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 130
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 146
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 159
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 187
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 224
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 251
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 329
        },
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 483
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 486
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 496
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 504
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 508
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 561
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 570
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 641
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 667
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_build_prompt_core",
          "line": 700
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 114
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 165
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_safe_session_id",
          "line": 381
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 424
        },
        {
          "exception_types": [
            "IOError"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 536
        },
        {
          "exception_types": [
            "IOError"
          ],
          "status_code": null,
          "enclosing_function": "_build_prompt_core",
          "line": 723
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 769
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 785
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 829
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 403
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_from_packet",
          "line": 412
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 780
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 819
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_prompt",
          "line": 825
        }
      ],
      "http_calls": []
    },
    "utils/resource_monitor.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "ResourceMonitor",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__new__",
              "params": [
                "cls",
                "*args",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 28
            },
            {
              "name": "_ensure_nvml",
              "params": [],
              "return_type": null,
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 38
            },
            {
              "name": "__init__",
              "params": [
                "self",
                "poll_interval: int = 5"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 47
            },
            {
              "name": "start",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 73
            },
            {
              "name": "stop",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 82
            },
            {
              "name": "_monitor",
              "params": [
                "self"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 88
            },
            {
              "name": "is_distracted",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 138
            },
            {
              "name": "check_and_clear_distracted",
              "params": [
                "self"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 142
            },
            {
              "name": "get_instance",
              "params": [
                "cls",
                "*args",
                "**kwargs"
              ],
              "return_type": null,
              "decorators": [
                "classmethod"
              ],
              "is_async": false,
              "line": 165
            }
          ],
          "line": 24
        }
      ],
      "functions": [
        {
          "name": "shutdown_monitor",
          "params": [],
          "return_type": null,
          "decorators": [],
          "is_async": false,
          "line": 171
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "ImportError"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 9
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": null,
          "line": 18
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_ensure_nvml",
          "line": 44
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_monitor",
          "line": 127
        }
      ],
      "http_calls": []
    },
    "utils/stream_observer.py": {
      "module_docstring": null,
      "classes": [
        {
          "name": "Interrupt",
          "bases": [],
          "docstring": null,
          "methods": [],
          "line": 16
        },
        {
          "name": "StreamObserver",
          "bases": [],
          "docstring": null,
          "methods": [
            {
              "name": "__init__",
              "params": [
                "self",
                "config: Config",
                "llm",
                "name: str = 'AgentCore-Observer'"
              ],
              "return_type": null,
              "decorators": [],
              "is_async": false,
              "line": 22
            },
            {
              "name": "observe",
              "params": [
                "self",
                "packet: Optional[CognitionPacket]",
                "output: str"
              ],
              "return_type": "Interrupt",
              "decorators": [],
              "is_async": false,
              "line": 74
            },
            {
              "name": "fast_check",
              "params": [
                "self",
                "buffer: str"
              ],
              "return_type": "bool",
              "decorators": [],
              "is_async": false,
              "line": 519
            },
            {
              "name": "check_response_quality",
              "params": [
                "response: str",
                "user_prompt: str"
              ],
              "return_type": "Optional[Interrupt]",
              "decorators": [
                "staticmethod"
              ],
              "is_async": false,
              "line": 532
            },
            {
              "name": "_verify_citations_against_rag",
              "params": [
                "self",
                "output: str",
                "packet"
              ],
              "return_type": "Dict",
              "decorators": [],
              "is_async": false,
              "line": 596
            },
            {
              "name": "_validate_code_paths",
              "params": [
                "self",
                "text_content: str"
              ],
              "return_type": "List[Dict]",
              "decorators": [],
              "is_async": false,
              "line": 643
            },
            {
              "name": "verify_side_effects",
              "params": [
                "self",
                "packet: Optional[CognitionPacket]",
                "route_result: Dict[str, Any]",
                "llm_output: str = ''"
              ],
              "return_type": "Interrupt",
              "decorators": [],
              "is_async": false,
              "line": 697
            }
          ],
          "line": 21
        }
      ],
      "functions": [],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_core.config import Config",
        "from gaia_core.ethics.core_identity_guardian import CoreIdentityGuardian",
        "from gaia_common.protocols.cognition_packet import CognitionPacket, ReflectionLog",
        "from gaia_common.utils.string_tools import trim_text"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 40
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 44
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "__init__",
          "line": 48
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 91
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 223
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 244
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 257
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 270
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 299
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 348
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 505
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_verify_citations_against_rag",
          "line": 618
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "verify_side_effects",
          "line": 783
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_const_bool",
          "line": 67
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 131
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 203
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 361
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 368
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 372
        },
        {
          "exception_types": [
            "TypeError"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 383
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 402
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 459
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_const_bool",
          "line": 57
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 166
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 285
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 296
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 414
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 456
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 489
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 502
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 515
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 476
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 426
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 453
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 487
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "observe",
          "line": 474
        }
      ],
      "http_calls": []
    },
    "utils/temporal_context.py": {
      "module_docstring": "Temporal Context Builder  assembles a rich temporal snapshot for prompt injection.\n\nProduces a concise text block (~100-150 tokens) injected into the system prompt\nso GAIA has awareness of time, her ",
      "classes": [],
      "functions": [
        {
          "name": "build_temporal_context",
          "params": [
            "timeline_store: Optional[Any] = None",
            "sleep_manager_status: Optional[Dict[str, Any]] = None",
            "session_id: Optional[str] = None",
            "session_created_at: Optional[datetime] = None",
            "session_message_count: int = 0",
            "last_message_ts: Optional[datetime] = None",
            "code_evolution_path: str = ..."
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 33
        },
        {
          "name": "_semantic_time",
          "params": [
            "dt: datetime"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 111
        },
        {
          "name": "_format_duration",
          "params": [
            "seconds: float"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 123
        },
        {
          "name": "_wake_cycle_summary",
          "params": [
            "timeline_store: Any"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 137
        },
        {
          "name": "_session_summary",
          "params": [
            "session_id: Optional[str]",
            "session_created_at: Optional[datetime]",
            "message_count: int",
            "last_message_ts: Optional[datetime]"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 176
        },
        {
          "name": "_activity_summary",
          "params": [
            "timeline_store: Any"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 203
        },
        {
          "name": "_state_summary",
          "params": [
            "status: Dict[str, Any]"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 241
        },
        {
          "name": "_code_evolution_summary",
          "params": [
            "path: str"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 250
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_temporal_context",
          "line": 99
        },
        {
          "exception_types": [
            "OSError"
          ],
          "status_code": null,
          "enclosing_function": "_code_evolution_summary",
          "line": 283
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_temporal_context",
          "line": 61
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_temporal_context",
          "line": 73
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_temporal_context",
          "line": 82
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "build_temporal_context",
          "line": 91
        }
      ],
      "http_calls": []
    },
    "utils/world_state.py": {
      "module_docstring": "Lightweight dynamic world-state snapshot for prompts.\n\nThis module intentionally avoids heavy dependencies. It gathers a short,\nbounded view of:\n- Clock/uptime\n- Host load/memory (coarse)\n- Active mod",
      "classes": [],
      "functions": [
        {
          "name": "_uptime_seconds",
          "params": [],
          "return_type": "float",
          "decorators": [],
          "is_async": false,
          "line": 26
        },
        {
          "name": "_mem_summary",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 37
        },
        {
          "name": "_load_avg",
          "params": [],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 55
        },
        {
          "name": "_model_paths",
          "params": [],
          "return_type": "Dict[str, str]",
          "decorators": [],
          "is_async": false,
          "line": 64
        },
        {
          "name": "_mcp_tools_sample",
          "params": [
            "limit: int = 6"
          ],
          "return_type": "List[str]",
          "decorators": [],
          "is_async": false,
          "line": 73
        },
        {
          "name": "_mcp_tools_full",
          "params": [
            "limit: int = 50"
          ],
          "return_type": "List[str]",
          "decorators": [],
          "is_async": false,
          "line": 82
        },
        {
          "name": "world_state_snapshot",
          "params": [],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 91
        },
        {
          "name": "world_state_detail",
          "params": [],
          "return_type": "Dict",
          "decorators": [],
          "is_async": false,
          "line": 103
        },
        {
          "name": "_capability_affordances",
          "params": [
            "tools: List[str]"
          ],
          "return_type": "List[str]",
          "decorators": [],
          "is_async": false,
          "line": 121
        },
        {
          "name": "format_world_state_snapshot",
          "params": [
            "max_lines: int = 12",
            "output_context: Dict = None"
          ],
          "return_type": "str",
          "decorators": [],
          "is_async": false,
          "line": 165
        }
      ],
      "endpoints": [],
      "enums": [],
      "constants": [],
      "gaia_imports": [
        "from gaia_common.utils import tools_registry"
      ],
      "error_handlers": [
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_uptime_seconds",
          "line": 32
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_mem_summary",
          "line": 49
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_load_avg",
          "line": 59
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_mcp_tools_sample",
          "line": 78
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "_mcp_tools_full",
          "line": 87
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "format_world_state_snapshot",
          "line": 183
        },
        {
          "exception_types": [
            "Exception"
          ],
          "status_code": null,
          "enclosing_function": "format_world_state_snapshot",
          "line": 237
        }
      ],
      "http_calls": []
    }
  },
  "reference_services": [
    "gaia-wiki",
    "gaia-orchestrator",
    "gaia-mcp"
  ],
  "cc_review": {
    "service_id": "gaia-core",
    "reviewer": "cc",
    "review_direction": "forward",
    "review_timestamp": "2026-02-21T00:15:00Z",
    "overall_fidelity_score": 0.8,
    "discrepancies": [
      {
        "dimension": "contract",
        "severity": "major",
        "blueprint_claim": "8 endpoints marked [MISSING] by pre-check: GET /gpu/status, POST /gpu/release, POST /gpu/reclaim, POST /sleep/wake, GET /sleep/status, POST /sleep/study-handoff, GET /sleep/distracted-check, POST /sleep/shutdown",
        "code_evidence": "ALL 8 endpoints are actually implemented in separate router files with prefix routing. api/gpu_endpoints.py defines GET /status, POST /release, POST /reclaim (lines 67, 94, 148) under an APIRouter with prefix='/gpu'. api/sleep_endpoints.py defines POST /wake, GET /status, POST /study-handoff, GET /distracted-check, POST /shutdown (lines 23, 74, 87, 121, 143) under prefix='/sleep'. Both routers are registered in main.py via app.include_router(). The pre-check's 54.5% structural completeness is a false alarm  actual completeness is 12/12 (100%).",
        "recommendation": "No code change needed. The pre-check pattern matcher needs enhancement to follow include_router() prefix composition. All blueprint endpoints are fully implemented.",
        "affected_file": "api/gpu_endpoints.py"
      },
      {
        "dimension": "failure_modes",
        "severity": "minor",
        "blueprint_claim": "Session state corruption  Clears session, starts fresh, logs incident to heartbeat",
        "code_evidence": "Session management is handled through gaia_core's session infrastructure. agent_core.py:run_turn() has extensive Exception handling throughout (lines 633-2019) which would catch corrupt session state. However, there is no explicit 'clear session and start fresh' handler for session corruption specifically  corruption would be caught by general exception handlers which may not always clear the corrupt session cleanly.",
        "recommendation": "Consider adding explicit session corruption detection (e.g., JSON decode errors when loading sessions.json) with a dedicated recovery path that clears the affected session and logs to the heartbeat timeline.",
        "affected_file": "cognition/agent_core.py"
      },
      {
        "dimension": "failure_modes",
        "severity": "minor",
        "blueprint_claim": "Checkpoint write failure  Sleep proceeds without checkpoint; next wake has no prime.md restoration context",
        "code_evidence": "prime_checkpoint.py:create_checkpoint() (line 61) and the internal _generate_checkpoint() (line 143) have Exception handling (line 153). The OSError handlers in __init__ (line 52) and rotate_checkpoints (line 99) suggest file I/O failures are anticipated. However, the specific claim that 'sleep proceeds without checkpoint' when write fails is an architectural property of sleep_cycle_loop.py  the checkpoint write is called during drowsy transition but the sleep state machine continues regardless of checkpoint success.",
        "recommendation": "The behavior is correct by design  checkpoint failure is non-fatal. Consider adding a log warning when checkpoint write fails to make this graceful degradation explicit in operational logs.",
        "affected_file": "cognition/prime_checkpoint.py"
      },
      {
        "dimension": "contract",
        "severity": "observation",
        "blueprint_claim": "Blueprint documents 12 inbound endpoints + 7 outbound interfaces",
        "code_evidence": "main.py additionally exposes endpoints not in the blueprint: voice-state endpoint (sleep_endpoints.py line 45). The outbound interfaces are well-matched: prime inference via OpenAI-compatible API (external_voice.py HTTP calls), MCP dispatch (mcp_client imports), orchestrator GPU signals (sleep_cycle_loop.py HTTP calls), web presence updates (sleep_cycle_loop.py:_update_presence). The service also has additional autonomous features not documented as interfaces: ThoughtSeedHeartbeat, InitiativeEngine, ConversationCurator, SleepTaskScheduler with multiple task types.",
        "recommendation": "Consider documenting the voice-state endpoint and the autonomous background subsystems (heartbeat, initiative engine, sleep task scheduler) in the blueprint, even if they are internal-only.",
        "affected_file": "api/sleep_endpoints.py"
      },
      {
        "dimension": "intent",
        "severity": "observation",
        "blueprint_claim": "Cognitive role: The Brain  runs the full reasoning loop: intent detection, tool routing, multi-step reflection, and response generation",
        "code_evidence": "The code strongly matches this intent. agent_core.py implements the complete reason-act-reflect loop via run_turn() (5000+ lines). Intent detection (nlu/intent_detection.py), tool routing (_run_tool_routing_loop, _execute_mcp_tool), self-reflection (self_reflection.py), cognitive audit (cognitive_audit.py), and response generation (external_voice.py) are all present. Additional cognitive capabilities include: loop detection/recovery (loop_detector.py, loop_recovery.py), goal tracking (goal_detector.py), semantic probing (semantic_probe.py), knowledge enhancement (knowledge_enhancer.py), and persona management (behavior/ package). CPU-only design is confirmed by GPU endpoint delegation to orchestrator.",
        "recommendation": "No change needed. Intent coherence is excellent. The service is unmistakably The Brain.",
        "affected_file": null
      },
      {
        "dimension": "dependencies",
        "severity": "observation",
        "blueprint_claim": "Dependencies: gaia-prime (optional, fallback groq), gaia-mcp (optional), gaia-web (required), gaia-orchestrator (optional), groq (optional), openai (optional), gemini (optional)",
        "code_evidence": "All declared dependencies are confirmed by imports and HTTP calls. gaia-prime: external_voice.py uses OpenAI-compatible API. gaia-mcp: mcp_client module handles JSON-RPC dispatch. gaia-web: output routing via HTTP. gaia-orchestrator: GPU sleep/wake signals in sleep_cycle_loop.py. External APIs (groq, openai, gemini) are used as fallback inference backends. No undeclared dependencies detected beyond gaia-common (universally available).",
        "recommendation": "No change needed. Dependency declarations are complete and accurate.",
        "affected_file": null
      }
    ],
    "open_question_updates": [
      {
        "question": "Should reflection loop depth be dynamic based on query complexity or fixed per persona?",
        "status": "new",
        "evidence": "agent_core.py:run_turn() implements reflection via reflect_and_refine() and run_self_reflection(). The reflection depth appears to be fixed per invocation (single pass) rather than dynamic based on complexity. The _should_escalate_to_thinker() method (line 2222) provides some complexity-based routing but this controls model selection, not reflection depth."
      },
      {
        "question": "Semantic codex hot-reload interval is hardcoded  should it be configurable via gaia_constants.json?",
        "status": "new",
        "evidence": "SemanticCodex is imported in agent_core.py but the hot-reload interval configuration was not visible in the AST summaries. The codex writer and reader modules exist but reload timing appears hardcoded."
      }
    ],
    "promotion_recommendation": "approve_with_notes",
    "summary_note": "gaia-core demonstrates strong blueprint fidelity (80%). The alarming 54.5% pre-check score is entirely due to the pattern matcher's inability to follow APIRouter prefix composition  all 12 endpoints are fully implemented across main.py, api/gpu_endpoints.py, and api/sleep_endpoints.py. All 4 declared dependencies are correctly integrated with appropriate fallback chains. The cognitive loop (reason-act-reflect) is comprehensively implemented in agent_core.py with extensive supporting subsystems (loop detection, goal tracking, semantic probing, knowledge enhancement). Two failure modes (session corruption, checkpoint failure) lack explicit dedicated handlers but have general exception coverage. The service has grown substantially with autonomous background systems (heartbeat, initiative engine, sleep tasks, conversation curation) that should be reflected in an updated blueprint."
  },
  "promotion_outcome": "passed",
  "modifications_before_promotion": [],
  "divergence_score_final": 0.25,
  "ground_truth_fidelity": 0.75,
  "total_checkpoints": 6
}